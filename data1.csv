"The Swedish Act on Municipal Energy Planning was written in 1977 in a time of energy crisis and requires each municipality to have a plan for rational supply and distribution of energy. With regards to the on-going climate change however, there is a need for energy planning to emphasise on shifting towards an efficient energy system with high share of renewables, and low impacts on the climate and the environment.The legislation is therefore argued to be outdated and is currently under review. This study shows that most municipalities are working with the energy issue, as 71% have adopted a policy document with focus on energy and climate. However, 41% has not adopted an energy plan as referred to in the Act on municipal energy planning.The results show that the energy strategies have a wider focus than what is stated in the legislation, which strengthens the view that the legislation can be regarded as outdated. Energy Strategies however still have an important function at the municipal level, as they can help to integrate energy aspects into spatial planning, as well as function as support for the daily energy and climate work in the choice of strategies and measures.The study further shows that the use of Strategic Environmental Assessment has potential to increase the consideration of environmental quality objectives, especially those that might be impacted from the energy plans, but the use of it has been fairly limited and only conducted in 6% of the energy plans. It is therefore recommended that the Act on Municipal Energy Planning is revised to instead include requirements for municipal energy and climate strategies, and that they are made subject to Strategic Environmental Assessment, thus promoting a transition to a sustainable energy system, where environmental objectives are taken into account and possible conflicts can be addressed early in the planning process.",Energy and Environment
"The importance of energy conservation in all the aspects of energy production, transportation, distribution and utilisation should not be underestimated. A special attention to that is paid since the oil crisis in 70’s of the last century. Today energy efficiency has increased considerably, but there is still a potential for energy savings. This potential is widely spread in power plants, energy supply systems, factories, plants, agricultural and residential facilities.In the countries in transition, such as former socialist countries, energy saving policies have started not so long time ago and a lot of work is to be done in order to improve energy efficiency and approach the level of developed countries. In Moldova, the energy sector is one of the most problematic parts of the national economy. 98% of the primary energy resources are imported, which complicates very much energy security in the state.Some internal problems, such as lack of investments in the sector, old and inefficient facilities, uncontrolled and unpaid energy consumption, internal social and political instability create additional difficulties in improving this situation. Industry and residential sector consume the highest amount of the supplied energy. It is obvious that improved energy efficiency in these sectors could lead to big energy savings. Reduction in energy consumption will favourably influence the impact of the energy sector on the environment.The present work aims at identifying energy saving potential in the industrial and residential facilities in Moldova. Interdependence between energy and environment, the positive influence of reduced energy consumption on the environment is shown. Future development strategies and energy resources potential are also discussed.A brief history overview of Moldova and of the energy sector development are presented for a better understanding of the particularities and reasons of the present situation. This is followed by a description of the energy sector in Moldova, its infrastructure and economy, the problems to pass and energy security objectives. In the following part, energy and environment issues are discussed and the way energy conservation influences environmental impact. Environmental aspects of energy use, policy, legislation and institutions in Moldova are also described. Energy Conservation Programme is presented concluding this part.Energy utilisation sector, with deeper analysis of industrial and residential parts is overviewed in the main part of the study. Energy conservation measures are discussed in case studies and the energy savings potential is shown.Scenarios and strategies for future development of the energy system of Moldova are described as a result of the study. Conclusions and further work suggestions are made.",Energy and Environment
"The main aim of this study is to compare actual power production from an existing wind farm with power production prediction by WindSim, which is a CFD tool based on the nonlinear flow model. The wind farm that is being worked on is located in Northern Sweden and has high orographic complexity with forested hilly terrain.There is 1 year record of met-mast wind measurements and nearly 2 years record of production data.Firstly roughness and height contours data are put as an input in order to simulate and generate wind fields over the complex terrain. In addition forest model is used to get more detailed roughness height.After generating wind fields existing turbine locations and 1-year wind speed measurement are imported.The results show that how accurate are the CFD calculations to solve turbulence in a complex terrain. Comparison between actual production data with energy production results by simulations is the main approach of this thesis work to validate the simulations.The results indicate that both WAsP and WindSim have overestimated energy production and wind speed as well. However particularly with WindSim forest module CFD calculations have more accurate results than without forest module and WAsP estimations.",Energy and Environment
"The European Union has set environmental targets on climate change in three areas: energy efficiency, renewable energy sources, and reduction of emissions. These targets are the main driver for the change in today’s power system. The defined targets do not only affect the production and distribution of electricity but also raise questions on how electricity is being consumed.An essential building block of an efficient power system is often referred to as the smart grid. One of the important components of a smart grid is dynamic market models that facilitate demand response. Residential customers account for a relatively large portion of the total electricity consumption in Europe but relatively little is known about dynamic market models used in the residential sector. Pilot projects concerning dynamic market models have been conducted, but there is a lack of common evaluation methods to assess them.This report investigates how pilot projects concerning demand response can be evaluated and presents a compilation of 135 international pilot projects and their results. The evaluations methods and findings from the international compilation are then applied to assess the proposed dynamic market model for the Stockholm Royal Seaport.Four evaluation criterions have been identified. The first relates to the demand response resource that is being studied and its impact on the results of the pilot project. Secondly, design principles of the pilot project must be considered. Thirdly, the division of costs and benefits among stakeholders must be calculated. Lastly, the precision of these measures must be taken into consideration.The compilation of international pilot projects reveals that dynamic markets models are often combined with modern technology. Combinations of market models, feedback and technology have an impact on overall electricity conservation and peak reduction. The reductions also depend on what electrical appliances are being used by the household members and their willingness to change their behavior. Customer acceptance is generally large among participants in pilot projects concerning dynamic market models.The hypothesis for the Stockholm Royal Seaport, in which five to fifteen percent of the load can be shifted from peak hours to off-peak hours with the proposed market model for the Stockholm Royal Seaport, is estimated to be reasonable. Load shift would lead to savings in the range between 64 – 266 SEK per year, which accounts for 1 – 4 % in bill savings. If the proposed dynamic market model is compared to fixed one month contracts, which includes retail price and fixed network tariffs, the bill savings were estimated to have been 563-766 SEK in year 2010. This corresponds to bill savings in the range of 8 – 11 %.",Energy and Environment
"The report investigates the feasibility of accessing waste heat at kiln 7 in the Cementa AB cement plant in Slite, Gotland. The background is provided, with a description of the cement manufacturing process.Most of the report concerns itself with the heat transfer capabilities of the plant, therefore a short description of the heat flow within the most essential equipment is provided.The investigation follows a set of steps to derive the conclusion. The first step investigates previous studies to obtain the three most feasible heat sources. The second step investigates the available heat of the selected sources.In the third step, accessing the source is discussed and investigated for both convection and radiation heat transfer methods. It also includes the sizing of the required heat exchangers. Using the new sources, the connection possibilities to existing infrastructure and its benefits are investigated in step four.The connections were made to the existing infrastructure used at kiln 8 for electrical generation and district heating supply. The selections of the most feasible solutions are provided based on heat recovery, payback period and practicality. The final step in the study provides for the final design, which consists of three possible connections or all of them combined.In the conclusion, the final design would provide for a reduction in oil burned, fuel consumption and CO2 emissions and an increase in electricity generated by the existing system. It is recommended that only one of the three connections be installed.",Energy and Environment
"The island of Malta is highly reliant on fossil fuels for its power (99%), and due to climate mitigation policies implemented by EU the Maltese government is required to have 10% of its power generation from renewables by 2020.To achieve these energy goals, the Maltese government has expressed interest in investing on a Hexicon platform to produce 9% of the Maltese energy demand. The Hexicon platform is a floating structure capable of carrying a wide range of renewable energy generators. The Hexicon platform proposed for Malta is meant to have a rated capacity of 54MW distributed by vertical and horizontal wind energy converters.Nevertheless, due to the irregular nature of wind the Hexicon platform would still use diesel generators on-board as backup power; this inherently defeats the purpose of the Maltese investment, and therefore a Hydrogen backup system was proposed and investigated for its technical and economic viability.A literature study was carried out on renewable hydrogen system in order to familiarise with the type of markets and the best way to apply the technology to the scenario at hand. Four markets were established, small-scale, transportation, stand-alone power systems, and large buffering systems; the large buffering system is the most appropriate for the study, and taking this type of system into account, the most appropriate hydrogen generation and utilisation system were then identified. It was established that the system is composed of three parts, electrolyser, storage tanks and fuel cells stacks.However, an additional water purification system is necessary; this is due to the fact that the Hexicon platform will be located offshore, and salt water is not appropriate for the electrolyser. A literature study was then performed to identify the most appropriate equipment for each stage of the process; it was established that a Reverse Osmosis (RO) system will be used to purify the water, an alkaline electrolyser will be used to generate the Hydrogen, the Hydrogen will then be stored in pressure vessels (at 30bar), thus also requiring compressors, and the recovery of energy will be performed by a proton exchange membrane (PEM) fuel cell (FC) stack.A study was carried out to establish the models to use for each equipment, and based on the hourly demand for Malta, as well as the hourly winds, a first estimate of the size of each equipment was established. The system model was developed in the HOMER software, which unfortunately did not model the desalination plant.The Hexicon (in the design considered in this study) is not able to provide Malta with 9% of the energy demand; this was mainly due to the low wind conditions. In addition to this, it was understood from the literature study that a hydrogen system backup system, i.e. a buffering system, would not be applicable to the scenario initially proposed in this thesis due to the low renewable energy penetration, and also due to the fact that the Hexicon would be connected to the grid, rendering such a system defunct. A micro-grid scenario was assumed and developed.This scenario tried to assess how low the demand would need to be in order to make a hydrogen project feasible. Different percentages were tried and the only one that met the constraints was one with 1.1% of the Maltese demand.The system would consist of a 3MW Fuel Cell, a 4.5MW electrolyser, and hydrogen storage for 10.5tonnes. The NPC of this system would be approx. 130 Million €, with an initial investment of approx. 71 Million €, LCOE of 0.257€.kWh-1, and a Hydrogen cost of approx. 20€.kg-1. While other economic indicators show viability, for example, a short payback time of 3.5 years based on the revenue from the excess electricity, the cost of hydrogen suggests that it is too expensive.",Energy and Environment
"Building sector in Sweden constitutes a major part of the overall energy consumption, making up for around 40% of the total energy use. During the 60s and 70s, there was a big surge in housing in Sweden with over a million dwellings, both single family houses and multi-family apartments, constructed over a period of ten years.These buildings constructed according to the pre-oil crisis standards, suffer from poor energy performance and are in dire need for large scale renovations. This makes it a very interesting area to focus on to meet the Swedish government targets of 50% energy reduction by 2050.This study tries to assess the prevailing situation in multifamily housing sector and focuses on various obstacles and hinders in the path towards achieving long term energy saving goals. A model has been developed using bottom-up approach to study different scenarios for energy use in 2050 based on various renovation possibilities in the building stock.",Energy and Environment
"Hybrid Energy Resource System (HERS) is studied and applied around world in recent years. Control and monitor of them are quite important in real application. HERS also has the equipment to integral with power grid such as distribution grid networks.Therefore, to design and implement the information communication system following IEC 61850, which is most promising standard for design of substation communication and automation system, is necessary.This paper presents the design of Information Communication Technology (ICT) architecture and Unified Modeling Language (UML) models and final implementation through LabVIEW programming for Smart Energy Container. Applying design following IEC61850 series standards allow the HERS can communicate and interoperate with other IEC61850 devices and SCADA systems.The implementation is applied to SmartEnergy Container which contains wind power, solar power, battery energy storage system, and hydrogen energy storage system. Verification and testing results shows the design is qualified to control and monitor Smart Energy Container.",Energy and Environment
"The world’s energy use in buildings (residential and commercial) accounts for around 40% of the worldwide energy consumption, and space heating is the responsible for half of the energy need in the building sector. In Europe, only a small share (less than 10%) of existing buildings was built after 1990. Most of the building stock does not satisfy the recent energy technical standards; in addition there is a very low trend to construct new buildings in the last years.Renovation of the existing buildings is a feasible option to reduce the energy need in Europe, but finding the optimum solutions for a renovation is not a simple task. Each design parameter differently influences the final energy need of buildings and, furthermore, the different variables are differently correlated each other. Building refurbishment will benefit from a tool for the selection of the best measures in term of energy need.This work, through a global sensitivity analysis, aims at determining the contribution of the design parameters to the building energy demand and the correlation between the different variables. The considered parameters are related to the improvement of the thermal transmittance of both the opaque envelope and the windows, the solar transmittance of the glazing surfaces, the window size, the thermal inertia of the internal walls and the external sunshades for windows.Several dynamic simulations have been performed varying the design parameters from different starting conditions. Finally, due to the large number of cases elaborated, an inferential statistical analysis has been performed in order to identify the predominant factors and the correlation between the design parameters in a global context.",Energy and Environment
"Decision making processes of natural resources for sustainable development are very complex processes that contain large amounts of contradicting criteria and alternatives and/or objectives. Hence efficiency of planning and decision making is highly dependent on the structure of the decision problems.In this respect Multi Criteria Decision Aid (MCDA) is the most widely used method. Particularly GIS-based MCDA using the Analytical Hierarchy Process (AHP) is a well-known method in this respect. However, there are inter relationships and inter-dependencies among problems of the real world. As a result, many spatial problems cannot be structured hierarchically because the importance of the criteria determines the importance of the alternatives, and the importance of the alternatives also determines the importance of the criteria.Analytical Network Process (ANP) based MCDA is a new planning and decision making approach that allows the decision problem to be modeled considering feedbacks and interdependence among criteria. This study critically reviews GIS-based MCDA using the AHP method and the ANP based MCDA method and forwarded recommendations for future works.To attain this, practical decision making processes were used of urban form selection for a sustainable development of the Stockholm region. For this purpose literature was reviewed, separate methodologies were developed, criteria were formulated to be analyzed using GIS and SuperDecision software‟s, and finally reasonable results were achieved and separately presented to critically evaluate both the methods and the outcome.This study showed that GIS has the potential to be an important decision aid tool, that the ANP seems to give more realistic results than the GIS-based MCDA method, and that a compact scenario that over time follows already established polycentric pattern would be the best alternative urban form for a sustainable development of Greater Stockholm.",Energy and Environment
"This study has been conducted as a Minor Field Study (MFS). It focuses on solar water pumping for small-scale farmers in the Kilimanjaro Region of Tanzania. The purpose is to investigate the possibilities for rural farmers to operate their irrigation with solar power instead of their current option: fossil fuels, primarily petrol.The study was conducted in three phases, starting with pre-study in Sweden, followed by field study in Tanzania from January to March 2015 and finishing with summarizing and calculating in Sweden.Fuel powered water pumping has a cheap capital cost; however, it is expensive and problematic to maintain and operate. Solar powered water pumping is almost completely opposite. It has a higher initial cost; however, it is considerably cheaper to run. The results indicate that the investment in solar power might be too expensive for the farmers, as long as they do not receive external financial and educational support.Assuming that the farmers are able to obtain a solar water pumping system, results show that they will benefit and save a considerably amount of money over a long period of time. Also, solar water pumping is environmentally friendly compared to the systems in Tanzania today.",Energy and Environment
"Nowadays it is necessary a new approach in the society, more focused on getting a sustainable behavior and development in a global environment. Today, it is accepted by most of the scientific community that the global warming is more and more enhanced by the increased CO2 in the atmosphere, due to the burning of fossils fuel for the last 100 years, necessary for various energy services.At the same time it is also clear that many energy transformation processes have showed to be highly inefficient, because they mostly concentrate upon one energy service only. A higher efficient system would require using the available energy fully to supply different services (like power, heat, cooling, clean water, transportation fuel, pellets …) simultaneously. The concept of polygeneration (simultaneous transformation of basic energy sources) can be a practical way for getting a significant higher yield from the basic energy source.Micro gas Turbines (MGT) are a relatively new distributed generation technology which is used for stationary energy generation applications. Their use for-on site smallscale energy production offers a great opportunity for primary energy saving and reduction of pollutant and greenhouse gas emissions. Microturbines can be used for generating power only or they can be used in cogeneration systems, for generating both power and heat (CHP systems), so it is possible locally recovering waste heat from exhaust gas, especially for Thermally Activated Technologies (TAT) The polygeneration lab at KTH hosts several test rigs that can be operated separately and also integrated. An important part of the work is to study, make and optimize the integration of the various rigs.The objective of the work reported in this Thesis is installing and testing the performance of a new microturbine, with a very similar design to the old one, but provided with a more solid turbogenerator. The turbine performance will be analyzed for its possible future contribution in a polygeneration system. Moreover, the old microturbine will be disassembled for checking the causes of the vibrations, making conclusions about its shortcomings and suggestions for making sure that the new one will be a real improvement",Energy and Environment
"Waste disposal is a global problem contributing to the ongoing climate change by large emissions of greenhouse gases. By using waste material as a resource instead of landfilling, the greenhouse gas emissions from landfills are reduced.Waste material can be used for waste incineration with energy recovery, thus decreasing the greenhouse gas emission from energy utilization by changing from fossil fuels to a partly renewable fuel.Arges County in Romania has severe problems with its waste material, mainly sewage sludge and waste from households and industries. As a consequence of the Romanian EU accession in 2007, Arges County is obliged to close its landfills for waste in a near future.A reconstruction of the wastewater treatment plant and an improved management of the sewage sludge residue are necessary in order to comply with EU standards. The requirements from the EU regarding waste disposal together with the existence of a district heating network in the residence city Pitesti, makes it interesting to investigate energy recovery from waste material in Arges County.Therefore, the goal of the study is to evaluate the possibility to extract energy from co-incineration of the waste material, sewage sludge and waste generated in Arges County. In order to reach this goal, the composition and quantities of the waste material is investigated. A suitable technology for the waste-to-energy (WTE) plant is proposed, based on the data of the waste material as well as on   established WTE technologies and their costs.It is assumed that the WTE plant will be implemented in 2020 and that all the generated waste will be incinerated. Furthermore, an environmental analysis is carried out, which presents the reductions of greenhouse gas emissions with the proposed WTE plant in comparison with the present system; including the management of waste and sludge and the district heating production, which is based on fossil fuels.The result shows that the waste material in Arges County has a calorific value of 7.5 MJ per kg, which is suitable for co-incineration of waste and sludge. The suggested WTE plant has the total power of 130 MW, annually recovering 620 and 330 GWh of heat and electric power respectively. The investment cost of the WTE plant is estimated to 226 million euro with a payback time of 8 years. The environmental analysis shows that the proposed system in comparison with the present system will decrease greenhouse gas emissions by 88 percent.A WTE plant appears to be a sound investment in Arges County and would sharply reduce the emissions of greenhouse gases in the county. However, some obstacles exist. Waste management is a new field in Romania and currently there are no WTE plants. Furthermore, the data used in this study concerning the quantity and composition of the waste, is uncertain and further studies are necessary before a WTE plant can be established.",Energy and Environment
"Brazil is very much rich in agriculture and forestry. The agro industry occupies an area of 28840726 ha. The more important crops are sugarcane (7080920 ha), rice (289030 ha), wheat (1853220 ha), coconut (283205 ha), cassava (1894460 ha), corn (13767400 ha) and grass (140000 ha). These crops generated 597 million tons of residues. Forest plantations in Brazil supplied 102.9 million m3 of industrial roundwood, of which nearly half is for renewable fuelwood and charcoal.Part of this plantation output is destined for the pulp and paper industry:The renewable sources are fulfilling 46.4% of the total Brazilian energy demands.Energy forestation in Brazil includes mainly Eucalyptus and Bracatingas.In this study three biomasses abundant in the Brazil are studied:  i.e. Eucalyptus, Garapeira/Peroba (wood dust) and Sewage Sludge.The wood samples (Eucalyptus and Peroba/Garapeira) have higher heating value than the sewage sludge because the wood samples have higher amounts of carbon and hydrogen than the sewage sludge. The sewage sludge has higher ash content and lower amount of volatiles and fixed carbon than the wood samples resulting in a lower heating value.The pyrolysis of eucalyptus, garapeira/peroba and sewage sludge has been studied in a thermobalance over a wide range of degradation temperatures. Between 225 °C – 375 °C (for eucalyptus) and 225 °C – 425 °C (for garapeira), the thermal decomposition of the biomass leads to significant weight loss.The weight loss for Eucalyptus between 265°C and 350°C is 0.48 % / °C and taking into account a heating rate of 10°C/min, the weight loss is 4.8 % /min. Garapeira has a similar behaviour than eucalyptus. The weight loss for garapeira between 265°C and 365°C is 0.4 % / °C and taking into account a heating rate of 10°C/min, the weight loss is 4 % /min.The behaviour of the sewage sludge to the increase of temperature from 25°C to 700 °C in an inert atmosphere do not show such different zones as the behaviour of the woody biomass. Between 150 °C and 235°C the weight loss of the sewage sludge was 0.07 %/°C (0.7 %/min). The highest weight loss takes place between 300 °C and 390 °C (0.15 %/°C or 1.5 %/min). In the third zone, between 500 °C and 600°C, the weight loss was 0.03 %/°C (0.3 %/min).The pyrolysis is assumed to be a first order decomposition. The activation energy (E) and the pre exponential factor (A) are calculated for the studied samples.The proximate analysis shows differences between the woody biomass and the sewage sludge. The sewage sludge has higher ash content and lower fixed carbon and volatiles. Eucalyptus has lower carbon fixed and higher volatiles than peroba-garapeira.",Energy and Environment
"The aim of this project is to make an energy survey for a group of apartments and suggestions to change the heating system from electricity to a more efficient one. There are in total 73 flats in 21 buildings. All flats are separated in several houses from two to five flats in one building. There are two different kinds of flats. One with three rooms in one floor, in the following referred to as ‘flat A’ and the other one with four rooms in two floors, in the following referred to as ‘flat B’.In the area there are also two buildings for the commonalty. In these buildings there are a shelter and several common rooms like a storage and a laundry. In our work these two buildings are not included because they are used by everyone inside the community and we could not obtain exact values for the used electricity and the water consumption. So our work is specialised only on the residential houses.The first part of this thesis contains the energy balance for the different kinds of flats to see how much energy they consume for heating and hot tap water. To get theses values we have to analyse the total energy flow into one flat and compare it with the energy which is used because of transmission losses, ventilation losses, hot tap water, electricity for the household and natural ventilation and infiltration.The total energy consumption for flat A is about 19000 kWh per year and in flat B about 23200 kWh per year. But the electricity which is used and has to be bought is about 15600 kWh per year in flat A flat and 17600 kWh in flat B. The rest of the energy is from so called free heat caused by solar radiation and internal heat generation.These numbers for the electricity need in one year create annual costs of about 20000 SEK in flat A and 22500 SEK in flat B. To reduce these costs it is necessary to know where this energy goes and for what it is used. The important parts of the energy balance for this thesis are the transmission losses, the losses caused by natural ventilation and infiltration and the used energy for hot tap water.The losses caused by mechanical ventilation have also a significant value, but they would only affect the new heating system if the ventilation system would be connected to the new system. And the electricity used in the household for electrical devices can only be changed by the consumer himself. The part which is affecting the energy costs for the transmission and natural ventilation losses and the hot tap water sums up to 9240 kWh per year in flat A and flat B. This causes costs of about 10000 SEK per year.To reduce these costs it is necessary to change the actual heating system. In the following we analyse the saving potentials with a change to an air-water heat pump or with a connection to the local district heating network. The costs which can be saved with the installation of a heat pump sum up to about 7000 SEK per year. The installation costs are about 100000 SEK to 125000 SEK depending on the different proposed models. If you consider that the existing electrical boiler has to be changed anyway in the next years the investment costs for the combination with a heat pump decreases. The payback time is then between 9½ and 13½ years. With assumed increasing electricity prices of 5 % each year the payback time decreases to 8½ to 11 years.With a connection of each flat to the local district heating network the energy costs for heating and hot tap water decreases to 3200 SEK per year. Although the price per kWh for district heating is much lower than for electricity the costs are not decreasing a lot because of a high annual fixed fee of 7100 SEK. The saved money per year sums up to 300 SEK and 1000 SEK depending on the electricity contract. The payback time for this alternative is between 50 and up to 160 years.An alternative to the exchange of the heating and hot water system is to change the actual heat exchanger of the ventilation system. With this measure the energy consumption can be reduced with less investment costs. The investment costs for a new heat exchanger are about 35000 SEK, including a new exhaust hood from the kitchen outwards to reduce the contamination of the filters in the heat exchanger. The payback time ranges from 13 years in flat A to 21 years in flat B.",Energy and Environment
"Current hydraulic systems involving multiple actuators and a single hydraulic power supply generally have poor efficiency. Using throttling valves to control multiple actuators requires meeting the highest pressure requirement and the total flow of all of actuators.When there is a large difference in the pressure requirement of the actuators, fluid throttling results in significant energy losses. The purpose of this project is to implement switch-mode control in a multi-actuator circuit and demonstrate the improvement in efficiency over a traditional hydraulic system with throttling valve control.To accomplish this task a hydraulic crane arm powered by two actuators was designed and constructed. One actuator provides a pivoting motion utilizing low pressure and high flow, while the other provides a lifting motion utilizing high pressure and low flow.Using a simple feedback control loop, the crane arm lifts, rotates, and lower a load. After designing and testing the hydraulic crane, the team concluded that high-speed switch technology with multiple actuators is feasible. This new technology, once implemented on a larger scale in realistic applications, will reduce losses in hydraulic systems that depend on multiple actuators to function.Introduction:",Energy and Environment
"Accurate wind resource assessment is of high importance for wind farm development. This thesis estimates and compares the annual energy production results produced employing two wind farm design tools WindPRO and WindSim for a site located in Greece.Two years of data are available from a 56 meter met mast. The data are analyzed filtered and converted to appropriate formats for usage by the wind farm design tools. Abnormalities in the wind data are observed, investigated and presented.For energy calculations in WindPRO different roughness data and height contours are used and evaluated resulting to 36 different energy estimations. The result show that the annual energy production results for different parameters have a difference from 0,07% to 8,18 %. Concerning energy estimations using WindSim a grid sensitivity study is produced utilizing a low resolution grid to an ever more refined grid for different boundary layer heights and air density’s.Parameters introducing uncertainties and energy losses in the calculations are identified and quantified. Using the annual energy production, uncertainty and energy losses the P50, P75, P90 are produced for WindPRO, WindSim and are compared. These result indicate a good approximation in the estimated values from both wind farm design tools, for the investigated site the result differences vary from 0,2 % – 2,0%.",Energy and Environment
"The electrical energy output and the performance of a PEM fuel cell is dependent on the ion transfer in the fuel cell. The ion transport mechanism in the electrolyte cell membrane is dependent on the charge site in the membrane.The charge sites increases with an increase in the hydration of the membrane, this shows that the water content of the membrane is important to facilitate the ion transfer in the electrolyte membrane, hence proper management of water is essential to the operation of the PEM fuel cell system, to achieve these a proper balance of the water transport within the PEM fuel cell is needed for the optimum operation of the PEM fuel cell membrane.This work is based on an assessment of the humidity management effect on the performance of the PEM fuel cell. If the fuel cell membrane is over hydrated with water, it results in over flooding of cell membrane, which causes activation losses and H+ ion cross over losses in the fuel cell, and if the membrane is poorly hydrated it results in poor hydration of the membrane which causes concentration loss, and very low ion conductivity.The water balance system of the fuel cell is such that water vapour is present in the air at the inlet, the water is also used for H+ ion transport from the anode to the cathode, the excess water in the cathode is back diffused in to the anode, at the cathode it is also produced from the chemical reaction of the fuel cell, at the exits water it is evaporated at both the anode and cathode of the cell, and finally with the use of water mass balance we determine the mass of the water which is injected into the fuel cell to meet up the water demand for the hydration of the membrane.This work analyses how these parameters, the operating temperature, relative humidity of air, the inlet temperature, the pressure drop in the cell membrane, the operating temperature, the membrane thickness and the stoichiometry of air affects the water content of the cell membrane. The results from this work showed that a proper management of the PEM fuel cell is of central importance to control the membrane hydration and ensure proper performance of the fuel cell.",Energy and Environment
"This work aims on the investigation of factors influencing the discharge characteristics of a heat storage system, which is based on the reversible reaction system of Ca(OH)2and CaO. As storage, a packed bed reactor with embedded plate heat exchanger for indirect heat transfer is considered. The storage system was studied theoretically by means of finite element analysis of a corresponding mathematical model.Parametric studies were carried out to determine the influence of reactor design and operational mode on storage discharge. Analysis showed that heat and gas transport through the reaction bed as well as the heat capacity rate of the heat transfer fluid affect the discharge characteristics to a great extent.To obtain favourable characteristics in terms of the fraction of energy which can be extracted at rated power, a reaction front perpendicular to the flow direction of the heat transfer fluid has to develop. Such a front arises for small bed dimensions in the main direction of heat transport within the bed and for low heat capacity rates of the heat transfer fluid.Depending on the design parameters, volumetric energy densities of up to 309 kWh/m3 were calculated for a storage system with 10 kW rated power output and a temperature increase of the heat transfer fluid of 100 K. Given these findings, this study is the basis for the dimensioning and design of a pilot scale heat exchanger reactor and will help to evaluate the technical feasibility of thermo-chemical heat storage systems.",Energy and Environment
"This thesis examines the performance of residential buildings and the energy systems contained within those buildings by simulating them in the TRaNsient SYstems Simulation (TRNSYS) program. After matching a building’s floorplan to that of house local to the College Park area, national and local building surveys were consulted to produce a prototype of the average Maryland home. This home was simulated with ordinary insulation levels, heating, ventilation, and air conditioning (HVAC) equipment, and appliances.Various construction characteristics, including wall insulation, thermostat set points, HVAC equipment, and appliance efficiency were varied to examine the effects of each individual change upon the final annual energy consumption of the building, and in doing so, the value of retrofitting each characteristic was explored.Finally, the most effective energy-saving strategies were combined to model a low-energy home, in order to explore the possibility of refitting an existing home to become a net-zero site energy building. Sensitivity study results were listed, and a net-zero-energy building was successfully simulated.",Energy and Environment
"This project has been developed at the company Gavlegardarna. The company owns a large part of the buildings of Gävle and two of them are the objective of the project. Gavlegardana is highly concerned about the environment; for this reason, they cooperate on the subject with the energy management from their technical department.Gävle is one of the Swedish cities where the DH (district heating) network is distributed, arriving to most of the dwellings, industries and commercial buildings. As DH uses environmentally friendly sources of energy,Gavlegardana is introducing it in its buildings.Electrical radiators and boilers were installed in the buildings when the price of electricity was more affordable than nowadays. The price of the electricity can be considered 1,23 SEK/kWh while the DH price is 0,45 SEK/kWh.Consequently, this is another reason why the objective of the company at the present time is to replace electrical space heating systems by means of district heating.The energy balance of the buildings is analysed in order to study their current energy situation. This entails the consideration of heat gains and losses involved. The heat gains of the building are the heat from solar radiation which arrives at the building trough the windows, the heat internally generated (by persons, lighting and other devices) and the heat supplied. The heat losses are composed by the transmission trough walls and windows, the infiltrations, the heat used for hot tap water and the ventilation losses.An important part of the work required to calculate the energy balance has consisted of the collection and organization of all the data (areas, types of material, electrical devices, lighting, number of employees, opening hours…).This data comes from the drawings of the buildings provided by the company and from the information gathered during the visits to the installation. In addition, the ventilation flows were measured in-situ using the tools provided by Theorells.Gavle Energi, the DH distributor company, has been contacted in order to fixthe cost and other details related to the district heating connection. The heat exchanger models, selected from Palm at System AB, are TP20 for Building A and TP10 for Building B. TP20 provides 100 kW of heating and 0,4 l/s of hot tap water and TP10 provides 50 kW and 0,31 l/s respectively. The capital cost is 187500 SEK which includes the heat exchangers and the connection cost.As the secondary circuit is not currently installed because the existing system is composed by electrical radiators, the installation of the piping network in the building has been designed. The radiators’ power is calculated taking into account the need of heat in each room which is estimated as the transmission losses. This need of heat calculated is higher than the energy currently supplied which means that the thermal comfort is not achieved in all the rooms of the buildings.In spite of using more energy for space heating, the change of heat source entails a lower energy cost per year. The selected radiators are from Epecon and the investment cost (including the installation) is 203671 SEK. The brand of the selected pipes is Broson and the investment cost of the total piping system is 66000 SEK.The initial investment of the new installation is 457171 SEK, considering the DH connection, heat exchangers, radiators and pipes. If the initial investment is totally paid in cash by the company the payback will be fulfilled in 6 years. In case of borrowing the money from the bank (considering an interest rate of 5%), two possibilities can be considered: paying back the money in annual rates over 15 years or 30 years of maturity. The paybacks are 11 and 8 years respectively.After designing the DH piping system in the buildings, estimating the total costs of the investment and studying the project’s feasibility by suggesting different payment options, some possible energy savings are recommended.The first of the options refers to the transmission losses trough the windows whose values’ are considerably high. Using a glass with a lower U-value, these losses can decrease until 66% (with triple glass windows). Consequently, the power required for space heating can also be reduced until 26%.Regarding the ventilation, rotating heat exchangers are currently used, which entails the problem of smells mixture detected by the users of the buildings. By changing them with flat-plate heat exchangers, the problem is solved and the efficiency is increased from 66% to 85%. The new heat exchanger cost is340387 SEK and it has a payback of 10 years.",Energy and Environment
"China is rich in coal resources, possessing as much as 13 percent of world’s coal reserves.With a vital role in domestic economic development, coal contributes to 70 percent of national energy needs. China’s power industry mainly depends on thermal power plants,where the largest share of coal is consumed.At present in China, generating and transmitting of electricity are completely 2 separated operating systems, particular different in monopoly level. For better communication between them and more effective and smooth working procedures, the State Grid Corporation of China(hereinafter referred to as SGCC) was established in 2002, under supervision of National Development and Reform Commission, which is in charge of making major policies concerning development. SGCC has multiple functions, both as governmental authority and as an individual company.The electricity power market is experiencing a significant systematic reform which has been ongoing for over 10 years. Its main goal is to ”Break monopoly, and introduce competition”. In this reform, there are two big power grid companies and five major electricity generation groups established in the scheme of organization reform. These power grid companies are responsible for electricity transmission and the power generation groups are in charge of electricity production. One purpose of this thesis is to introduce deregulated market theory in China’s electricity market.Only when generation, transmission and distribution are opened separately, can it achieve to reduce electrical energy cost and, as a result, lower electricity price. In the process of reform, several theory problems are discussed: Competition and monopoly, bidding for sale, the electric power system’s big cycle and minor cycle.Petroleum is regarded as a non-renewable resource and will be used up someday.Meanwhile,oil prices surge gradually, and with human society’s full-scale development, new demand as well as new energy technology are stepping onto the historical stage. These factors are major reasons that the utilization efficiency for petroleum is lower than for any other energy. In order to ease the contradiction between energy supply and demand, we must minimize the share of un-renewable resources such as fossil fuels, and increase the new and renewable energy shares in the current energy structure.In one word, the long-term objective is to establish a sustainable-developing energy system.New energy for electric power industry in China has two aspects: First, utilization of clean coal technology for electricity generation, and second, the renewable energy resource for electricity generation mainly consists of hydropower, wind power, biomass electricity generation, tidal power, and solar power generation and so on. The industry is still in its infancy and there’s still a long way to go.The Chinese government will progressively increase the ratio of consumption of the high-quality, clean and renewable energy in the gross energy consumption from 7 percent in 2005 to 13 percent in 2020.",Energy and Environment
"This study investigates the feasibility of installing solar thermal energy systems on small residential districts and the practical issues that can arise. A residential district, planned to be built in the locality Tierp, has been used as a case study.The residential district Kanalstaden will be designed as a canal residential area, where houses will be constructed alongside three to five artificial canals. The district will consist of small module houses with one basic module that later can be extended by adding one or two similar modules, as well as larger two floor houses.The circumstances of the residential area, the houses and the residents, puts certain requirements and demands on the design of a potential solar thermal system. This does in turn highlight some main factors that have to be taken into consideration when a solar thermal energy system is planned for residential areas.Practical issues like where and how collectors and tanks can be placed has to be considered, but also things like the balance between supply and demand has a great importance. Surrounding circumstances, such as shadowing, can also have a great impact. Social factors, such as the specifics of the residents’ heating and water demand, have ultimately also a very important role.The most significant conclusion that can be drawn from the case of Kanalstaden however, is the flexibility of solar thermal energy systems. It can, and should, be implemented differently depending on the actual circumstances existing – it just has to be designed and installed in accordance to it.",Energy and Environment
"Improvements in technology, as we get closer and closer to the limits of Moore’s law, require the use of a holistic design approaches as a new paradigm in value creation for future technologies. In light of these limitations, technology innovations should focus not only on shrinkage but also on a combination of exotic materials and novel designs. This idea constitutes the frame work of the research work presented in this project.The work focuses on the study of novel micro-circuit ideas founded on material processes, integrations and device structures. This work begins with a hydrated Ruthenium oxide and activated carbon based electrochemical energy cell is introduced. Multiple electrode materials, packaging approaches and electrolyte composition are investigated. The performances of the various devices are evaluated. The studies on the fabrication of the novel electrochemical energy cell yielded encouraging results where the most promising cell is the Graphite-Zinc cell.Subsequently, the examination of a novel AlxGa1-xN alloy device structure and growth method that enables simultaneous dual UV-wavelength band detection. A clear roadmap to the creation of a dual UV-wavelength detector array, based on confined epitaxial growth, is offered. The growth mechanism involved in the confined epitaxial growth approach, which enables the stacking of active layers with varying stoichiometry, is introduced. Electrical and optical evaluations of the fabricated detectors proves the diode nature of the detectors; while, spectral sensitivity curves demonstrate dual UV-wavelength sensitivity of the detector array.Finally, an inexpensive and effective sub-wavelength lithography technique based on a novel mask is studied. The concept behind the mask is to substitutes the conventional clear and opaque mask by a “dot array” mask making use of plasmonic waves. The mask is then utilized for far-filed imaging within a traditional stepper. Mask principals, fabrication approach and characterization of the printed patterns are presented. Contact windows were exposed with critical dimensions down to 110nm using 248nm incident radiation. While the exposure times are slightly longer than usual, the imaged patterns appear to be a cooperative effect of scattering from multiple apertures. The absence of a few random apertures does not distort the printed patterns.",Energy and Environment
"It is a requirement of the project briefing document that each site is to incorporate sustainable technologies within their design in order to reduce energy consumption in line with global measures to reduce carbon dioxide emissions.As a measure of applying appropriate sustainable measures it was a requirement that Al Zeina could achieve a minimum silver rating under the Leadership in Environmental and Energy Design (LEED) system. The aim was to deliver a showcase development and example of best practice in Abu Dhabi which would set the standards for future development in the city.There is usually a cost implication associated with sustainable technology and this needs to be recognized at the onset of any project by both the Client and the Contractor. However, through careful design and selection of equipment, payback periods can be reduced and the systems then provide financial as well as environmental benefits.",Energy and Environment
"This project deals with the potential of membrane stratified solar ponds which consist of two water layers, where one is a salt solution here, and a separating translucent membrane. An experimental pond was set up to study the thermal behaviour of such collector systems. The input is mainly solar radiation, sometimes when the ambient temperatures are higher than the pond temperatures also heat from the environment is transferred into the pond.The measured temperatures of the pond, the ambient temperature, the global radiation and wind speed were the basis data for thermal calculations which showed that the pond was working well as a solar collector and thermal storage system all in one. Heat was not extracted from the pond however, only the losses to the environment were studied.It was found out that the pond temperatures were higher than the ambient temperature over the whole measurement period of 12 days, and insulation and pollution problems as well as future prospects and suggestions for further studies are discussed at the end of this paper.",Energy and Environment
"The work presented in this thesis concerns the dimensioning of an Energy Storage System (ESS) which will be used as an energy buffer for a grid-connected PV plant. This ESS should help managing the PV plant to inject electricity into the grid according to the requirements of the grid System Operator.It is desired to obtain a final production not below 1300kWh/kWp with a maximum ESS budget of 0.9€/Wp. The PV plant will be sited in Martinique Island and connected to the main grid. This grid is a small one where the perturbations due clouds in the PV generation are not negligible anymore.A software simulation tool, incorporating a model for the PV-plant production, the ESS and the required injection pattern of electricity into the grid has been developed in MS Excel. This tool has been used to optimize the relevant parameters defining the ESS so that the feed-in of electricity into the grid can be controlled to fulfill the conditions given by the System Operator.The inputs used for this simulation tool are, besides the conditions given by the System Operator on the allowed injection pattern, the production data from a similar PV-plant in a close-by location, and variables for defining the ESS. The PV production data used is from a site with similar climate and weather conditions as for the site on the Martinique Island and hence gives information on the short term insolation variations as well as expected annual electricity production.The ESS capacity and the injected electric energy will be the main figures to compare while doing an economic study of the whole plant. Hence, the Net Present Value, Benefit to Cost method and Pay-back period studies are carried on as dependent of the ESS capacity.The conclusion of this work is that it is possible to obtain the requested injection pattern by using an ESS. The design of the ESS can be made within an acceptable budget. The capacity of ESS to link with the PV system depends on the priorities of the final output characteristics, and it also depends on which economic parameter that is chosen as a priority.",Energy and Environment
"This project is a preliminary study in order to build a small power plant, located beside to Gavleån River. It has been designed with the aim of cooling a district of Gävle city, Sweden. That big project is carried out by the international consulting engineering company SWECO.The mentioned plant contains a thermodynamic cycle that takes water from the river and afterwards, it is returned back warmer. It will attempt to study the temperature raise downstream along the river due to the spill of hot water.In addition, it will try to quantify and weight which may be the importance of the increment of temperature compared to the entire river. This work could be vital for an environmental impact study. The thermo and fluid dynamic problem is going to be solved using typical procedure for numerical simulations.To do this, it will be used Computer Aided Design (CAD) to model Gavleån River path and Computational Fluent Dynamics (CFD) to predict the distribution of temperatures. Finally the results of the simulations will be analyzed and discussed to draw conclusions about the final temperature raise in Gavleån River.",Energy and Environment
"Harvesting Energy stands alone as one of the most promising techniques for approaching the global energy problem without depleting natural resources. Energy harvesting technologies from road infrastructure is a new research territory that encompasses technologies that capture the wasted energy occurred at pavements, accumulate and store it for later use.Their most enticing characteristic is that they already offer extended paved surfaces. Paved surfaces with conductive pipes, PV sound barriers, nanomaterials or Phase Change Materials, piezosensors and thermoelectrical generators and induction heating technique are just the most updated representatives.Their outputs can be listed as production of electric energy and district heating  and cooling, deicing surfaces or powering wireless networks and monitoring pavements conditions along with the enhancement of their self-healing process. The objective of this thesis is to review them and identify their strong and weak points.The three Green Roadway Concepts that shaped, proposed and implemented, theoretically are identical for the long-and short-term challenges that they meet. Their forthcoming future is here and only their in-situ implementation can prove their viability and prominence.",Energy and Environment
"Bio gas is a sustainable alternative for fossil fuels. This also provides a solution to biowastes. There are various designs for the efficient production of biogas. Majority of biogas generation units use animal wastes as feed material.Plug flow type biogas digester was identified as more suitable for using non conventional feed stocks like green vegetations, municipal waste for the biogas production. These digesters have been reported to be more efficient in converting feed stocks with higher total solids content.The aim of this study was to investigate the variables associated with plug flow biogas digesters and to determine the operational parameters that will give optimum biogas production. In the study  three feed rates were used.The highest specific methane production of 0.341m3/kgVS per day was observed at feeding rate of 1.4kg per day. Highest VS reduction of 91.37% was observed at feeding rate of 1.4 kg per day. VFA profile and pH profile along the digester length showed the distribution of biogas production stages along the length of the digester especially at lower feed rates.",Energy and Environment
"Our goal for this project is to design and implement a bicycle power generator for the DC House Project. The DC House Project is an initiative to bring safe and reliable power to the billions of people around the world without electricity.This goal will be accomplished by designing a safe and sturdy human powered stationary bicycle that produces DC energy. The DC power generated can be stored via batteries and used by the local population to use for lights and other utilities that many take for granted on a daily basis.Bicycle Power Generators are not a new idea, with many created by hobbyist for residential use with small scale energy in mind, to charge batteries in case of a power outage or natural disaster. We are looking to expand upon these designs and build a DC generator that will convert human power into electrical power.The objective is to build a device that is safer and more power efficient. If our product design were to be built and shipped to people across the globe, it would be imperative that it meets all the safety specifications that any national commercial product entails.",Energy and Environment
"In United Arab Emirates (UAE), a huge proportion of electrical energy consumed in buildings is used to run air conditioning equipments. This is because UAE’s climate is characterized by very high ambient temperatures and high humidity, especially during summer periods.There is need to promote air conditioning systems that are run by renewable energy based power because of the environment threats and energy security negative issues associated with conventional fossil fuel – energy powered systems. The huge buildings’ cooling loads occur during periods of high solar insolation; this creates a huge potential of using solar powered cooling systems for air conditioning applications.However, the solar air conditioning systems still face a number of challenges in UAE which include; the availability of cheap electricity from fossil fuel resources and lack of government incentives to promote renewable energy resources. In order to understand the potential of applying solar cooling systems for air conditioning applications versus conventional systems, there was a need to experimentally and/or theoretically evaluate the performance of pilot solar cooling systems in UAE.In this project, the performance of a 10 TR solar cooling system in Ras Al Khaimah (RAK) Emirate of UAE was evaluated by both experiment and theoretical simulation. TRNSYS, a transient – systems simulation software that was developed by Solar Energy Laboratory – University of Winsconsin, was used for the purpose of the theoretical simulations of the system.The solar cooling absorption equipment used for this study is an R&D system that was developed by CSEM – uae in RAK for the purpose of assessing the potential of applying solar cooling systems in UAE. The solar cooling system is based on absorption chilling technology run by hot water produced by a field of evacuated tube solar collectors.Experimental results were compared with TRNSYS – theoretical simulations results and areas of possible improvements in the solar cooling system were recommended. Results of the study show that the solar cooling system runs with a COP in the range of 0.60 – 0.80, with an average COP of 0.70.It was also observed that the inlet cooling and hot water temperatures to the absorption chiller have a huge impact on the performance of the solar cooling system. A need to isolate the absorption chiller hot water circuit from the hot water stratified tank by incorporation of a heat exchanger between the chiller and the stratified tank was also identified. This will help to improve the degree of stratification during the operation of the solar cooling system.Theoretical performance evaluation of the system using a typical TMY2 weather data shows that the system can meet its cooling requirement for at least eight (8) months of the year. In conclusion, this study has indicated that solar cooling for air conditioning application in UAE has a huge potential. However, further research is necessary to enable improvement of the performance of solar cooling systems and to assess the possibility of commercialization of such systems.",Energy and Environment
"The aim of the project is to analyze the enlargement of the district heating line located in Gävle, evaluating the hydraulic facilities and calculating the heat losses with different insulation thicknesses to choose the best insulation thickness for the pipes. To choose the best thickness, different insulation thicknesses have been evaluated calculating the heat losses for each insulation thickness.To manage the heat losses problem, the pipe length has been divided into three stretches, underground pipe, sea pipe and air pipe. These three stretches have different boundary conditions, and each stretch has been calculated separately. The best thermal solution is choosing the insulation of 0.5m of thickness, but the best thermal solution is not the best solution for this project due to the elevated cost of this thickness in one of the stretches of the line.The pipe crossing the seahas to be on the bottom and to keep the pipe on the bottom concrete is going to be added. The quantity of concrete needed depends on the floatability of the pipe and specifically depends on the insulation thickness. The insulation is a porous material and its density is very small, therefore it has a high floatability.The final selection is a multi-thickness insulation, with different insulation thicknesses in the different stretches, 0.6m of thickness in the underground and air pipe and 0.3m of thickness in the sea pipe. With this configuration the heat losses are quite close to the optimum case. The purpose in the hydraulic study has been quantifying the start pressure in the new line to fulfil the energy demand in the worst point of the line.With 320kPa at the start of line, the pressure in the worst point is enough to fulfil the nowadays demand, 3MW, and in the future when this line will be enlarged and the demand increased to 20MW, the pressure at the start of the line to ensure the requested pressure of 250kPa in the worst point should reach more than 380kPa. Having such pressure is not recommended to avoid the pressure hammer and to build a new pumping station after the sea pipe is recommended.",Energy and Environment
"A nuclear power plant is a very complex dynamic system with a lot of built in regulators and security systems that make it almost impossible to know by reasoning,exactly how the system dynamics is going to react due to e.g. plant modifications,transients or operator behaviors. A common way to find out is to build a computer model and simulate the system.This study is about building a dynamic model of the steam system in the boiling water reactor Ringhals 1. The model has been developed in the modeling-/simulating software Dymola and the components are written in the programming language Modelica. The model contains the most critical components in the steam system from reactor tank to condenser and also the most important parts of the control systems.The final model has been compared to real power plant data from Ringhals 1 for full power operation, reduced power and a turbine trip. During steady state conditions the model has good compliance with the available data in most positions of the steam system.Due to absence of good data the results of the dynamic verification for the drop of load and turbine trip is incomplete. Instead the plausibility of the system behavior has been done. The results are good but the magnitudes of the transients are impossible to evaluate.Two major weaknesses have been found during the verification of the model. They are the turbine behavior during off-design load and various transients, and the control of the flow through the tube side of the reheater. The lack of mass flow data is also making it hard to fully trust the model.The final conclusion is that the steam system model is not ready to take on real problems, but it is a good basis for further development and utilization. The above mentioned problems have to be looked further into and depending on the intended usage of the model; it may be necessary to modify it to more exactly describe certain parts of the steam system.",Energy and Environment
"EGR (Exhaust Gas Recirculation) is a method for reducing NOx emissions for heavy-duty diesel engines. EGR works by introducing part of the exhaust gases back to the engine cylinders. Exhaust gases consists mainly of CO2, NOx, SO2 and H2O. As the temperature decreases, these gases form a corrosive condensate.The EGR components which are exposed to the condensate environment must therefore be of corrosion resistant materials. The objective of this study is to investigate suitable materials for use in exhaust condensate environment.The goal is to evaluate the pitting corrosion resistance for eight different commercial stainless steels and two commercial aluminium alloys in exhaust gas condensate environment. Furthermore, nitriding surface treatments on one martensitic stainless steel and anodising treatments on one aluminium alloy, were also included in this study.Five different exhaust gas condensates with different concentrations of sulfuric acid, nitric acid and chloride were chosen to perform electrochemical measurements. Two pH values 2.5 and 1.5; three chloride concentrations, 32 ppm, 200 ppm, 3300 ppm were included in the environmental parameters.The testing temperature was 60 oC, since it is the temperature which can still be expected to produce substantial amount of exhaust gas condensate in the EGR system. The electrochemical method used, was anodic polarisation measurements. This is a useful method to evaluate the pitting resistance for stainless steels in chloride containing solutions.The results show that the two aluminium alloys and the martensitic stainless steel were subjected to both general and pitting corrosion in a normal condensate solution at pH 2.5. The anodised film on the aluminium surface was not stable in condensate environments with low pH value. After twelve hours of exposure to a condensate at pH 2.5 at 60 oC, the protective effect of the lm became negligible.The austenitic, ferritic and duplex stainless steels show, however good resistance against both corrosion types. Increasing condensate acidity from pH 2.5 to 1.5 could not be observed to increase risk of pitting corrosion for the austenitic, ferric and duplex steel stainless steels.High concentrations of sulphuric acid, low pH value, but low chloride content (200 ppm) do not increase the risk for pitting corrosion for austenitic steels 1.4404 and 1.4301, duplex 2304 and ferritic 1.4521. However, chloride concentration of 3300 ppm, signficantly increased risk of pitting corrosion, especially for the austenitic stainless steels. Duplex stainless steel show better pitting resistance in high chloride environments, in addition to the good general corrosion resistance in low pH value environments.There is no dierence in corrosion resistance between the nitride coated 1.4112 steel and the steel without coatings. No dierences can be observed between the plasma and gas nitrided samples. Further investigation in less corrosive environment is recommended, since anodic polarisation is not a suitable method to study general corrosion behavior.The pitting corrosion resistance in condensates with high chloride concentrations at 60 oC follows the sequence 1.4301<1.4521<1.4404<duplex 2304<duplex LDX2404<duplex 2205. Clearly, duplex stainless steels have better pitting corrosion resistance in low pH environment when chloride concentration is increased. Considering the operating conditions of the EGR components, the element prices, it is probably more benecial to consider the duplex stainless steels for use in the EGR system.",Energy and Environment
"The aim of this project is to calculate how much energy could be saved in the School of Jädraås, in the municipality of Ockelbo. The objects of study were the lighting and the ventilation systems, not only because of the energy saving but due to the comfort also.After our study, the municipality wants to use our results to improve all their municipality buildings and save as much energy as it is possible in the whole municipality.We analyzed the hours when the ventilation system is working during the whole year, and we calculated how much energy could be saved if the amount of working hours were decreased or if new devices, as heat exchangers, were installed.In the lighting system part, the aim was not only the energy saving, but the comfort also. The currently lighting system is quite bad, specially in the dinning room, where bulbs are still lighting the room. These bulbs, anyways, should not be changed in the next ten years. The lighting system in the learning rooms is also old.Although there are fluorescent lamps already, some new lamps with lower energy consumption and better efficiency can be installed.",Energy and Environment
"This study was carried out in Woreta Zuria village, around Woraeta town, the capital of Fogera woreda with the objectives of evaluating of current status of traditional biomass energy utilization, assessment of biogas potential in the Amhara region and estimating the amount of biogas required to substitute the traditional biomass energy, including designing and description of a biogas plant.The major source of data for the analysis was the result of household survey conducted within Woreta Zuria village in which it was intended to be the beneficiary. The procedure employed in the survey was first that15 households were selected by systematic sampling method and primary data were collected by types and sources of energy for domestic use.Fuelwood and cattle dung cake were the most dominant traditional biomass fuel sources utilized by the households in the study area. For the average household with five members, fuelwood and dung cake consumption for cooking was 5.9 kg and 5.0 kg respectively while, the daily kerosene use was 0.13 liter.The intention of this study was to estimate the required biogas energy to replace the current use of the traditional biomass energy use. So, fresh dung was measured in each household for all normal sized sedentary adult cattle and it was found that daily average dung collected from single cattle was around 9 kg.In the household having 5 family members, the average overall energy consumed from all energy sources, including kerosene for lighting aggregates to 176.7 MJ. The equivalent amount of biogas to replace this traditional energy use for the household was estimated to 1.73 m3 n with daily input of 36 kg of fresh substrate (cow dung and human feces).The biogas plant to produce the same amount of biogas was designed to be 6 m3 with a total construction cost of 12007 ETB. This study shows that installing a 6 m3 biogas plant will have fuel related savings of about 2197 ETB per year, from both cooking and lighting fuel expenditures at household level. The annual bio-slurry produced per household from a 6 m3 volume biogas plant was estimated to be around 26280 kg, which has a financial value of 1703 ETB fertilizer benefit.The annual financial health benefits due to clean energy and improved sanitation of the biogas plant was aggregated to 674 ETB at the household level. In this study, the annual fuelwood, dung cake and kerosene saved was estimated to be 2154 kg, 1825 kg, and 47.43 liters respectively for the household. These savings can reduce 6.1 tons of CO2 emission and could save 0.36 ha of forest land that would have a total equivalent amount of 2795 ETB from car bon reduction and aforestation costs.The financial net present value of the biogas plant was 16201 ETB, while the economic net",Energy and Environment
"The present study is concerned with forced convection heat transfer in laminar and turbulent flow with nanofluids. Nanofluids are defined as a colloidal suspension of particles in a base fluid, where the particles have a characteristic length of less than 100 nm.Experiments were conducted to determine the qualification of nanofluids for laminar and turbulent flow forced convection heat transfer. The experiments were conducted in two different devices: Firstly, a stainless steel pipe with an inner diameter of 3.7 mm, heated directly by a DC current in the pipe wall, and secondly, a tubular heat exchanger, which the fluid was cooled down in.The tested nanofluids were not only assessed considering Nu/Re, as it has been found to be common in a short literature review, but also by taking into account the pressure drop indifferent ways. A way of considering pressure drop in non-dimensional quantities was introduced that had not been seen in literature.In some cases, an opposite assessment for the fluid could be found from comparing Nu/Re of base fluid and nanofluid and comparing h/Δp. Difficulties during validation of the test rig had called for system improvement; an extensive error investigation was conducted on the test rig and the calculation. The error investigation resulted in changes concerning the calculation and the test rig.",Energy and Environment
"Liquid Biofuels mainly Bioethanol and biodiesel are the main replacement for fossil fuels in the current world. But there are questions and concerns about the present biofuels production, mainly when it comes to matter of sustainability.In this thesis paper,Strategic Life Cycle Management data along with Life Cycle Analysis data has been used to analyze the sustainable biofuels condition in Sweden and the Netherlands. Data also has been collected through the interview from different stakeholders in Sweden and the Netherlands.",Energy and Environment
"The understanding of secondary flow behavior has become an important aspect in the design of modern gas turbines. Secondary flow gives rise to aerodynamic losses, distorts the thermal field and affects the flow conditions at the exit of a passage negatively.Therefore, reducing secondary flow is a major concern for efficiency improvement. Many passive control-methods have been suggested by turbine designers and researchers, and one very promising modification is blade leading edge contouring near the endwall.At the Division of Heat and Power Technology KTH, Stockholm, a detailed experimental investigation of three filleted nozzle guide vanes in an annular sector cascade has been performed, providing excellent experimental data for numerical validation of complex turbine flows.Based on the above, a numerical study and aerodynamic investigation for a leading edge filleted vane and baseline vane has been performed. The potential effect of the leading edge fillet on flow structure and secondary losses has been evaluated based on a number of flow parameters, and computational predictions have been compared to experimental results.The numerical investigation has shown some differences in the flow behavior between the filleted and baseline case. All results indicate that the fillet affects the flow structure in regions close to the hub endwall. It shifts the position of vortices and loss core. However, the overall effect on reducing secondary losses downstream of the passage is insignificant. Additionally, the numerical results show good qualitative agreement with experimental results.",Energy and Environment
"Wind power counts for roughly 3 % of the global electricity production. In the chase to produce greener power, much attention lies on getting more electricity from the wind, extraction of kinetic energy, with help of wind turbines.Wind turbines have been used for electricity production since 1887 and have since then developed into more efficient designs and become significantly bigger and with a higher efficiency.The operational conditions change considerably over the rotor length. Inner sections are typically exposed to more complex operational conditions than the outer sections. However, the outer blade sections have a much larger impact on the power and load generation. Especially here the demand for good aerodynamic performance is large.Airfoils have to be identified and investigated on mid/outer sections of a 7.0 MW rotor with 165 m diameter. Blade performance criteria were determined and investigations like sensitivity analysis were made. With the use of XFLR5 (XFoil) and Qblade, the airfoils were made into a blade and tested with the blade element momentum theory.This simulation gave detailed information regarding performance and operational loads depending on the different airfoils used. These results were then validated in a professional aero-elastic code (Flex5), simulating steady state, turbulent and wind shear conditions.The best airfoils to use from this reports airfoil catalogue are the NACA 63-6XX and NACA 64-6XX. With the implementation of these airfoils, blade design 2 and 3 have a very high performance coefficient compared to large commercial HAWT rotors.",Energy and Environment
"Buildings account for over 35% of the energy demand in OECD countries, making them a prime target for improvement. (EIA 2011) To help building owners reduce energy usage, ratings systems such as LEED have been developed.A prerequisite for certification is the demonstration of energy efficiency through computer modeling; however, the complex nature of building energy simulations too often leads to errors of up to 30% (Turner and Frankel 2008). One source of significant error can be the assumptions made of environmental conditions, which are often simplified to speed up simulations.To demonstrate the significance of active microclimate modeling, a building energy model combined with a microclimate model has been created in RadTherm, a commercial CAE thermal solver.Simulations are run using Passive House construction in three types of environments, and demonstrate an increase in energy demand over an annual time scale when microclimatic components are included.The increase in demand is less than 1%, however the decrease in radiant heat losses are up to 30%. Using the same methodology with revisions to the building construction and urban geometry, a larger increase in energy demand is expected.",Energy and Environment
"The Electricidade de Moçambique, E.P. (EDM) is the power utility in Mozambique, responsible to generate, transport and distribute electricity all over the country.The company has three gas turbines installed at Maputo Power Plant. All units burn diesel oil and are used only for back up. Currently only the unit #2 is available for operation.The main constraint that EDM faces is the high operation costs due to diesel price. Hence the company is considering converting units #2 and #3 to burn natural gas, resource available locally. The country is currently exporting natural gas to the neighbouring Republic of South Africa.This project calculates the power output of all gas turbines when burning natural gas and optimizes the power plant capacity by proposing modifications of the current power turbine cycles to allow sustainable operation.",Energy and Environment
"This study was provided by Scania AB. The objective of this thesis was to modify an application in the free Computational Fluid Dynamics software OpenFOAM to be able to handle spray and wall film modeling of a Urea Water Solution together with Conjugate Heat Transfer.The basic purpose is to widen the knowledge of the vaporization process of a Urea Water Solution in the exhaust gas after treatment system for a diesel engine by using OpenFOAM.First, urea has been modeled as a very viscous liquid at low temperature to mimic the solidication process of urea. Second, the development of the new application has been done. At last, test simulations of a simple test case are performed with the new application. The results are then compared with simplied hand calculations to verify a correct behavior of certain exposed source terms.The new application is working properly for the test case but to ensure the reliability, the results need to be compared with another Computational Fluid Dynamics software or more preferable, real experiments. For more advanced geometries, the continued development presented last in this thesis is highly recommended to follow.",Energy and Environment
"This paper deals with the cogeneration plant in Hässelby, Sweden and the district heating grid of north-western Stockholm. Before the background of the complex system of plants connected to the district heating grid and a volatile electricity market, the paper shows possible ways to optimise production at the Hässelby cogeneration plant by introducing additional heat storage.The pursued idea is to use heat storage to maximize electricity production during electricity peak price hours and store the excess heat for later supply. At the same time, heat storage can also be used to minimise production from more expensive heat plants. The situation is analysed by using the modelling and simulation software energyPRO.Based on the present value method, the evaluation implies a good investment potential for enlarging the existing heat storage. The conducted sensitivity analysis shows that the present value increases with growing storage capacity. The highest obtained present value is about 12,500,000€.",Energy and Environment
"This study deals with the performance calculations of a 9MW linear Fresnel CSP plant with direct steam generation built by the Solar Division of the CNIM Company. The aim was to calculate the annual electricity production taking into account the weather conditions as well as some steam storage.At first, a steam accumulator model was developed with Excel, in order to estimate the pressure evolution in the tanks during the charging, storage and discharging processes. The data obtained with this model was then integrated to the thermodynamic cycle model, programmed with Excel, which calculated the electrical power production knowing the thermal power available in the solar field.The electricity production calculations were made every 600 seconds during one year.To improve the results accuracy, the influence of the plant location slope was estimated, calculating the equivalent azimuth and elevation angles in a new spherical coordinates system. For an average slope of4.21° at the plant location, the annual thermal energy gain is 14.4% (with a gain up to 60% during winter days) and the annual electricity production is increased by 12.59%. The influence of frost on the mirrors during cold and humid nights was also estimated with a simple model of the energy needed to heat up a constant layer of ice.Depending on the assumptions, the electricity production losses were between 1.27 and 2.84% of annual electricity production. The losses due to plant shutdowns set by the electrical network manager RTE during the snow melt months were also estimated.The annual electricity production could decrease by 8.02 to 11.57 % because of the load management, depending on the days during which the plant is shutdown.Finally, an economic optimisation was led with prices estimated by CNIM, which gave an optimal solarfield design with 31 lines and 5 steam accumulators. The payback time would then be 9.887 years.",Energy and Environment
"The growing worldwide energy demand and the impacts of climate change due to anthropogenic greenhouse gases emissions are among the major issues facing humanity. The global energy system, responsible for most of the greenhouse gases emissions, is therefore at the heart of global concerns. In particular, the search for a reliable, sustainable and environmentally friendly means of generating electricity is a crucial matter, with growing worries about the scarcity of fossil resources, air pollution and water acidification.For these reasons, alternatives for the sustainable production of electricity are to be found.Among the plethora of alternatives available, concentrated solar power (CSP) appears as one of the most favourable options. The stability and dispatchability of production achievable by the integration of storage and fuel-solar hybridisation are amidst the major advantages of this technology.Nevertheless, conventional CSP plants are based on stream-turbine cycles which consume large amounts of water. In addition to the low thermodynamic efficiency of this type of cycle, the installation of such plants in water-scarce areas is complicated by their reliance on water resources. Thus, the study of new concepts that overcome these drawbacks is necessary for the future of this technology. The availability of high temperature solar receivers for solar tower systems opens the way for the use of gas-turbines in hybrid solar-natural gas configurations. In order to increase the efficiency of the cycle while keeping the water consumption as low as possible, a promising alternative to the recovery of the waste heat in steam-turbines is to use a low-temperature intercooled-recuperated gas-turbine cycle.This work focuses on the analysis and optimisation of the performance of an innovative hybrid solar gas-turbine power plant with an air-based bottoming cycle (ABHSGT). The evaluation considers thermodynamic performance, economic viability and environmental impact as interrelated concerns. With this in mind, detailed steady-state and dynamic models of the power plant have been developed and validated by comparison with existing components. A second model without bottoming cycle has been built for comparison. A multi-objective optimisation using an evolutionary algorithm has then been performed, optimising both capital cost and specific CO2 emissions and resulting in a Pareto-optimal set of possible designs.The analysis of the trade-off curves resulting from the optimisation reveals promising outcomes. The global minimum for the levelised cost of electricity, found at relatively high solar shares, proves the economic potential of the technology. The integration of the bottoming cycle decreases significantly the levelised cost of electricity and the CO2 emissions of the system compared to the reference plant, and higher efficiencies are achieved.The optimal design selected for an in-depth thermoeconomic and environmental analysis exhibits a levelised cost of electricity of 109 [USD/MWhe] for a solar share of 20% and an overall exergetic efficiency 38.5%. The specific CO2 emissions are reduced by 33% compared to simple gas-fired power plant. The water consumption is kept at very low levels compared to other CSP plants, making the system suitable for the deployment in water-scarce areas.In addition, the environmental impact induced by the land use requirements is considerably lower than that of other renewable energy technologies. The sensitivity analysis performed to assess the consequence of changes in varying financial conditions on the levelised cost of electricity and the net present value reveals that the system studied represents a profitable investment in the presence of feed-in tariffs.In the light of the performance obtained in the three aspects considered (thermodynamic, economic and environmental), it can be concluded that the ABHSGT represents a promising alternative to other renewable energy technologies, especially in water-scarce areas.",Energy and Environment
"Polygeneration systems attract attention recently because of their high efficiency and low emission compare to the conventional power generation technology. Three different polygeneration systems based on low temperature solid oxide fuel cell, atmospheric solid oxide fuel cell/ micro gas turbine, and pressurized solid oxide fuel cell/ micro gas turbine are mathematically modeled in this study using MATLAB (version 7.12.0.635).These systems are designed to provide space heating, cooling and hot domestic water simultaneously. This report provides the design aspects of such systems. Furthermore, the effects of some important operating properties on the polygeneration systems performance are investigated.",Energy and Environment
"In industry today, the need for excellent product development and realization in many different aspects is increasing. This calls for excellent quality, while at the same time time-to-market is increasingly important.A concurrent engineering (CE) approach is directed towards simultaneously developing different aspects of product realization in order to enhance both quality and speed. This thesis deals with the internal materials supply system (MSS) from a CE approach. Logistics aspects are often not dealt with until later stages of development, which leads to limitations in the possible solutions for the MSS. While designing a new production system, including MSS aspects early on in the project implies stating at an early stage what is required by the system. In order to aid the development of such requirements, this thesis aims at suggesting a structure for the requirements on the MSS where the relevant stakeholders of the system are involved. The thesis results are achieved through literature reviews and a case study at a manufacturing company in the automotive industryThrough literature reviews the thesis suggests a four-level hierarchic approach to requirements, considering four levels: stakeholder level, system level, sub system level and component level. This approach is supported by the case study, where stakeholders and requirements are analyzed and content and important aspects for the requirements specification in a current product realization project are considered. Through the case study, the thesis suggests a view of MSS stakeholders and a two-part structure for MSS requirements with a requirements specification matrix and a tree diagram. The requirements specification matrix contains the four suggested levels, where twelve different requirement categories are considered on each level. The stakeholder level considers the stakeholder requirements, which are translated into requirements on the system.The thesis results are considered to have the possibility of aiding the inclusion of MSS aspects at an early stage of product realization, and many different aspects are considered through the inclusion of all the relevant stakeholders in the study. The results are expected to be applicable in many different contexts. However, this need to be examined further and also the robustness of the results need to be established through further studies.",Material Science
"Tetrachloroethylene and its daughter-products represent a group of contaminations which are frequently found at sites with industrial activities, such as metal processing, electrotechnical and pharmaceutical industries as well as dry cleaning of clothing and the production of colours, paints and laquers.Due to their toxicity and persistence under natural conditions “denser-than-water” non aqueous phase liquids are substantial threats to the subsurface environment as well as the surface ecosystems including human beings. During the last two decades a number of technical solutions has been presented to enhance the situation of contaminated areas. One of the more recently established concepts are permeable reactive barriers.Permeable reactive barriers are passive in site treatment zones containing a reactive material suitable to remove the contamination from the groundwater. They are installed downgradient from the pollution source perpendicular to the groundwater flow direction to immobilise or degrade the dissolved pollutants in the groundwater as it flows through.This project was organised in two main parts. The first part assessed seven different iron powders in batch experiments to determine the most efficient powder in terms of degradation velocity. The second part of the study employed this powder in a column experiment using different mixing ratios with sand to evaluate its performance under simulated subsurface conditions in a permeable reactive barrier.The aim of this experiment was to obtain a more detailed description of the behaviour and performance of the selected material. In the batch experiment the most promissing iron powder produced a half-life of tetrachloroethylene of 2.36 h. The column study demonstrated that cis-dichloroethylene has the longest half-life compared to tetrachlorethylene and trichloroethylene with 1.65 h. Having the longest half-life of all chloroethylenes included in this investigation the cis-dichloroethylene concentration will determine the dimensioning of a permeable barrier for remediation purposes.",Material Science
"The deep mining and civil engineering industry need to perform rock stability analyses during excavation projects. The stability is mainly controlled by the shear strength of the rock fractures, which are the weakest point of the rock mass. In turn, the shear strength is governed by the mechanical properties of the fractures.It is both time and cost demanding to determine the properties of the rock fractures in laboratory. Also, the interpretation of the results requires a deep understanding of the normal and shear behaviour of rock fractures.This study aims to investigate if it is possible to determine the peak shear strength of rock fractures by merely estimating fracture parameters during field mapping and core logging.SKB supplied test results on drilled bore cores from site investigations in Forsmark and Laxemar for deep nuclear waste deposits. SKB generated data of high quality and in large quantity, which made it very valuable for the purpose of the study.The study begins with a literature review and an interaction matrix, clarifying the relationships between mechanical properties and affecting parameters of rock fractures. The predicted relationships of the parameters are then tested in an analysis based on the compiled data from SKB.The results show that the peak friction angle, the residual friction angle and the dilation angle are possible to approximate for open granite fractures in deep mining projects.Further on, the study proposes that the joint matching coefficient is included in the field mapping and core logging since it has a strong influence on the mechanical behaviour of the fracture, notably the normal and shear stiffness. Finally, the study questions estimations of JRC on small samples.",Material Science
"In the past decade significant advances have been made in the field of high performance concretes. The next generation of concrete, Ultra-High Performance Concrete (UHPC), exhibits exceptional strength and durability characteristics that make it well suited for use in highway bridge structures.This material can exhibit compressive strength of 28 ksi, tensile strength of 1.3 ksi, significant tensile toughness, elastic modulus of 7600 ksi, and minimal long-term creep or shrinkage. It can also resist freeze-thaw and scaling conditions with virtually no damage and is nearly impermeable to chloride ions.Prestressed highway bridge girders were cast from this material and tested under flexure and shear loadings. The testing of these AASHTO Type II girders containing no mild steel reinforcement indicated that UHPC, with its internal passive fiber reinforcement, could effectively be used in highway bridge girders.A large suite of material characterization tests was also completed. Based on this research, a basic structural design philosophy for bridge girder design is proposed.",Material Science
"Red mud, the main waste generated in aluminum and alumina production by the Bayer process, is considered hazardous due to its high pH, according to the Brazilian standard NBR 10004/2004, and worldwide generation of this waste exceeds 117 million tons/year.In this work, non-calcined red mud was used, thus requiring less energy and time and reducing costs, which is the ideal condition for reusing wastes. Mortars containing 30 wt. (%) of cement substituted by red mud showed higher strength of hardened products. The pozzolanic activity index was evaluated based on physical and mechanical parameters (Brazilian NBR 5751 and NBR 5752 standards) and on a chemical analysis (European EN 196-5 standard).A comparison of the reference mixture (without red mud) and the results obtained with red mud confirm the potential of non-calcined red mud for use a as pozzolanic additive in cementitious materials. The setting time (according to the MERCOSUL NM 65 standard) tends to increase but workability remains almost unchanged.",Material Science
"Concrete in Sweden has traditionally been manufactured with natural aggregate from glaciofluvial eskers. There is a need to preserve the remaining eskers because of their cultural value and importance for water filtration, thus natural aggregate has to be replaced. The most realistic alternative is to use crushed rocks. The major problem with crushed rocks in concrete production is the workability.This is because crushed rocks have less favorable properties. The fragments are flakier and have a rougher surface than natural aggregates that have been rounded in water. Without any amelioration of the crushed rock, to reach a certain workability and strength, the amount of cement in the mix has to be increased. Cement production requires large amounts of energy and the decarbonation of limestone releases large amounts of CO2. Combined, the release of CO2, due to burning and decarbonation of limestone, accounts for about 5% of the global CO2 emissions. An increase in cement consumptions is less desirable. Thus to replace natural aggregates, the use of crushed rocks has to be optimized as regard cement consumption.Several crushed aggregates, most from granitic rocks, from all over Sweden were analysed in this study. These crushed rocks were characterized according to their grading, specific surface, shape and petrography and compared to natural sand.Rheological tests that reveals the workability in detail was performed on mortars. The tests showed that as regard workability the 0-2 mm fraction is the most important factor. Further, the maximum aggregate size was gradually increased up to 16 mm, to have a more realistic approach to the concrete produced by the building industry.The results showed that with grading optimization and superplasticizer, some crushed rocks can be used for concrete production without increasing, and even decreasing, the cement consumption. This research also contemplated the use of filler. As a mineral admixture it can improve the compressive strength. It can also be used to replace cement; a replacement up to 20 kg/m3 of cement by filler can be done without significant effect on compressive strength.",Material Science
"Geosynthetics have become well established construction materials for geotechnical applications in most parts of the world. Because they constitute manufactured materials, new products and applications are developed on a routine basis to provide solutions to routine and critical problems alike.Results from recent research and from monitoring of instrumented structures throughout the years have led to new design methods for different applications of geosynthetics.Because of the significant breath of geosynthetics applications, this paper focuses on recent advances on geosynthetics products, applications and design methodologies for reinforced soil using geosynthetics reinforced walls.",Material Science
"This project has two major goals; first to develop scalable scripts for steady-state analysis, then to perform a case study on the dynamic properties of a vertical pile. The scripts are based on the numerical library PETSc for parallel linear algebra. This opens up the opportunity to use the scripts to solve large-scale models on supercomputers. The performance of the scripts are verified against problems with analytical solutions and the commercial software ABAQUS. The case study compares the numerical results with those obtained from an approximate solutionThe results from this study are verified scripts that can find a steady-state solution for linear-elastic isotropic solids on supercomputers. The case study has shown differences between numerical and semi-analytical solutions for a vertical pile. The dynamic stiffness show differences within reasonable limits but the equivalent viscous damping show larger differences. This is believed to come from the material damping in the soil that has been excluded from the approximate solution.These two results make it possible for further case studies on typical three-dimensional problems, that result in large-scale models, such as the dynamic properties of a slanted pile or pile-groups. The scripts can easily be expanded and used for other interesting research projects and this is the major outcome of from this study.",Material Science
"The history of timber buildings in Sweden entered a new era when the authorities decided to lift the ban on constructing more than two-storey timber buildings in Sweden. This change in legislation has contributed to the emergence of timber construction during the last decade.The Cross Laminated Timber (CLT) has become recognized as a new technology that used correctly in construction gives strong and reliable structures. The building material is gaining more credit day by day mainly due to the stiffness and strength it proved throughout the tests in projects where it was used.One of the projects that used CLT as load bearing elements was Limnologen in the city of Växjö 500 kilometres south of Stockholm. In this project, a system of CLT floors as well as CLT walls has been used. One of the challenges related to medium-rise timber buildings in general is to calculate and take account of the vertical displacement of the whole building. The sources for the displacements are instantaneous elastic as well as time dependent. In this project we are introducing two evaluation methods for the vertical displacements in Limnologen.The first is the experimentally measured vertical displacement that was performed by a group of researchers from Växjö University, and the second is a Finite Element Model simulating the vertical displacement according to the factors and parameters thought to be important to be included in the modelling. The output of the simulation was to be compared with the experimentally obtained values. Simulation is an important way to predict the vertical displacement in future CLT buildings. All modelling were done using the finite element software Abaqus.",Material Science
"One of mankind’s most important needs is the need for shelter. All around the world people live in lack of this basic need. Colombia is a South American country heavily burdened by civil war for many years. This has led to that many people have moved to the larger cities with large slum areas and bad living conditions.This thesis is aiming to give a solution to the problem with bad housing and it is performed in cooperation with Ankarstiftelsen. Ankarstiftelsen is a Swedish charity organisation that works with the suffering people in various places in Colombia.This thesis examines the possibility to build a house in a sandwich technique with a core of rigid plastic foam and a skin material of fibre reinforced plastic. The construction should be as easy as possible to manufacture, and the construction is also intended to be self carrying. The final proposition is to build the house using polyurethane rigid foam as the core, and a glass fibre reinforced polyester as the skin. This combination combines good mechanical behaviour with a relatively low price.Tests have been performed to evaluate the constructions ability to withstand some basic loads, with the help of computer aided engineering. The program that has been used to create a model is ProEngineer, and the application ProMechanica has been used to perform the analysis. The loads that have been tested are: gravity loads, wind loads, maintenance loads and earthquake loads.Colombia is located in the so called Pacific Ring of Fire, where earthquakes are a bitter reality. The Colombian building code is, as a result of this, much focused on the issue of earthquake safety. The Colombian building code has been used in order to create reliable earthquake testing models.The authors come to the conclusion that the house is possible to build with the given data. However, further investigations regarding manufacturing techniques and practical tests have to be made before the house can be built in reality.",Material Science
"While the increase in shear strength of Steel Fibre Reinforced Concrete (SFRC) is well recognized, it has yet to be found common application of this material in building structures and there is no existing national standard that treats SFRC in a systematic manner.The aim of the diploma work is to investigate the shear strength of fibre reinforced concrete beams and the available test data and analyse the latter against the mostpromising equations available in the literature. The equations investigated are: Narayanan and Darwish’s formula, the German, the RILEM and the Italian guidelines.Thirty articles, selected among over one hundred articles taken from literature, have been used to create the database that contains almost 600 beams tested in shear. This large number of beams has been decreased to 371 excluding all those beams and test that do not fall within the limitation stated for this thesis. Narayanan and Darwish’s formula can be utilized every time that the fibre percentage, the type of fibres, the beam dimensions, the flexural reinforcement and the concrete strength class have been defined.On the opposite, the parameters introduced in the German, the RILEM and the Italian guidelines always require a further characterization of the concrete (with bending test) in order to describe the post‐cracking behaviour. The parameters involved in the guidelines are the residual flexural tensile strengths according to the different test set-ups.A method for predicting the residual flexural tensile strength from the knowledge of the fibre properties, the cylindrical compressive strength of the concrete and the amount of fibres percentage is suggested. The predictions of the shear strength, obtained using the proposed method for the residual flexural tensile strength, showed to be satisfactory when compared with the experimental results.A comparison among the aforementioned equations corroborate the validity of the empirical formulations proposed by Narayanan and Darwish nevertheless only the other equations provide a realistic assessments of the strength, toughness and ductility of structural elements subjected to shear loading.Over the three investigated equations, which work with the post‐cracking characterization of the material, the Italian guideline proposal is the one that, due to its wide domain of validity and the results obtained for the gathered database of beams, has been selected as the most reliable equation.",Material Science
"The current interest in energy saving asphalt production techniques is great and several new processes have been developed to reduce the mixing and compaction temperatures for hot mix asphalt.In particular, mastic asphalt products (Gussasphalt) require high working temperatures, and harder requirements concerning bitumen fumes and carbon dioxide emissions have been introduced for such products. Consequently, the need of a new means of producing and placing mastic asphalt at lower temperatures is particularly large.One way of reducing asphalt mixture temperature is by using special flow improving additives like wax. This technique has successively been tried in several studies for polymer modified mastic asphalt used for bridge decks and parking areas in Sweden. However, there still are uncertainties about possible negative impact on crack susceptibility at lower temperatures due to the addition of wax.In this study, 4% montan wax (Asphaltan A) was used for one particular polymer modified mastic asphalt product. Type and amount of wax additive was selected based on results from earlier studies. The impact on binder, binder/filler mixtures and mastic asphalt from production was tested in the laboratory, focusing on low temperature performance.The bending beam rheometer (BBR) was used for determining low temperature creep compliance and the tensile stress restrained specimen test (TSRST) for determining fracture temperatures. Binder properties were determined using dynamic mechanical analysis (DMA), Fourier transform infrared (FTIR) spectroscopy and conventional tests (softening point, penetration, elastic recovery, Fraass breaking point, viscosity and storage stability). Aging was performed using the rolling thin film oven test (RTFOT) at 200°C.As expected, the addition of wax to the polymer modified binder showed a viscosity reduction at higher temperatures, corresponding to a similar positive effect of more than 10°C on production and laying temperature for the mastic asphalt. DMA and BBR results showed some increase in stiffness and a more elastic response of the wax modified binder at medium and low temperatures. The TSRST fracture temperature was 5 °C higher for the mastic asphalt containing 4% wax, indicating however no dramatic negative impact on crack susceptibility.",Material Science
"High magnitude earthquakes have devastating effects that leads to severe human and material losses; when affecting concrete gravity dams, seisms devastate the surrounding habitat through sudden release of reservoir. Dam safety is therefore a significant issue to be accounted in order to prevent the failure of dams located in seismic regions.The Baozhusi dam, the case study of this thesis, was exposed to 8.0 Ms (at the Mercalli scale) Wenchuan earthquake 2008 with intensity of (0.148 g) at the dam site. The earthquake intensity exceeded the design level of the dam (0.1 g); yet, the Baozhusi dam was not severely damaged as showed by tests. The present study case is a modeling and analyzing of the dynamical behavior of the Baozhusi dam during the earthquake duration.The results show that the horizontal component of the ground motion predominate the dynamic response of the dam. It is confirmed that the horizontal component of the ground motion crossed the dam at its axis and therefore minimizing the damages on the concrete gravity dam.",Material Science
"This report deals with the fire resistance of cross-laminated timber (CLT). The main purpose is to verify a new model on CLT and its ability to sustain its bearing capacity when exposed to fire.To establish this, a series of bending tests has been conducted in combination with fire exposure of the CLT. Two different series, with different dimensions, of beams were tested (series 1 and series 2).Four basic set-ups: CLT in tension or compression, either equipped with fire protective covering or not. Results from the tests has been gathered and evaluated to verify the theoretical model of the fire resistance. Evaluation was made through analysis of the residual cross-sections of the beams regarding charring depth and rate and moment of inertia (I).Results of the tests verify to a large extent the Design model. External problems and variations in the beams themselves caused some deviations.Analysis confirmed the CLT as being more similar to other laminated products such as Laminated Veneer Lumber (LVL) then homogenous solid beams.BothCLT and LVL experience delamination when exposed to fire resulting in an increased charring rate. The difference in rate when using Gypsum plaster as a protective barrier against the fire exposure is also equal to LVL.The results of the report will be used in the new version of the European Standard, Euro Code 5 and in the third edition of Fire Safe Timber Buildings.Charring rates proved to be less than expected but the CLTs ability to with standfire while keeping its bearing capacity",Material Science
"Wood-stud shear walls are commonly used to provide lateral stability against horizontal forces in wood houses. Therefore, accurate predictions of the deformation properties of shear walls are necessary in order to improve the design of wood frame houses against earthquake loading.The aim of this study is to increase damping capacity of wood-stud shear walls and hence improve wood frame houses resistance against earthquake.The starting point has been the laboratory experiments of nail joint’s deformation properties. Purpose of the experiments was to determine material properties of a nail joint. The material properties have later been used as material input data in the finite element (FE) model of wood-stud shear wall elements under alternating lateral loading.FE results have shown that wood-stud shear wall element’s damping capacity is mainly dependent on nail joints properties, number of nail joints, wall dimension and the use of middle studs.",Material Science
"The new pavement design methodology is based on mechanistic-empirical principles that are expected to be used in parallel with and eventually replace the current empirical pavement design procedures. The new mechanistic-empirical pavement design guide (MEPDG) requires greater quantities and quality of input data.Material characterization for the mechanistic-empirical approach, the focus of this study, is significantly more fundamental and extensive than in the current empirically-based AASHTO Design Guide. The objective of the study is to develop an organized database of material properties for the most common paving materials used in Maryland.A comprehensive material property database in Microsoft Access 2007 has been developed. The database is initially populated with all information received from SHA. It provides complete data management tools for adding and managing future data as well as data display screens for MEPDG. Recommendations for future material testing for Maryland are also provided.",Material Science
"Ultra High Performance Concrete (UHPC) is one of the newer and superior classes of concrete that can be used to develop improved bridges capable of meeting the present and future traffic, environmental, maintenance and economical requirements. Developing on the superior material properties of UHPC, the research discussed herein studies the behavior of UHPC when used as a bridge girder material.Four optimized girders have been cast and studied for various early age as well as long term properties such as early age shrinkage, transfer length, creep behavior and shrinkage under steam treatment. Data has been recorded through vibrating wire gages installed at strategic locations within each girder before they are cast.While the shrinkage and creep observed are very low which is characteristic of UHPC, various other aspects such as shrinkage being closely tied to formwork restraint and temperature and the prestress transfer being dependent on the girder geometry and strand pattern have been discussed. From the results we can conclude that UHPC is a promising bridge building material and with further research can be extensively employed for developing bridges.",Material Science
"Recently established EU environmental legislation obliged Sweden to close many landfills until year 2020. Such an operation requires a lot of inexpensive and water resistant coverage materials. Six prototypes of linings were constructed at Tveta landfill. Built coverage consisted mainly of residual products such as compost, sludge, fly and bottom ash. Between 2004 and 2007 water permeability through tested coverage was well below the maximum limit for non-hazardous waste.However, recent lysimeter records indicated increased permeability through the constructed linings. Readings of water infiltration were verified. Direct current (DC) resistivity, induced polarization (IP) and ground penetrating radar (GPR) were the methods applied in the research. The data was processed to present resistivity distribution in 2D pseudo-sections and 3D model. Resistivity measurements confirmed increased conductivity at the area with highest lysimeter readings. Unfortunately, GPR and IP output could not be used as reference information for DC resistivity readings.Constructed prototypes seemed to be suitable for coverage lining. Leakage was probably a result of minor mass transport along the slopes of the waste pile. It was recommended to prepare additional DC resistivity measurements to verify correctness of the processed 2D pseudo-sections and 3D model.",Material Science
"Our generation is about saving the earth, our one and only home. For centuries resources have been used without the consideration of tomorrow. Modernization contributed to today’s environmental issues such as climate change and greenhouse effects. Effects of past deeds have been seen and experienced. We are trying to correct these mistakes and this paper is all about that.Construction industry is a major contributor to these issues and sustainable building is one solution to aid these matters. This paper is about exploring the possibility of sustainable building in timber in Baguio City, Philippines.Considering the intensive development, rapid population increase and natural conditions, the city like most of the cities in the world is in need of sustainable building. This paper reviews modern green architecture and today’s durable timber construction design particularly suited for the city. There is of course a presentation of timber as sustainable material. To complement these reviews fieldwork in documentation on traditional and current sustainable building in timber of the city was performed.Discussions with the different Philippine organizations regarding the current use of timber as sustainable material were also completed in this work. While to recognize the current situation in Baguio City enquiry to Department of Environmental and Natural Resources-CAR was necessary. Visit and phone call survey of the availability of Benguet Pine, the most dominant timber, in local suppliers were made as well.For decades the Luzon Tropical Pine Forest has been exploited for its timber. These forests have not been sustainably managed. Logging (illegal and legal), regular fires and natural calamities are causes of forest destructions. These are the constraints of sustainable building in timber not only in the city but the whole country. There is now an on going forest rejuvenation and log banning. That is why Benguet Pine is not available in the market. Building in timber is expensive and very limited.The future success of the Department of Environmental and Natural Resources – CAR as well as the international and national NGOs in saving the forest and promoting Sustainable Forest Management will answer the availability of Benguet Pine for local timber production.The package of green architecture, combination of traditional and modern durable timber construction designs is the beginning of future Sustainable Building in timber in the City of Pines.",Material Science
"The objective of this report was to investigate means to rapidly dewater fine grained soils for immediate re-use as an emergency construction material. Dewatering using polymers was the primary thrust of the research. Secondary efforts were related to the use of geotextile tubes and equipment such as clarifiers to expedite dewatering of fine grained soil for immediate re-use as an emergency construction material.The dewatered soils are to be stabilized with cementitious materials prior to use, which is also addressed in this report. Test results indicated the approach was feasible, yet not the most practical approach for development of an emergency construction material. The research indicated emergency dewatering of contaminated sediments to be a more suitable application.Factors leading to this decision were largely related to portable equipment availability and polymer supply/demand in a disaster environment. Settling column testing incorporating polymers provided promising results and indicated polymer dosage requirements could be lessened for this application relative to optimum rates found from gravity flow drainage testing.",Material Science
"Dredged sediments are obtained from the process of dredging coastal areas and harbors in order to maintain navigable waterways. This study focuses on the potential of using dredged sediments as vertical cut-off wall backfill material.Materials used as vertical cut-off wall material are expected to have low hydraulic permeability and good workable characteristics. The Baltimore Harbor dredged sediments used for this study were plastic in nature and finer than the commonly encountered wall materials, and a research study was needed to evaluate their beneficial reuse in such an application.The objective of this study was to find an appropriate mix of sediment and bentonite that will be able to function as a vertical cut-off wall backfill material. The preliminary tests on the bentonite were carried out for screening purposes and to find an appropriate water content that will satisfy the desired viscosity range. Bentonite was then added to the dredged sediment in ratios of 1%, 2% and 3% of the total dredged sediment weight. The preliminary tests were repeated for each of these mixes to determine applicable trends and at what percentages of bentonite, the viscosity of the mixture was still in the workable range.The 1% bentonite mix was additionally modified with the addition of 5% and 8% fly ash by weight. These mixtures were then subjected to API filter press tests to determine the effect these mixes would have on the hydraulic conductivity. Adsorption testing was also carried out on the dredged sediment and all the mixes to determine their adsorption capacities to see if they can potentially be employed in reactive cut-off wall applications.The results show that a suitable moisture content and viscosity of the dredged sediments can be obtained that makes it usable in the mix design. Increased bentonite content, to the percent tested (3%), lead to a decrease in the hydraulic conductivity and increased fly ash content, to the percent tested (8%), lead to an increase in the hydraulic conductivity. For the metals tested, an increased bentonite content enhanced the adsorption capacity of the mix and an increased fly ash content diminished the adsorption capacity of the mix. With the appropriate mix design, dredged sediments can serve as an effective inhibitor to the flow of ground water and hence serve as an in-situ containment and remediation system.",Material Science
"This work is concerned with effect of material grade on fatigue strength of welded joints. Fatigue strength evaluation of welded joints in as welded and post weld treated condition was carried out with effective notch method. Results of peak stress method have also been compared with those of effective notch method for as welded joints.In addition, using the results of effective notch method, the effect of important weld and global geometry factors on notch stress concentration factor has been studied with 2-level design of experiment and a mathematical relation among stress concentration factor and the geometric factors has been proposed. Overall, thickness of the base plate and toe radius is found to be the most important factors determining fatigue strength of the joint.Welding induced residual stresses have also been predicted using 2D and 3D FEM analysis to see their effect on fatigue strength of the joints. Also, transversal residual stresses were measured using X-ray diffraction method to assess the accuracy of predicted results. Based on simulation results, effect of geometric factors on maximum value of transversal residual stress was also investigated.",Material Science
"Under TE 30, High Performance Concrete Pavement program, several states are undertaking a variety of innovative research in high performance concrete pavement materials and innovative design/construction features.This project addressed the needs of Maryland State Highway Authority in exploring the use of fiber reinforced and low shrinkage concrete in pavements. Past experience with these materials have indicated i) potential benefits in flexural fatigue resistance and reduction in crack development, and ii) potential reduction in slab warping effects with implications on pavement slab longevity.The objective of this study was to examine the design and lab performance of these materials for Maryland conditions, monitor their lab and field performance, and quantify potential benefits. Extensive fatique modeling was undertaken for developing the fatigue relationships and SN curves for these mixtures. In addition, finite element analysis (FEM) was used to model the behavior of these materials in field conditions and developing the base analytical model to be used in comparing future behavior and performance of the pavement test sections with these mixtures.",Material Science
"This study is an attempt to analyze and interpret the behavior of the two elements arsenic and phosphorus when released into the environment. Both of them may occur naturally in the environment but also may be added to the environment for certain purposes e.g. as pesticides and fertilizers respectively or through anthropogenic sources.When in excess, arsenic can be toxic to plants and organisms in the soil and some of it when leaches to groundwater or transported to surface water bodies through runoffs may pose a threat to aquatic organisms. Likewise, phosphorus when in excess result into eutrophication of surface water bodies and groundwater as well which has been a major problem in the Baltic Sea.In order to be able to predict their mobility a study on their chemical and physical characteristics under different conditions is important. The soil composition is an important aspect of nutrient management because some of the minerals present i.e. hydr(oxides) of aluminium and iron tend to hold and store both arsenic and phosphorus in the soil, while plant uptake and harvest may remove them (especially phosphorus) from the soil.This study was focused on Swedish agricultural soils and the samples for investigation were collected from two locations, one is Broknäs from which samples were collected from different horizons i.e. A 0-30 cm, C 60-90 cm and C 47-67 cm samples from an area known as Bogesundslandet, NE of Stockholm (59°24’N, 18°18’E) and E21:2 was collected from the county of Östergötland (58°27’N,14°57’E), southern Sweden not far from Lake Vättern, from where the A horizon was collected. Batch experiments were performed to check pH and concentration dependence of the sorption/desorption of As and P.Two varieties of the Freundlich equation (Basic and Competitive) were used to model the results obtained. It was observed that the dependence of arsenate and phosphate sorption/desorption on pH show a similar but not identical trend for both anions. At low pH, the dependence of dissolved P and As did not agree, for unknown reasons.Possibly, the low pH value may mobilize otherwise un-reactive P that at higher pH are blocked by some aluminium/iron precipitate. The Freundlich modeling results showed that there is direct competitive adsorption between As and P ions, at least in the A horizon. However use of the competitive Freundlich equation did not result in meaningful results in the C horizon, which may indicate different As and P sorption mechanisms. However, further studies on this are recommended.",Material Science
"EGR (Exhaust Gas Recirculation) is a method for reducing NOx emissions for heavy-duty diesel engines. EGR works by introducing part of the exhaust gases back to the engine cylinders. Exhaust gases consists mainly of CO2, NOx, SO2 and H2O. As the temperature decreases, these gases form a corrosive condensate.The EGR components which are exposed to the condensate environment must therefore be of corrosion resistant materials. The objective of this study is to investigate suitable materials for use in exhaust condensate environment.The goal is to evaluate the pitting corrosion resistance for eight different commercial stainless steels and two commercial aluminium alloys in exhaust gas condensate environment. Furthermore, nitriding surface treatments on one martensitic stainless steel and anodising treatments on one aluminium alloy, were also included in this study.Five different exhaust gas condensates with different concentrations of sulfuric acid, nitric acid and chloride were chosen to perform electrochemical measurements. Two pH values 2.5 and 1.5; three chloride concentrations, 32 ppm, 200 ppm, 3300 ppm were included in the environmental parameters.The testing temperature was 60 oC, since it is the temperature which can still be expected to produce substantial amount of exhaust gas condensate in the EGR system. The electrochemical method used, was anodic polarisation measurements. This is a useful method to evaluate the pitting resistance for stainless steels in chloride containing solutions.The results show that the two aluminium alloys and the martensitic stainless steel were subjected to both general and pitting corrosion in a normal condensate solution at pH 2.5. The anodised film on the aluminium surface was not stable in condensate environments with low pH value. After twelve hours of exposure to a condensate at pH 2.5 at 60 oC, the protective effect of the lm became negligible.The austenitic, ferritic and duplex stainless steels show, however good resistance against both corrosion types. Increasing condensate acidity from pH 2.5 to 1.5 could not be observed to increase risk of pitting corrosion for the austenitic, ferric and duplex steel stainless steels.High concentrations of sulphuric acid, low pH value, but low chloride content (200 ppm) do not increase the risk for pitting corrosion for austenitic steels 1.4404 and 1.4301, duplex 2304 and ferritic 1.4521. However, chloride concentration of 3300 ppm, signficantly increased risk of pitting corrosion, especially for the austenitic stainless steels. Duplex stainless steel show better pitting resistance in high chloride environments, in addition to the good general corrosion resistance in low pH value environments.There is no dierence in corrosion resistance between the nitride coated 1.4112 steel and the steel without coatings. No dierences can be observed between the plasma and gas nitrided samples. Further investigation in less corrosive environment is recommended, since anodic polarisation is not a suitable method to study general corrosion behavior.The pitting corrosion resistance in condensates with high chloride concentrations at 60 oC follows the sequence 1.4301<1.4521<1.4404<duplex 2304<duplex LDX2404<duplex 2205. Clearly, duplex stainless steels have better pitting corrosion resistance in low pH environment when chloride concentration is increased. Considering the operating conditions of the EGR components, the element prices, it is probably more benecial to consider the duplex stainless steels for use in the EGR system.",Material Science
"Nowadays, timber is widely used in construction industry thanks to its availability and good properties. The use of solid (sawn) timber is not always proper since it is only available up to certain dimensions. Therefore, the so-called Engineered Wood Products (EWPs) have been introduced to cope with the different design needs of structures.The Glued laminated Timber (glulam) is a type of EWPs that consists of smallsections of timber laminates glued together to form beams and columns. Glulam can be manufactured in almost any size and shape; it can also be tapered or notched. However, notching a beam at its end leads to a stress concentration at the re-entrantcorner of the notch due to the sudden change in the notched beam’s cross section. The concentration of shear and tensile stresses perpendicular to the grain can lead to a catastrophic brittle failure caused by the crack propagation from the notch corner.Crack opening due to tensile stresses perpendicular to grain is the most common failure at the notch corner and it is always taken into design consideration. However,shear component is usually exists and must be also considered in design to guarantee the safety of the structure. Currently, only the normal forces perpendicular to the beam’s axis are considered in the design of the reinforcement in design handbooks. The aim of this thesis was to study the structural behavior of notched glulam beams reinforced by adhered plywood panels and FRP. The carrying capacity of the notched glulam beams at their ends is the main subject of this project.",Material Science
"A quadrotor is a helicopter with four rotors placed at equal distance from the crafts centre of gravity, controlled by letting the different rotors generate different amount of thrust. It uses various sensors to stay stable in the air, correct readings from these sensors are therefore critical.The purpose of this project is to analyse the feasibility of a quadrotor camera surveillance system by optimizing the handling of vibrations, video signal and external disturbances for a quadrotor and by reducing vibrations, electromagnetic interference and external disturbances the quadrotor’s stability can increase.The quadrotor will be flown through first person view and should be able to hover at 10 meters altitude in a radius of 3 meters. Only sensor readings will be optimized, not data processing. The flight controller used will be a MultiWii Pro which has an accelerometer, a gyroscope, a magnetometer, a GPS and a barometer. Balancing motors and applying vibration dampening material between the motors and the frame vibrations were reduced by 73 %. Electromagnetic interference to the magnetometer was made negligible when the magnetometer had a distance of 3 cm from the power circuit. Video signal was improved by applying a LC-filter. Isolating the barometer improved calculations for the altitude. The quadrotor’s position could be locked within a radius of 4 meters and its altitude could be locked in an interval of 2 meters. The quadrotor cannot be considered stable enough for automatic camera surveillance, however with software improvement it could be.",Signal Processing
"This master’s thesis examines whether it is possible to improve an existing road grade estimator by measuring an additional signal from a GPS receiver. The existing estimator uses the differentiated altitude signal from the GPS to estimate the current road grade.The additional signal is the vertical component of the 3D-velocity that is reported by the GPS. By using spectral analysis together with system identification the additional signal, which is based on velocity information, is compared to the previously used signal which is based on position information (altitude).By sampling data from an experiment at Swedish highway E4 it was possible to conclude whether the two signals should be used together (sensor fusion) or if it was better to use just one of them.The signals’ measurement errors were not white noise but they were modeled as autoregressive (AR) processes. An augmented Kalman filter, with the two AR models included in the system model, was used to evaluate the performance of the sensor fusion algorithm.The result of the thesis is that the previously used signal, the one based on differentiated altitude, should be used alone in this specific road grade estimator. The major reason for this is that the additional signal proved to have a bias that would have been integrated by the road grade estimator and driven the estimation of the altitude away from the true altitude.A solution for this problem would be to neglect this bias and construct a road grade estimator that does not include the altitude as a state.",Signal Processing
"In mobile communications, channel side information at transmitters can increase capacity. For moving relays nodes, local nodes placed on buses and trams in urban areas, the channel state information is outdated for control delays of several milliseconds, as in the LTE system.Prediction of the channel based on statistic is not adequate for vehicular velocities. In this thesis, prediction made with an additional antenna, a “predictor antenna”, placed in front of the main antenna is evaluated.The predictor utilizes that the channel of the predictor antenna is highly correlated to the channel experienced by the main antenna somewhat later, when the main antenna has moved to the position previous occupied by the predictor antenna.A normalised correlation of up to 0.98 could be measured between the channels of the antennas for an antenna separation of several wavelengths, but it was found that the close environment and the antenna pattern have a big impact on the correlation.The predictions made with the antenna are also combined with predictions based on statistics of past measurements from the main antenna to see if a better result can be achieved. For a prediction range of 0.5 carrier wavelengths, a prediction as good as a normalised mean square error (NMSE) of -13.9 dB could be seen.This is sufficient to give a gain in the performance when using link adaptation and opportunistic multi-user scheduling, based on channel state information at transmitter. The evaluations is based on measurements on a 20 MHz downlink channel at 2.68 GHz.",Signal Processing
"MMS-enabled terminals on the market today are very complicated to use. It takes several steps to create a multi-slide MMS-message with images and text. This discourages users from using it.To increase usage of MMS, several companies provide web-based or stand-alone programs that allow users to create and send MMS-messages from a regular computer. However these editors have many limitations and are not user-friendly.This project describes the design and implementation of a user-friendly web-based MMS-portal where users can create, edit and send MMS-messages. The portal is integrated into Densitet’s system for development of mobile services.Conclusions that can be draw from this work are that problems with MMS interoperability have mostly the poor standardization to blame. Different terminals support different types of images and sound formats, and to make the MMS-portal user-friendly, format conversions of uploaded content had to be implemented. Also the MMS-portal only supports basic MMS-functionality.If the MMS-specification includes more audio and image formats and if the MMS-terminals are upgraded to handle these formats, sending MMS-messages will be easier and mobile messaging will continue to grow.",Signal Processing
"The Internet has become a valuable channel for both business-to-consumer and business-to-business e-commerce. It has changed the way for many companies to manage the business. Every day, more and more companies are making their presence on Internet.Web sites are launched for online shopping as web shops or on-line stores are a popular means of goods distribution. The number of items sold through the internet has sprung up significantly in the past few years. Moreover, it has become a choice for customers to do shopping at their ease.Thus, the aim of this project is to design and implement a consumer to consumer application for Facebook, which is one of the largest social networking website. The application allows Facebook users to use their regular profile (on Facebook) to buy and sell goods or services through Facebook. As we already mentioned, there are many web shops such as eBay, Amazon, and applications like blocket on Facebook.However, none of them is directly interacting with the Facebook users, and all of them are using their own platform. Users may use the web shop link from their Facebook profile and will be redirected to web shop. On the other hand, most of the applications in Facebook use notification method to introduce themselves or they push their application on the Facebook pages.This application provides an opportunity to Facebook users to interact directly with other users and use the Facebook platform as a selling/buying point. The application is developed by using a modular approach. Initially a Python web framework, i.e., Django is used and association rule learning is applied for the classification of users’ advertisments. Apriori algorithm generates the rules, which are stored as separate text file. The rule file is further used to classify advertisements and is updated regularly.",Signal Processing
"Permittivity is an important property of dielectric materials. By measuring the permittivity of a material, it is possible to obtain information about the material’s physical and chemical properties, which are of great importance to many applications.In this study, a realtime control system for a frequency-response (FR) permittivity sensor was developed. The core of the hardware was a kitCON167 microcontroller (PHYTEC America, LLC), which controlled and communicated with peripheral devices.The system consisted of circuits for waveform generation, signal conditioning, signal processing, data acquisition, data display, data storage, and temperature measurement. A C program was developed in the TASKING Embedded Development Environment (EDE) to control the system.The control system designed in this study embodied improvements over a previously designed version in the following aspects: 1) it used a printed circuit board (PCB); 2) the measurement frequency range was extended from 120 MHz to 400 MHz; 3) the resolution of measured FR data was improved by using programmable gain amplifiers; 4) a data storage module and a real-time temperature measurement module were added to the system; 5) an LCD display and a keypad were added to the system to display the FR data with corresponding frequencies and to allow users to enter commands.Impedance transformation models for the sensor probe, the coaxial cable that connects the control system with the sensor probe, and the signal processing circuit were studied in order to acquire information on the permittivity of measured materials from measured FR data. Coaxial cables of the same length terminated with different loads, including an open circuit, a short circuit, a 50 resistor, and a 50 resistor paralleled by a capacitor, were tested. The results indicated that the models were capable of predicting the impedances of these specific loads using the FR data. Sensor probes with different sizes and coaxial cables with two different lengths terminated with the same sensor probe were also tested. The results were discussed.Additional tests for the gain and phase detector were conducted to compare FR data measured by the gain and phase detector with those observed on an oscilloscope. The results were discussed.",Signal Processing
"The study purpose is to be implementing a system where a sweeping signal generator connected to a scalar network analyzer (SNA). The SNA is a less complicated that the VNA and normally much cheaper.Between these two instruments only the cable fro synchronization between then needed. The synchronization signal is simply low frequency saw tooth signal not so sensitive for disturbance as RF signal. Therefore a very simple cable can be used.For my part of the project is that use the PC to control the SNA and acquire the data from the SNA. The method is that connect PC with the SNA by GPIB table, then use the Labview to identify the SNA, and build the control driver, use the command code to control and acquire data from the SNA, store the data.",Signal Processing
"Starting from Maxwell’s equations, we derive a sensor model for three-axis magnetometers suitable for localization and tracking applications. The model depends on the relative position between the sensor and the target, orientation of the target and its magnetic signature.Both point targets and extended target models are provided. The models are validated on data taken from various road vehicles.The suitability of magnetometers for tracking is analyzed in terms of local observability and Cramér Rao lower bound as a function of the sensor positions in a two sensor scenario. Also the signal to noise ratio is computed to determine the effective range of the magnetometer.Results from field test data indicate excellent tracking of position and velocity of the target, as well as identification of the magnetic target model suitable for target classification.",Signal Processing
"The need for RF spectrum for the rapidly growing broadband access services is evident. Cognitive radio is an emerging technology that aims to introduce secondary usage of the spectrum resources without interfering with the primary usage of the licensed users but with a lower priority.Signal detection for cognitive radios has drawn a lot of interest in the research community, where different algorithms are suggested. The most commonly used algorithms are energy detection, feature detection, eigen value based detection. Energy detection is the simplest and most common way to detect signals.It has fast sensing time but poor performance. The feature detection and eigenvalue based detection methods are more sophisticated and offer better performance but they are more complex and expensive. This thesis will present the pros and cons of each method and offer comparisons between them.To evaluate the performance of different algorithms used in cognitive radio, different research testbeds have been suggested in the literature. Some of the most frequently used testbeds are based on GNU-radio, WARP, or BEE2. GNU-radio is the simplest testbed and is free, but it has low bandwidth and poor performance.WARP and BEE2 are more advanced testbeds. They offer good performance and are easy to update, but they are more complex and expensive. These three testbeds will be described, compared, and their advantages and disadvantages will be observed in this thesis.",Signal Processing
"Most mobile video-recording devices of today, e.g. cell phones and music players, make use of a rolling shutter camera. A rolling shutter camera captures video by recording every frame line-by-line from top to bottom of the image, leading to image distortions in situations where either the device or the target is moving. Recording video by hand also leads to visible frame-to-frame jitter.In this study, methods to decrease distortion caused by the motion of a video-recording device with a rolling shutter camera are presented. The methods are based on estimating the orientation of the camera from gyroscope and accelerometer measurements.The algorithms are implemented on the iPod Touch 4, and the resulting videos are compared to those of competing stabilization software, both commercial and free, in a series of blind experiments. The results from this user study shows that the methods presented in the study perform equal to or better than the others.",Signal Processing
"In nearly all modern tracking systems, signal processing is an important part with state estimation as the fundamental component. To evaluate and to reassess different tracking systems in an affordable way, simulations that are in accordance with reality are largely used. Simulation software that is composed of many different simulating modules, such as high level architecture (HLA) standardized software, is capable of simulating very realistic data and scenarios.A modular and general-purpose state estimation functionality for ﬁltering provides a profound basis for simulating most modern tracking systems, which in this work is precisely what is created and implemented in an HLA-framework. Some of the most widely used estimators, the iterated Schmidt extended Kalman ﬁlter, the scaled unscented Kalman ﬁlter, and the particle ﬁlter, are chosen to form a toolbox of such functionality.An indeed expandable toolbox that offers both unique and general features of each respective ﬁlter is designed and implemented, which can be utilized in not only tracking applications but in any application that is in need of fundamental state estimation. In order to prepare the user to make full use of this toolbox, the ﬁlters’ methods are described thoroughly, some of which are modiﬁed with adjustments that have been discovered in the process.Furthermore, to utilize these ﬁlters easily for the sake of user-friendliness, a linear algebraic shell is created, which has very straight-forward matrix handling and uses BOOST UBLAS as the underlying numerical library. It is used for the implementation of the ﬁlters in C++, which provides a very independent and portable code.",Signal Processing
"Signal processing in advanced radar systems requires high computation performance. Therefore, Multicore processor architectures are of increasing interest for science and industry, as an enabling technology for the implementation of radar signal processing.Four versions of multicore processors studied in this thesis: 1) 8 cores with 1 shared cache, 2) 8  cores with 8 private caches, 3) 32 cores with 1 shared cache, and 4) 32 cores with 32 private caches.The focusing of this study is to evaluate the performances of their memory architectures. The studied multicore architectures have been simulated using the ThreadSpotter tool and using threads as abstraction for concurrently executing cores.In order to evaluate the cache architectures of the studied set of processors, we use four benchmarks, (Tilted Memory Read, Cubic  interpolation, Bi-cubic interpolation and Covariance matrix estimation in STAP), based on HPEC, (High Performance Embedded Computing), Challenge Benchmark Suite.These benchmarks have been chosen to simulate different kinds of memory access patterns in radar signal processing. The original benchmark code has been modified and implemented using OpenMP.The selected benchmarks have been analysed using the ThreadSpotter tool. Conclusions have been drawn according to some indicators, for instance the Fetch Ratio and the Fetch Utilization, which is generated by the ThreadSpotter.The processor with 8 cores and private caches achieved the best  performance thanks to its private cache that can avoid some race conditions and false sharing effects. The processor with 32 cores and private caches obtained the worst performance during almost all the experiments, due to its smaller private caches, which do not have enough capacity to hold useful cache lines.",Signal Processing
"The purpose of this study was to automatically track an Unmanned Aerial Vehicle (UAV), with an electronically steered antenna. To make it possible to track the UAV during flights, a 2.4 GHz transmitter was mounted on the aircraft.Due to the regulations of transmitted signal power and the fact that a very powerful transmitter would consume to much power, a 10 mW transmitter was used during development. With such a weak transmitter a high gain antenna (a reflector antenna in this case) is required, in the receiver, to detect the transmitted signal at far distances.To be able to detect movement of the UAV, four small Yagi-antennas are mounted around the focal point of the reflector disc antenna. The received signal strength in the four Yagi-antennas will vary depending on where the transmitter (UAV) is located relative to the tracking device. By comparing the strength of these signals using a microcontroller, the direction of the UAV can be computed and in turn the antenna can be",Signal Processing
"Image processing is the field of signal processing where both the input and output signals are images. Images can be thought of as two-dimensional signals via a matrix representation, and image  processing can be understood as applying standard one-dimensional signal processing techniques to  two-dimensional signals.Image processing is a very important subject, and finds applications in such fields as photography, satellite imaging, medical imaging, and image compression, just to name a few. In the past, image processing was largely done using analog devices. However, as computers have become more powerful, processing shifted toward the digital domain.Like one-dimensional digital signal processing, digital image processing overcomes traditional analog “problems” such as noise, distortion during processing, inflexibility of system to change, and difficulty of implementation. The image processing technique we will be implementing will be",Signal Processing
"Simultaneous Localization And Mapping (SLAM) is a process of mapping an unknown environment and at the same time keeping track of the position within this map. In this theses, SLAM is performed in a marine environment using radar images only.A SLAM solution is presented. It uses SIFT to compare pairs of radar images. From these comparisons, measurements of the boat movements are obtained. A type of Kalman filter (Exactly Sparse Delayed-state Filter, ESDF) uses these measurements to estimate the trajectory of the boat. Once the trajectory is estimated, the radar images are joined together in order to create a map.The presented solution is tested and the estimated trajectory is compared to GPS data. Results show that the method performs well for at least shorter periods of time.",Signal Processing
"With the development of mobile (specifically: wide area cellular telephony) technology, users’ requirements have changed from the basic voice service based on circuit switch technology to a desire for high speed packet based data transmission services.Voice over IP (VoIP), a packet based service, is gaining increasing attention due to its high performance and low cost. However, VoIP does not work well in every situation. Today Network address translation (NAT) traversal has become the main obstruction for future VoIP deployment.In this thesis we analyze and compare the existing NAT traversal solutions. Following this, we introduce a VoIP over IPSec (VOIPSec) solution (i.e., a VoIP over IPSec virtual private network (VPN) scheme) and an extended VOIPSec solution mechanism. These two solutions were tested and compared to measure their performance in comparison to a version of the same Session Initiation Protocol (SIP) user agent running without IPSec.In the proposed VOIPSec solution, the IPSec VPN tunnel connects each of the SIP clients to a SIP server, thus making all of the potential SIP participants reachable, i.e., solving the NAT traversal problem. All SIP signaling and media traffic for VoIP calls are transmitted through this prior established tunnel. This VPN tunnel provides the desired universal means for VoIP traffic to traverse NAT equipment. Additionally, the IPSec VPN also guarantees the security of VoIP calls at the IP level.In order to improve the security level of media streams for the VOIPSec solution, we deployed and evaluated an extended VOIPSec solution which provides end-to-end protection of the real time media traffic. In this extended VOIPSec solution, we used SRTP instead of RTP to carry the media content. This extended method was shown to provide all of the advantages of VOIPSec and SRTP without any additional delay for the media traffic (as compared to the VoIPSec solution).Note that the solution proposed in this thesis may be of limited practical importance in the future as more NATs become VoIP capable; but the solution is currently essential for facilitating the increasing deployment of VoIP systems in practice. For VoIP calls that do not need end-to-end security, we recommend the use of the VOIPSec solution as a means to solve the NAT traversal problem and to protect traffic at the IP level.When application to application security is not needed we prefer the VOIPSec solution to the extended VOIPSec solution for the following reasons: (1) our test results show that the time for call setup for the extended VOIPSec solution is twice time the time needed for the VOIPSec solution and the extended VOIPSec solution requires the use of user agents that support SRTP.While, the VOIPSec solution does not require a special user agent and all VoIP clients in the market are compatible with this solution. However, when more SIP user agents add support for SRTP, the extended VOIPSec solution will be applicable for users of these SIP user agents.",Signal Processing
This degree project deals with Wavelet transform and Karhunen-Loeve transform. Through the mathematic description to understand and simulation to investigate the denoise ability of WT and the de-correlation ability of KLT. Mainly prove that the new algorithm which is the joint of these two algorithms is feasible.,Signal Processing
"Sensor nodes forming a network and using wireless communications are highly useful in a variety of applications including battle field (military) surveillance, building security, medical and health services, environmental monitoring in harsh conditions, for scientific investigations on other planets, etc.But these wireless sensors are resource constricted: limited power supply, bandwidth for communication, processing speed, and memory space. One possible way of achieve maximum utilization of those constrained resource is applying signal processing and compressing the sensor readings.Usually, processing data consumes much less power than transmitting data in wireless medium, so it is effective to apply data compression by trading computation for communication before transmitting data for reducing total power consumption by a sensor node. However the existing state of the art compression algorithms are not suitable for wireless sensor nodes due to their limited resource.Therefore there is a need to design signal processing (compression) algorithms considering the resource constraint of wireless sensors. In our work, we designed a lightweight codec system aiming surveillance as a target application.In designing the codec system, we have proposed new design ideas and also tweak the existing encoding algorithms to fit the target application. Also during data transmission among sensors and between sensors and base station, the data has to be secured. We have addressed some security issues by assessing the security of wavelet tree shuffling as the only security mechanism.",Signal Processing
"Mapping is a central and common task in robotics research. Building an accurate map without human assistance provides several applications such as space missions, search and rescue, surveillance and can be used in dangerous areas.One application for robotic mapping is to measure changes in terrain volume. In Sweden there are over a hundred landfills that are regulated by laws that says that the growth of the landfill has to be measured at least once a year.In this project, a preliminary study of methods for measuring terrain volume by the use of an Unmanned Aerial Vehicle (UAV) and a Light Detection And Ranging (LIDAR) sensor is done. Different techniques are tested, including data merging strategies and regression techniques by the use of Gaussian Processes. In the absence of real flight scenario data, an industrial robot has been used for data acquisition.The result of the experiment was successful in measuring the volume difference between scenarios in relation to the resolution of the LIDAR. However, for more accurate volume measurements and better evaluation of the algorithms, a better LIDAR is needed.",Signal Processing
"Accurate measurements from sensors measuring the vehicle’s lateral behavior are vital in today’s vehicle dynamic control systems such as the Electronic Stability Program (ESP). This thesis concerns accurate plausibilisation of two of these sensors, namely the yaw rate sensor and the lateral acceleration sensor.The estimation is based on Kalman filtering and culminates in the use of a 2 degree-of-freedom nonlinear two-track model describing the vehicle lateral dynamics. The unknown and time-varying cornering stiffnesses are adapted while the unknown yaw moment of inertia is estimated.The Kalman filter transforms the measured signals into a sequence of residuals that are then investigated with the aid of various change detection methods such as the CuSum algorithm. An investigation into the area of adaptive thresholding has also been made.The change detection methods investigated successfully detects faults in both the yaw rate and the lateral acceleration sensor. It it also shown that adaptive thresholding can be used to improve the diagnosis system. All of the results have been evaluated on-line in a prototype vehicle with real-time fault injection.",Signal Processing
"Diagnosis based on vibration analysis is a method that has many benefits to offer. It is easy to implement the method on existing transmissions by attaching accelerometers outside the gearbox housing. If you have knowledge of the gearbox geometry, such as number of tooth on the gears and types of bearings, and any unwanted frequencies can be filtered out a good estimation of the gearbox condition can be achieved.In this project a number of condition indicators have been tested to identify and isolate different faults that may appear. All analysing have been done in the time domain on different synchronously averaged signals. The condition indicators have been used together with diagnosis theory from the division of Vehicular systems to create a diagnosis system able to find faults on a number of modelled signals.",Signal Processing
"A Low power fully operational digital hearing aid chip is proposed and implemented. The Σ-∆ ADC adopts the status controller to realize adaptive SNR technique without any external control.To achieve both low power consumption and high programmability, dedicated low power DSP with 6 control parameters is designed. The heterogeneous Σ-∆ DAC reduces more power dissipation without performance degradation. The digital hearing aid system is fabricated in 0.18 µm CMOS technology, consumes less than 96 µW and has a die size of 2.8 mm x 1.1 mm.Introduction:",Signal Processing
"Sudoku is a discrete constraints satisfaction problem which is modeled as an under determined linear system. This report focuses on applying some new signal processing approaches to solve sudoku and comparisons to some of the existing approaches are implemented.As our goal is not meant for sudoku only in the long term, we applied approximate solvers using optimization theory methods. A Semi Definite Relaxation (SDR) convex optimization approach was developed for solving sudoku.The idea of Iterative Adaptive Algorithm for Amplitude and Phase Estimation (IAA-APES) from array processing is also being used for sudoku to utilize the sparsity of the sudoku solution as is the case in sensing applications.LIKES and SPICE were also tested on sudoku and their results are compared with l1-norm minimization, weighted l1-norm, and sinkhorn balancing. SPICE and l1-norm are equivalent in terms of accuracy, while SPICE is slower than l1-norm. LIKES and weighted l1-norm are equivalent and better than SPICE and l1-norm in accuracy.SDR proved to be best when the sudoku solutions are unique; however the computational complexity is worst for SDR. The accuracy for IAA-APES is somewhere between SPICE and LIKES and its computation speed is faster than both.",Signal Processing
"Integrated tracking and detection, based on unthresholded measurements, also referred to as track before detect (TBD) is a hard nonlinear and non-Gaussian dynamical estimation and detection problem. However, it is a technique that enables the user to track and detect targets that would be extremely hard to track and detect, if possible at all with ”classical” methods. TBD enables us to be better able to detect and track weak, stealthy or dim targets in noise and clutter and particles filter have shown to be very useful in the implementation of TBD algorithms.This project has investigated the use of particle filters on radar measurements, in a TBD approach.The work has been divided into two major problems, a time efficient implementation and new functional features, as estimating the radar cross section (RCS) and the extension of the target. The later is of great importance when the resolution of the radar is such, that specific features of the target can be distinguished. Results will be illustrated by means of realistic examples.",Signal Processing
"Due to the recursive nature of most foot-mounted zero-velocityupdate-aided (ZUPT-aided) inertial navigation systems (INSs), the error covariance increases throughout each step and “collapses” at the end of the step, where the ZUPT correction is done. This gives sharp corrections and discontinuities in the estimated trajectory.For applications with tight real-time constraints, this behavior is unavoidable, since every estimate corresponds to the best estimate given all the information up until that time instant. However, for many applications, some degree of lag (non-causality) can be tolerated and the information provided by the ZUPTs at the end of a step, giving the sharp correction, can be made available throughout the step.Consequently, to eliminate the sharp corrections and the unsymmetrical covariance over the steps, the implementation of a smoothing filter for a ZUPT-aided INS is considered in this thesis. To our knowledge, no formal treatment of smoothing for such systems has previously been presented, even though an extensive literature on the general subject exists.Owing to the customary closed-loop complementary filtering used for aided INS, standard smoothing techniques cannot directly be applied. Also since the measurements (the ZUPTs) are irregularly spaced and appear in clusters, some varying-lag smoothing rule is necessary. Therefore, a method based on a mixed open-closed loop complementary filtering combined with a Rauch-Tung-Striebel (RTS) smoothing is suggested in this project.Different types of varying-lag smoothing rules are examined. For near real-time applications, smoothing is applied to the data in a step-wise manner. The intervals (steps) for the smoothing are determined based on measurement availability and covariance and timing thresholds. For complete o-line processing, full data set smoothing is examined. Finally, the consequences of the smoothing and the open-closed-loop filtering are quantified based on real data. The impact of the smoothing throughout the steps is illustrated and analyzed.",Signal Processing
"The purpose of this master thesis was to study different content-aware video retargeting techniques, concentrating on a generalization of seam carving for video. Focus have also been put on the possibility to combine different techniques to achieve better retargeting of both multi-shot video and single-shot video.This also involved significant studies of automatic cut detection and different measures of video content. The work resulted in a prototype application for semi-automatic video retargeting, developed in Matlab.Three different retargeting techniques, seam carving, automated pan & scan and subsampling using bi-cubic interpolation, have been implemented in the prototype. The techniques have been evaluated and compared to each other from a content preservation perspective and a perceived quality perspective.",Signal Processing
This paper proposes the application of the Wiener filter in an adaptive manner in speech enhancement. The proposed adaptive Wiener filter depends on the adaptation of the filter transfer function from sample to sample based on the speech signal statistics (mean and,Signal Processing
"In Sweden, growing processes and shrinking processes take place simultaneously since decades. The following thesis deals especially with the decline process in the remote rural municipalities in Sweden. The central question of the thesis is: how the national and municipal level in Sweden is dealing with the demographic decline in remote rural regions.To answer this question, the thesis includes three parts. The first part is the theoretical framework the thesis. The second part analyses the measures at the national level with a focus on the national regional growth policy as a support measure and the national equalisation policy as a compensation measure. The dealing on the national process is characterized by policies to reverse the decline and to compensate the negative impacts.The third part analyses the dealing process on the municipal level. Thereby, the dealing process has more a practical nature. This shows the two selected case study of the municipalities Arjeplog and Jokkmokk. It seems very common that the Swedish municipal measures are characterized by a two-way dealing namely reverse the decline and secure the municipal basic services.",Economics and Finance
"This document compiles a highly discussed issue present in many cities of the developing world today; it brings forward the importance of facing the challenges that slums create to today’s cities and the mechanisms used for tackling such challenge.The study focuses on the use of Participatory Planning approaches in the context of slum upgrading, giving the reader an insight to the advantages and challenges that such an approach has. It is built around a case study in the city of Medellin, Colombia where there has been a strong political will and commitment to implement programs and projects in the poorest areas of the city.This initiative emerged as a need to tackle deep rooted problems present in the slum areas of the city that together with other issues placed Medellin as the most dangerous city of the world during the 1990s.For tackling such a problem, the local Administration (2003-2007) created a slum upgrading model called “PUI – Proyecto Urbano Integral” (Integral Urban Project) which is said to be based on “participatory planning” and “slum upgrading” principles. The results of the first project following the “PUI Model”, the “PUI Noriental”, have been promoted by the Administration as highly successful and been considered as a model for slum upgrading both nationally and internationally.Therefore, there is the need to acknowledge and critically asses the PUI Model by evaluating its principles, its methods and its results having a deeper understanding and assessment of the concepts behind such an approach; specially since it has been internationally recognized that there is a lack of cases in which the ideals of participation and slum upgrading are put in practice.In this order of ideas, the principles, methods and tools of the “PUI Model” and its implementation in the “PUI Noriental”, are evaluated based on international theories and experiences dealing with the topic. By doing so, it is shown the close link between the principles of participation and the very nature of slum upgrading processes.As well it is brought forward the need to implement such kind of a approaches in cities presenting problems with slum areas. The results of the evaluation show that even though there is a strong political will towards using principles of participatory planning and slum upgrading approaches in Medellin, there is still a high need to have a deeper understanding of such concepts and the way they can be implemented.Nevertheless, it is shown that even with these shortcomings the significant outcomes produced by the PUI Noriental are a clear example that participation in the context of slum upgrading is a strong tool to bring benefits to the people of such areas.",Economics and Finance
"The aim of this research is to check whether the Taylor rule in its simple linear form can be viewed as an appropriate description of the monetary policy pursued by Norway’s central bank – Norges Bank, and whether this rule can be used for forecasting purposes.Not only does this research focus on the original Taylor rule, but it also deals with its extended version designed for small open economies such as Norway. A conclusion about whether regressions can produce reliable coefficient estimates is drawn on the basis of time series’ properties tests and cointegration tests. The performance of the simple-form Taylor equation is compared to its alternative forms through forecasting exercises.The study has shown that the extended version of the Taylor rule with interest rate smoothing and augmented with the real exchange rate, the policy rate of the EU and oil prices can be viewed as a close approximation of Norges Bank’s monetary policy and can be used for forecasting purposes.",Economics and Finance
"This paper investigates the impact of the increased off-shoring in business and manufacturing to Central and Eastern Europe (CEE). Since the off-shoring process is a relatively new activity, there is no precise definition of how to measure its direct impact on a country’s economy.Thus the study is dedicated to identify the main economic factors associated with off-shoring and to examine their impact on the economic growth. The study has used a dataset on economic characteristics for 9 CEE countries (Estonia, Latvia, Lithuania, Poland, Czech Republic, Hungary, Romania, Slovenia, Croatia) during the time period of 2000 – 2008.After applying fixed and random effects econometric model to the panel data for 9 countries, empirical results showed that FDI inflows that enter the country with offshoring processes have a positive influence on the GDP of those countries.Additionally, exports of manufactured products and ICT services are also shown to have a positive influence on GDP. At the same time, indigenous investments and private consumption do have a stronger impact on economic growth compared to foreign direct investments and exports, respectively.",Economics and Finance
"In recent years, terms as “knowledge economy” and “knowledge society” have appeared in contemporary management literature. The rhetoric has been that technology-based advantages alone are transient and that knowledge is the reason companies are able to gain and sustain competitive advantages.This has led to extensive research, and knowledge management has gained the reputation of a legitimate research field.This thesis aims at proposing a feasible approach and tool for an initial knowledge management assessment, using the case of an electronics manufacturer in South East China.By an extensive literature review and analyzing reasoning, a knowledge management assessment tool has been developed through a combination of a well-known model for knowledge creation and a globally wide-spread set of criteria for knowledge management. A pilot assessment, conducted to evaluate a management process in the case company, proved the assessment tool applicable.In that pilot assessment, it was shown that all stages of the dynamic knowledge creation process were supported to some extent even though there was a lack of support for some categories in the evaluation criteria. The trial evaluation is however to be viewed as successful since the assessment tool was proven to serve its purpose.The assessed process at the case company was considered to contribute a great deal to the department’s and organization’s knowledge management performance.Geographic location or maturity of knowledge management is not regarded to have any significant influence and the proposed assessment tool is considered as useful to various organizations, thus enjoying a high external validity.",Economics and Finance
"Indian IT companies have garnered a good market share in the global IT services market. Research has been emerging on the competitiveness of the Indian IT industry and the opportunities which led to the success of the Indian IT industry.However,considering the current challenges posed to the Indian IT industry, Indian IT companies have to move up in the value chain and achieve technology led catch-up with the incumbents to maintain the market share in a highly competitive market.The first part of this study investigates the windows of opportunities created by techno economic paradigm shifts and discontinuities that will help the Indian IT companies to move up in the value chain. To capitalize on the opportunities, Indian IT companies have to improve their innovation efforts.In the second part of this study, certain determinants which improve the ideation capability of the organization are investigated in the Indian IT companies and its effects are discussed. The report also discusses various strategies that can be employed by the Indian IT companies to capitalize on the opportunities and to achieve technology led catch-up.",Economics and Finance
"This study strives to examine how microfinance activities can be successfully applied in the developed world. This is done through a field study in New York City. Throughout interviews and observations with three of the largest actors in New York: Acción USA, Grameen America and Project Enterprise, as well as interviews with their clients, the lending processes and key characteristics of the organizations have been mapped. Furthermore, the Federal Reserve Bank of New York has been interviewed on the general opinion of microfinance in the US.Previous theory elaborates on some of the major challenges with implementing microfinance activities in the developed world, such as lack of funding and cultural differences hindering the lending processes to be carried out as they are in the developing world. Henceforth, problems regarding regulation, awareness and outreach are discussed.Throughout the observation of the institutions we can confirm that some of the challenges brought up in theory actually are apparent. We do, however, question the criticism towards the use of group-based lending programs in the developed world. Our study does, in contrast to previous research, imply that the concept does work as well in the US as it does in developing countries.Since this is a case study based on the observations of only a few organizations, it is precarious to draw any general conclusions based upon the findings. Indications of key success factors are, though, group-based lending programs, non-financial services, creating awareness, financial sustainability, savings as funding, standardized regulations and increased transparency. Finally we advocate focus on job creation to obtain acknowledgement.",Economics and Finance
"The role of the manufacturing units has a big impact on a company’s business. If competitive priorities and the production weapons can be merged together and describe a factory profile, it can be a factor that provides the competitive advantages for the company. This thesis has two objectives in this area, the industrial and the academic.The industrial objective will investigate how we can visualize and describe a manufacturing structure and make the desired positioning. The manufacturing footprint structure will be set up according to the performance objectives Innovation, Flexibility, Lead-time and Efficiency representing the product life cycle that also support decisions for the make or buy process.The result is a model that describes the manufacturing structure and a conflict area, or a “Black Hole”, is indentified and is leading to the academic research questions; why most of the manufacturing units are positioned in the conflict area and how to leave the “Black Hole”? The intersection in the views of positioning, knowledge and the network paradox are analysed and a scaled model connected to Dreyfus knowledge model, brings some understanding to the positioning problem.A process model is proposed for the characteristic profiles of the concept factories and how to move to the desired positions. This concept can be applied on a group of manufacturing units and handle the trade off dilemmas for the separate units by letting a group of units achieve top performance for all the performance objectives.The visualization and relation to the products life cycle can contribute to communication and developing the manufacturing footprint strategy. The model has been tested, in a positioning context for strategic purchasing with experience of supplier quality audits for positioning suppliers, with positive result.Further research of top performance factories would be interesting to do in order to find out their 8M profiles and identify more trade off dilemmas, connecting them to the different performance objectives in order to support the development in moving to different desired directions.",Economics and Finance
"In an attempt to capture the complexity of the economic system many economists were led to the formulation of complex nonlinear rational expectations models that in many cases can not be solved analytically. In such cases, numerical methods need to be employed.In chapter one I review several numerical methods that have been used in the economic literature to solve non-linear rational expectations models. I provide a classification of these methodologies and point out their strengths and weaknesses. I conclude by discussing several approaches used to measure accuracy of numerical methods.In the presence of uncertainty, the multistage stochastic optimization literature has advanced the idea of decomposing a multiperiod optimization problem into many subproblems, each corresponding to a scenario. Finding a solution to the original problem involves aggregating in some form the solutions to each scenario and hence its name, scenario aggregation.In chapter two, I study the viability of scenario aggregation methodology for solving rational expectation models. Specifically, I apply the scenario aggregation method to obtain a solution to a finite horizon life cycle model of consumption. I discuss the characteristics of the methodology and compare its solution to the analytical solution of the model.A growing literature in macroeconomics is tweaking the unbounded rationality assumption in an attempt to find alternative approaches to modeling the decision making process, that may explain observed facts better or easier. Following this line of research, in chapter three, I study the impact of bounded rationality on the level of precautionary savings in a finite horizon life-cycle model of consumption.I introduce bounded rationality by assuming that the consumer does not have either the resources or the sophistication to consider all possible future events and to optimize accordingly over a long horizon. Consequently, he focuses on choosing a consumption plan over a short span by considering a limited number of possible scenarios. While under these assumptions the level of precautionary saving in many cases is below the level that a rational expectations model would predict, there are also parameterizations of the model for which the reverse is true.",Economics and Finance
"Sustainable design and engineering is in great demand in cities all over the world. As a result, design and engineering consultancies have to continue finding ways to capitalize on sustainable developments responsibly.Implementing a strategy to reduce the friction between the human-ecology and economic imperatives is a major step. Amongst Ramboll’s Nordic sustainable perspectives, the Swedish perspective can be  innovative enough to reduce this friction that can stand in the way of the comprehensive sustainable project mission, which is profitable and value-added.But can this comprehensive and holistic Nordic approach, intended to link stakeholders into a positive project dynamic be applied  effectively enough under unique country-specific contexts? A strategy that incorporates a framework to understand and value the intangibilities of sustainability and fine-tuned for the different conditions and unique contexts of where projects are built can help by creating positive  synergies between stakeholders.The friction between the human-ecology and economic imperatives exists and we draw upon previous research and sustainable development projects in Sweden and Istanbul, Turkey, to determine how this friction prevents projects from being comprehensively sustainable.Exploring beyond the Swedish sustainable perspective can help rationalize contextual barriers during the pre-construction stages of the project life cycle. And, with the right strategy, the project coalition can design and engineer with confidence knowing that the intangibilities of sustainability are valued and used by each stakeholder to optimize their profitability responsibly.",Economics and Finance
"Regional integration has gained momentum since the 1980s and throughout the world. The new regionalism process prevailing since differs from the old one by its multi dimensionality covering economic, political, social, and cultural issues within a regional setting.While the old regionalism focused on market protection using a range of tariff and non tariff barriers, the New Regionalism is reinforced by the globalisation effects and strives for efficiency in production, and market access.Using the New Regionalisms Approach, the aim of this thesis is to appreciate the actual levels of regional integration in Africa and explore plausible ways of deepening the integration process with the view that regional integration can promote socio-economic development, provided a pro-development approach is privileged in the conception and implementation of the regional integration process.Focusing on SADC as a representative regional economic community, a qualitative content analysis is used for data collection while policy analysis is carried out using the Institutional Analysis and Development framework.The results of this study reveal discrepancies between policy formulation and policy implementation when it comes to enhancing the pro-developmental aspects in the unfolding regional integration process.In spite that shortcomings in past experiences triggered dramatic structural reforms ranging from the reorganisation of the Organisation of African Unity into the African Union, the creation of NEPAD, to structural reforms within regional economic communities with the example of the 2001 restructuring of SADC, empirical evidence shows that little change has occurred at the operational level.Moreover, even policy formulation at the collective-action level still lacks concrete strategies and plans for harmonisation and implementation of regional initiatives. Some of the strategies for deepening the regional integration process would include prioritising regional commitments to external ones and improving policy formulation as well as establishing linkages between different regional policies and strategies.",Economics and Finance
"This project studies two related issues that have gained relevance as a consequence of several of the major currency crises of the 1990s. The first is the impact that devaluations have on investment when domestic firms have currency mismatches, i.e., debt denominated in foreign currency and assets and revenues in domestic currency. The second has to do with the causes behind the widespread presence of currency mismatches in many economies of the world.Chapter 2 analyzes the first issue using firm level data for Thailand to test for the impact of currency mismatches on firms’ investment during the Asian crisis. A key feature of the analysis is that it exploits the heterogeneity that exists in the degree of currency mismatch across firms in order to identify the mentioned impact.The results of this chapter suggest that currency mismatches played a statistically significant role in explaining the investment decline observed in Thailand during and after the Asian crisis, and, as a result, that a balance sheet channel may have operated during the crisis.The results also suggest that omitting complementary explanations of the Asian crisis, in particular the presence of over-investment prior to the crisis, produces an artificially high impact of currency mismatches on investment. This result occurs due to the co-movement that investment and currency mismatches have in the period preceding the crisis. Chapter 3 assesses the generality of the results of the previous chapter by analyzing other three countries that were involved in the Asian crisis: Indonesia, Malaysia, and South Korea. Although less robust due to data limitations, the analysis is still very insightful.Chapter 4 deals with the second issue mentioned in the first paragraph. The chapter proposes a model that emphasizes the incentives of domestic governments to generate opportunistic devaluations in order to transfer resources from foreign lenders to domestic borrowers in case debt contracts were denominated in domestic currency. The model is not only able to explain why firms end up having currency mismatches, but it is also consistent with several of the stylized facts associated with international capital movements.",Economics and Finance
"This study examines employment, earnings, and income of the six major foreign and native born Asian groups, namely, Asian Indians, Chinese, Filipinos, Japanese, Koreans, and the Vietnamese for the year 2000. The study makes three contributions. First, it provides an updated analysis of employment and earning attainments of Asian individuals disaggregated by countries of origin, gender, and nativity status using the latest available and most suitable data.Second, it explores the use of a non-parametric technique, namely reweighting, to assess the Asian -white earning gaps. Third, it analyzes intergroup variations in household income, inclination to pool resources, and factors associated with the likelihood of forming nuclear living arrangements. Descriptive statistics document high average levels of employment, earnings, and human capital attainments for Asians relative to whites with notable subgroup differences. The multivariate and reweighting analyses show that foreign born Asians experience greater disadvantage relative to whites than the native born Asians.The gender comparisons indicate that being native relative to being foreign born is more beneficial for Asian women than men, with native born Asian women experiencing higher earnings than white women. Additionally, there is evidence of a ‘glass ceiling’ among Asian men. At the household level, the descriptive associations show the relative economic position of Asian households depends on the specific measure of household income employed. Asian households experience similar or higher levels of total household income and income per labor hour employed but lower levels of per capita income than white households. Also, a higher inclination to pool resources among the foreign compared to the native born Asian and white households is seen.Intergroup comparisons indicate foreign born Chinese, Korean, and Vietnamese households having a greater tendency to pool resources than the foreign born Indians and the Japanese. Multivariate analyses show a positive relationship between the householder’s earnings, education, and length of stay and the likelihood of forming nuclear relative to nonnuclear households. The overall findings from this study suggest that – at both the individual and household levels, the differences between the foreign and the native born Asians are more significant than the intergroup variations among Asians.",Economics and Finance
"Aim: The aim of this study is to fill the research gap on whether there are differences in how Swedish consumers remember publicized scandals in regards to the Country of Origin (COO), focusing on age, gender and time.Furthermore, this paper will also aim to look at how different scandals have affected the consumers trust based on whether foreign food scandals have a higher impact.Methodology: Since this thesis tested different relationships a deductive approach was taken with a conclusive research design. Quantitative data was collected via a VAS-scale questionnaire to 187 individuals via random sampling at train stations which had a response rate of 75,9%.By using SPSS, the primary data was analyzed via a Correlation and Factor analysis in accordance with scientific articles from within the fields of Purchasing Decision theory, the COO and Consumer Memory. A semi-open telephone interview with an expert from within the food industry was conducted as additional explanations to the findings were needed.Result & Conclusions: It was found that Swedish consumers remembered scandals differently depending on origin, and were according to themselves more affected by the foreign scandals. Gender did not have a preference depending on the COO of the product and consumer memory while age did.It was also found that trusting food was the essential theme throughout the empirical findings where the Swedish consumers valued cues such as food quality and food safety. This played a significant role on impacting the consumer’s long-term memory. Three different types of trust was found and divided by their characteristics; High-level-involvement products, the COO of the product or the company which the scandal was involved with, and finally, the size, positioning and equity of the brand involved.Business implications: Media can be seen as a key source of spreading negative publicity regarding scandals. It is therefore extra important for companies to act immediately, especially if they have any of the three characteristics of trust since it influences the consumer’s long-term memory in a negative way. These three characteristics combined could have strong more negative impact on the companies, where there is a risk of losing potential & current business partners, decreased brand equity & image and risk of facing legal aspects. This can be very costly both financially and time-wise which ultimately could lead to a negative turnover.Research Implications: future research is suggested to study why the results in this thesis differ from the other scientific findings when it comes to gender. Also suggested is that studies should be conducted similar to this, but based on specific types of food products since this thesis only studied food in general. Furthermore, studies comparing the effect of the consumer memory in regards to food scandals based on different companies are also suggested.",Economics and Finance
"International Development Programmes (IDPs) are United Nations‘ (UN) and developed countries‘ initiatives to develop world‘s least developed countries. IDPs significantly vary from other mainstream project management topics, as most often they do not have eye for commercial success or are not of simple charity nature of humanitarian perspective aid.Projects under IDPstry to deliver United Nations‘ and rich countries commitment to provide sustainable development to developing world in terms of reducing poverty and hunger, improving health and education system, building capacity to face disasters, eliminating gender discrimination, among others.This significant difference and lack of research in this field has left a gap in established project management methodologies that could be generalised as specifically suitable for IDPs.The knowledge of project selection methodologies has reached to its extreme variety, as it spreads from the simplest model of a checklist to the highest degree mathematical model.Leading researchers in the field have come to conclusion that project selection methods have to match the needs of a specific programme or portfolio to serve its purpose. The uniqueness of IDPs intensified the necessity of choosing projects by understanding the financial and strategic benefit they can deliver matching their resource requirement.In absence of straight direction in the research and real life case observations, the practice in project selection in IDPs has not still been an established procedure.To explore this need the authors of this report examined the theoretical framework of project selection and their compliance with IDPs unique characteristics. Project selection methods showed that due to organisations‘ varied need of delivering financial or strategic objectives, the selection models significantly vary.The use of different financial or strategic criteria with different emphasis on them is highlighted in project selection articles. Further analysis was focused on project selection stages and possible challenges evolving in the selection process.The researchers tried to explore project selection methods used in IDPs in Bangladesh by analyzing four different cases.The examination of the project selection process showed that it mainly follows the multi-stage assessment procedure, with project evaluation conducted by the assessment panel, comprised from the functional experts and in some cases stakeholders‘representatives.Further, from the findings it was evident that the primary theoretical suggestions for IDPs project selection methods being strategy driven rather than being commercial in nature is true. In all four cases, the researchers have seen the selectors using scoring and ranking model that are specifically designed with higher emphasis on the strategic factors, and that try to deliver development objective rather than contributing to commercial success.In addition, the challenges in IDP project selection practice are also discussed. Challenges like delivering development needs while trying to make the project sustainable in the long run, managing the powerful influence of different stakeholders in selecting projects, avoiding country politics,among others are making the project selection more difficult.The main contribution of this research has been establishing a primary selection framework from case evidence with suggestions on appropriate model, set of criteria which can be used and a set of challenges to be aware of. The study is presented as a basis for further research in this field.",Economics and Finance
"Traditional theories, models, and methods often address a general view of the environment including sociocultural, technological, political, and economic factors.However, there is a lack in infrastructural attention in these concepts which this thesis intends to contribute with by analyzing how regional specific infrastructural variables can be aggregated to one comparative measure and what that measure’s scope of use could be in the market analysis?Hence, the purpose of this thesis is to contribute to the strategic planning process research with a supporting quantitative tool, based on statistical metrics, for determining the market potential.This study has an inductive approach and is primary based on documentary secondary data and the strategic planning process is the main theory of concern when evaluating the possibilities of infrastructural assessment. As a complement, the infrastructural concerns in the economics are also dealt with.The empirics are compiled and calculated in a manner which allows an indexing and the finalized result is presented as an Infrastructural Status Index (InfraStat Index). Some of the utilities of this index are that it can be a complementary part of the PEST- and SWOT-models and a supporting tool in companies’ strategic planning processes.The index has both business and macroeconomic scopes of use and one of the summarizing conclusions is that further research within this concept should incorporate more variables in order to retrieve a more comprehensive result.",Economics and Finance
"This project aims to contribute to our understanding of dynamic interaction in duopoly markets. Chapter 1 motivates the study and offers a brief overview of the results. In Chapter 2 I study the dynamic equilibrium of a market characterized by repeat purchases. Such markets exhibit two common features: customer recognition, which allows firms to price discriminate on the basis of purchase history, and consumer switching costs.Both features have implications for the competitiveness of the market and consumer welfare but are rarely studied together. I employ a dynamic framework to model a market with customer recognition and switching costs. In contrast to earlier studies of dynamic competition with switching costs, these costs are explicitly incorporated in the demand functions. Two sets of market equilibria are characterized depending on the size of the switching cost.For all values of the switching cost, customer recognition gives rise to a bargain-then-ripoff pattern in prices and switching costs amplify the loyalty price premium. When switching costs are low, there is incomplete customer lock-in in steady state, firm profits increase in the magnitude of the switching cost and introductory offers do not fall below cost. When switching costs are high, there is complete customer lock-in in steady state, firm profits are independent of switching costs and introductory prices may fall below cost.Under incomplete lock-in and bilateral poaching, switching costs do not affect the speed of convergence to steady state; under complete customer lock-in and no poaching from either firm, convergence to steady state occurs in just one period. The model also suggests that imperfect customer recognition leads to lower profits relative to both uniform pricing and perfect customer recognition. In Chapter 3 I use the market framework developed in Chapter 2 to examine the perception that imperfect competition hinders information sharing among rivals in games of random matching. In contrast to previous studies of information sharing, I propose a new channel through which competition may deter information sharing. This approach reveals a key role for firm liquidity by showing that information sharing among rivals is more likely to arise in markets populated by more liquid firms.Employing a dynamic duopoly framework, in which competition intensity varies with the degree of product differentiation, consumer switching costs and consumer patience, I show that more intense market competition can weaken the disincentives associated with disclosing information to a rival. I test the model’s predictions using firm-level data on the information-sharing practices of agricultural traders in Madagascar. As predicted by the model, traders operating in liquid markets are shown to be more likely to share information about delinquent customers. This result is robust to the use of two alternative measures of liquidity, of which one is credibly exogenous, and two alternative ways of defining market liquidity. Furthermore, traders who report more intense competition in their market are found to be significantly more likely to share information.",Economics and Finance
"Financial sector of an economy plays an important role in its economic development and prosperity of the country. Banking industry serves as the backbone of the financial sector that accumulates saving from surplus economic units in the form of deposits and provides it to deficit economic units in the form of advances.Banking industry provides support to economy and industries in specific in the time of recessions and economic crisis. But when banks are at the heart of economic recession or banks are the cause of financial crisis like the recent past financial crisis 2007-09, it makes the situation worst for economic recovery. So it is of great importance to keenly observe the performance of the banks and their compliance with the regulatory requirements.Performance of the banks is measured at two levels, one is at the management and regulatory level of the banks and another is at external rating agencies. Purpose of regulatory and supervisory rating systems is to measure the bank performance at internal level and its compliance with regulatory requirements to keep the bank on right track. These ratings are highly confidential and are only available to the bank management.External credit rating agencies examine and evaluate the banks and issue ratings for the general public and investors in particulars. It is of great importance that both these ratings present the same results about the condition of the banks to provide clear information to investors and management. In past several banks suffer from bankruptcy that was the failure of both internal rating systems and credit rating agencies.CAMELS is the supervisory and regulatory rating system implemented by State Bank of Pakistan. It takes into account six important components of a bank when it evaluates performance of the bank. These components are Capital, Assets, Management, Earning, Liquidity and Sensitivity to market risk. Ratings is assigned to theses components on the scale of 1 to 5 and that is a base for composite rating that also ranged from 1 to 5.PACRA rating agency is the dominant credit rating agency of Pakistan that performs ratings for most banks and industries in the country. In our research we examine the similarities in the results generated by CAMELS rating system and PACRA rating agency. For that purpose we sample seventeen commercial banks of Pakistan Banking industry.We observed that results generated by sample banks do not show any similarities with each other. This might be an indication of the banks that went on to bankruptcy in past three to four years or a future threat to financial sector of Pakistan.",Economics and Finance
"Nowadays, there is a debate about the possibility that sin stocks bring higher returns than other ones to the investors. This study is a case study on a mutual fund: The Vice Fund. This US fund has a specific investment strategy: it invests in sin stocks.We compared this mutual fund to The Timothy Fund because they have similar characteristics such as – date of inception, total assets, home country and investment universe, expect the investment strategy. Indeed, The Vice Fund invests in sin stocks and The Timothy Fund does not. Two benchmarks are also used in the study: the S&P 500 Index as a domestic benchmark and the MSCI World Index as an international benchmark.This study is a case study using a deductive approach on a quantitative ground. The study is done on ten years long from 2003 to 2012. We divided the entire period into three different sub-periods depending of the S&P 500 Index trend. The first and the last sub-periods are bullish and the second one is bearish.In order to analyse both the financial performances and the risks of The Vice Fund we use several tools. We calculated returns and risk-adjusted ratios: the Treynor’s ratio, the Sharpe’s ratio and the Jensen’s ratio. Because these ratios are less accurate in bearish markets, we calculated the normalized Sharpe ratio by doing linear regressions and we also calculated the modified Sharpe ratio.In order to perform these calculations, we used DataStream as a database to obtain prices and dividends for the two mutual funds and the prices for the two benchmarks. We got also the one-month T-bill to have a risk-free rate. We found that The Vice Fund had a better average returns performance whatever the market conditions over the period studied.However the difference between weekly results with The Timothy Plan Fund and the benchmarks is not statistically significant. The risk- adjusted ratios confirmed the superiority of the risk-adjusted financial performance of the sin fund.",Economics and Finance
"Previous studies in mutual funds were focused mainly on the US market. The general belief is that mutual funds in average cannot outperform the market. We decided to test this theory in the less studied markets of equity funds in Sweden and Germany. Another controversial point is fees in mutual funds. Therefore we will give an overview of fees in both markets, and analyze the relation between fees and performance.This study analyzes the Swedish and the German mutual funds market. For the German market,funds with domicile in Germany and abroad are analyzed separately in order to examine possible differences between funds with a domestic domicile, and funds domiciled abroad.1285 funds performances covering period of 2000-2008 were calculated using Jensen’s Alpha measure. The results showed that all funds have on average negative alphas. Approximately 20% of funds in the German market and 12% of the funds in the Swedish market have significantly negative performance.Regarding fees, there is only a small difference between funds in the German and the Swedish market in general, while the difference between funds domiciled in Germany and Luxembourg was significantly bigger.Our analysis of the relation between fees and performance showed no significant relationship.",Economics and Finance
"This paper investigates the impact of the increased off-shoring in business and manufacturing to Central and Eastern Europe (CEE). Since the off-shoring process is a relatively new activity, there is no precise definition of how to measure its direct impact on a country’s economy.Thus the study is dedicated to identify the main economic factors associated with off-shoring and to examine their impact on the economic growth. The study has used a dataset on economic characteristics for 9 CEE countries (Estonia, Latvia, Lithuania, Poland, Czech Republic, Hungary, Romania, Slovenia, Croatia) during the time period of 2000 – 2008.After applying fixed and random effects econometric model to the panel data for 9 countries, empirical results showed that FDI inflows that enter the country with offshoring processes have a positive influence on the GDP of those countries.Additionally, exports of manufactured products and ICT services are also shown to have a positive influence on GDP. At the same time, indigenous investments and private consumption do have a stronger impact on economic growth compared to foreign direct investments and exports, respectively.",Economics and Finance
"In order to explain how to fulfill the purpose of investigating what makes similar companies adapt different risk report communication strategies in the Nordic banking industry, the research design, method and practical execution will be presented below.The research will be explorative in the sense that the financial risk reports (or pillar 3 reports) have a rather recent appearance in business and is by that naturally not very well covered in other research. As mentioned above, theories about communication is not a new matter and could nowadays be considered a well-established subject of research.It is further to explore how the communication theories visualize in this new subject, and will be researched in order to get better understanding for what financial reporting represent in the field of corporate communication. As the aim is to elaborate on present theoretical reasoning it is natural to focus on finding factors that may explain the phenomenon, and further elaborate if these findings are competing with earlier theories.",Economics and Finance
"Small and medium size enterprises (SMEs) are well known for being the backbone of the economy. They are the key factors of the economic growth as well as for innovating and developing products and services.Financial obstacles often occur for Swedish SMEs when they are searching for ways of financing the business. The lack of necessary financing to help SMEs’ businesses grow has been brought up in many institutions supportive of Swedish SMEs.This study is conducted to examine and give an understanding of how Swedish SMEs established in China are financing their businesses since strong internal financing results in a decrease for a need for external financing. Furthermore, the study is looking at what type of financial obstacles SMEs may encounter.For this purpose the relevant arguments are presented and discussed. This is done through a qualitative approach as well as hermeneutic phenomenology for a more in depth analysis on how certain Swedish SMEs are financing their business in China. The writers have chosen to interview Swedish SMEs who in some way are in the business of manufacturing and production and who are established in China.Interviews were also conducted with representatives from financial institutions in order to gather information on how Swedish SMEs can access external financing. All of the interviews were performed in a semi-structured manner. When the information was gathered some of the Swedish SMEs requested the answers to be anonymous, therefore the writers is keeping all answers from the responding SMEs anonymous in the result and analysis part of the thesis.The answers from the financial representatives are however clearly stated which respondent answered what. Additionally, the writers found that most of the existing research on financing can explain the SMEs financial decisions, yet there was some adaption needed in regards to the theories in order for them to fit into the context of the Swedish SMEs and financiers.Moreover, the authors found that there is no large financing gap or demand to require additional credit from traditional banks or other financiers. Hence, the participating Swedish SMEs established in China mainly obtain financing from shareholder equity or other internal sources to finance their business.",Economics and Finance
"This study strives to examine how microfinance activities can be successfully applied in the developed world. This is done through a field study in New York City. Throughout interviews and observations with three of the largest actors in New York: Acción USA, Grameen America and Project Enterprise, as well as interviews with their clients, the lending processes and key characteristics of the organizations have been mapped. Furthermore, the Federal Reserve Bank of New York has been interviewed on the general opinion of microfinance in the US.Previous theory elaborates on some of the major challenges with implementing microfinance activities in the developed world, such as lack of funding and cultural differences hindering the lending processes to be carried out as they are in the developing world. Henceforth, problems regarding regulation, awareness and outreach are discussed.Throughout the observation of the institutions we can confirm that some of the challenges brought up in theory actually are apparent. We do, however, question the criticism towards the use of group-based lending programs in the developed world. Our study does, in contrast to previous research, imply that the concept does work as well in the US as it does in developing countries.Since this is a case study based on the observations of only a few organizations, it is precarious to draw any general conclusions based upon the findings. Indications of key success factors are, though, group-based lending programs, non-financial services, creating awareness, financial sustainability, savings as funding, standardized regulations and increased transparency. Finally we advocate focus on job creation to obtain acknowledgement.",Economics and Finance
"Building Information Modeling (BIM) or Virtual Design and Construction (VDC) recently has been regarded as crucial by the architecture, engineering, and construction (AEC) industry. The use of BIM/VDC represents the creation and use of a three-dimensional (3D) virtual model that amplifies the design, construction, and operation of a building.This technological improvement fundamentally changes the process of how the buildings are designed and constructed. However, the approach to the use of advanced technology in the AEC industry does not seem to be welcomed by the majority of the industry regarding high initial cost of implementation.This study presents data gathered from meetings, interviews and a case study which was a construction project run in Sweden to determine the savings implementing BIM/VDC and to reveal the return on investment (ROI) from a general contractor (GC) perspective. The potential savings to the GC to invest in BIM/VDC were estimated based on the PENG model, measurable cost benefits associated with reduced schedule overruns and reduced change order cost.This study confirmed that BIM/VDC results in vast savings and positive impacts on ROI based on the results from the case study which deployed it successfully.",Economics and Finance
"Disinvestment is the action of an organization or government of selling or liquidating an asset or subsidiary.EVOLUTION OF DISINVESTMENT POLICY:It has been decided that Government would disinvest up to 20 per cent of its equity in selected public sector undertakings, in favour of mutual funds and financial or investment institutions in the public sector.The disinvestment, which would broad base the equity, improve management and enhance the availability of resources for these enterprises, is also expected to yield Rs. 2,500 crores to the exchequer in 1991-92.The modalities and details of implementing this decision, which are being worked out, would be announced separately. The policy, as enunciated by the Government, under the Prime Minister Shri Chandrashekhar was to divest up to 20% of the Government equity in selected PSEs in favour of public sector institutional investors.The objective of the policy was stated to be to broad-base equity, improve management, and enhance availability of resources for these PSEs and yield resources for the exchequer.Download Disinvestment Finance Project",Economics and Finance
"The need for Cash to run the day-to-day business activities cannot be overemphasized. One can hardly find a business firm, which does not require any amount of Cash. Indeed, firms differ in their requirements of the Cash.A firm should aim at maximizing the wealth of its shareholders. In its endeavor to do so, a firm should earn sufficient return from its operation. Earning a steady amount of profit requires successful sales activity. The firm has to invest enough funds in current asset for generating sales. Current asset are needed because sales do not convert into cash instantaneously. There is always an operating cycle involved in the conversion of sales into cash.The objectives are to analyze the Cash management and to determine efficiency in cash, inventories, debtors and creditors. Further, to understand the liquidity and profitability position of the firm.These objectives are achieved by using ratio analysis and then arriving at conclusions, which are important to understand the efficiency / inefficiency of Cash.It was noticed in the study that the company had utilized its Cash efficiently and can also try to get more effective values by working on it. The cash required to meet out the current liabilities is maintained at a normal level that shows the company follows an average policy.Download Project Report and PPT",Economics and Finance
"Worldwide, the wind has been changing in the finance sector in general and banking-investment sector in particular. Such a panorama teaches us that now, is the time of cooperation rather than a competition, now it’s a time of convergence rather than cutting each other’s neck over customers and markets, now it’s a time of consolidation rather than antagonism.Curing the fatal disease requires the doses of small pills; impressive thoughts come out from the small brain, similarly, India requires prominence of small and medium enterprises for curing its problem of low economic growth vis-à-vis developed nations.To cure the overall disease of lack of appropriate growth of Indian SMEs – Small and Medium Enterprises, India needs several small pills such as adequate credit delivery to SMEs, better risk management, technological upgradation of Banks esp. Public Sector Banks, attitudinal change in Bankers and so on. Among them, the major problem of inadequate financing to SMEs needs an urgent attention.Having said this, it is pertinent to mention that Small Industrial Development Bank of India has achieved landmark results in the domain of small and medium enterprise financing and fulfilling their credit requirements time to time in various forms such as long term project finance, working capital finance, bill discounting etc.However considering the level of appetite for credit facilities of Indian small and medium enterprises, private and public sector banks in India need to work out an unique and innovative model of financing to this vital sector (SME) of Indian Economy.In today’s changing world, retail trading, SME financing, rural credit and overseas operations are the major growth drivers for Indian banking industry. The scene has changed since the adoption of financial sector restructuring programme in 1991.The reform in the financial sector in India along with the overall second generation economic reforms in Indian economy has transformed the landscape of banking industry and financial institutions. GDP growth in the 10 years after reforms averaged around 6 %.With the introduction of the reforms especially in financial sector and successful implementation of them resulted into the marked improvement in the financial health of the commercial banks measured in terms of capital adequacy, profitability, asset quality and provisioning for the doubtful losses.Download Credit Appraisal Project",Economics and Finance
"In order to determine the maximum efficiency of investment solutions, introduced the concept of investment attractiveness of the company. The concept fairly new in economic publications appeared relatively recently and is used primarily in the characterization and evaluation of investment targets, ratings comparisons, and the comparative analysis of processes.Investigation of different points of view on its interpretation revealed that in the current understanding is no uniform approach to the essence of this economic category. Investment attractiveness correlate with the desirability of investing in the interests of the investor enterprise, which depends on several factors that characterize the activity of the subject.Evaluation of investment attractiveness of the company – actually checked that the company’s expectations of investors. Depending on the specifics of the company and available source of data the specific scope of work may differ, but in any case, the estimation of investment attractiveness of the company involves diagnosis of the company and determine its strengths and weaknesses to this point, as well as risk identification and future possibilities.During the diagnostic addresses all major aspects of the company: production of products / services, marketing, finance, corporate governance.",Economics and Finance
"Despite the huge sum of money that is being spent on research and development (R & D) on yearly basis by firms, very few empirical studies exist to shed more lights about the effects of this practice on firm performance.However, the International Financial Reporting Standards (IFRS) issued by the International Accounting Standards Board (IASB) in their publication of International Accounting Standard (IAS) 38, require that expenditures incurred during R & D should either be expensed in the statement of comprehensive income or capitalized as an intangible asset in the statement of financial position provided certain criteria are fulfilled.Therefore, the main purpose of this study is to investigate the impact of expensed R & D and/or capitalized R & D on firm performanceMETHOD: Data for the study was collected from the audited financial statements of firms listed at the London Stock Exchange as well as from the website of this stock market. Two sampling techniques were utilized in the study; namely stratified sampling and random sampling.Stratified sampling technique was used to stratify the companies into various industries while random sampling was used to randomly select firms that are engaged in R & D from each of these industries. The final sample consisting of 52 firms gave a total of 260 observations for a period of 5 years.Expensed R & D and capitalized R & D were obtained by taking the averages of statement of comprehensive income R & D to Revenue and statement of financial position R & D to revenue respectively. Moreover, firm performance was measured using accounting-based indicators which were Return on Asset (ROA), Return on Capital Employed (ROCE), Dividend Yield (DY), Dividend Cover (DC), Earnings per Share (EPS), Price Earnings Ratio (PE) and Capital Gearing Ratio (CGR).RESULTS: The results of the study show that expensed R & D has a significant positive impact on DC, a significant negative impact on EPS, positively correlated with CGR with no significant impact and negatively correlated with ROA, ROCE, DY and PE but had no significant impact.As concerns capitalized R & D, the results reveal that capitalized R & D has a significant negative impact on ROA, ROCE and EPS, positively correlated with CGR but have no significant impact and negatively correlated with DY, DC and PE as well though no significant impact was found.",Economics and Finance
"Within the field of microfinance, there has been an ongoing debate about whether microfinance institutions should be commercialized. One side argues that a business that very much can earn profits at the same time as it helps the poor, is not justified to receive charity, but should be run with the risks and benefits of any other profit-seeking business.The other side argues that the outreach to the ones who most need microfinance, is severely hampered if firms are profit-seeking; arguing that they only target the individuals who allow them to make profits.This study is a case study based on India, one of the world’s largest nations, and home to millions of people living below the poverty line. Microfinance is widespread in India, and with one of the researchers speaking Hindi, India became our choice of case study. A grounded theory methodology is applied in order for us to learn as much as possible about the context of microfinance in India.Within the context, we look for the mission and the impact of the various institutions. Analysis is done through the constant comparison method; with comparisons within and between different organizations. Each organization is individually analyzed to find recurring themes, always being open to the emergence of new themes. Then, the organizations are compared with others of the same legal form, and finally with all other forms of organizations.Several different kinds of institutions are identified, working directly or indirectly with providing small loans to low-income individuals. These institutions include banks, local area banks, section 25 companies, NGOs, and cooperative societies.Each one of the institutions has, by law, different areas of restriction and the study finds that the missions of the various organizations can be linked to their legal form; the mission indicating which form they currently operate under or which legal form they are striving to achieve.The major difference between the various legal forms is their methods of accumulating finances, and how they manage their revenue. Although banks actually earn profits, they have not yet been fully commercialized, as they are restricted from attracting mainstream international capital.The conclusions indicate that in India, microfinance has not reached the point where it has been fully commercialized, but rather the passion for their work and visions of the founders very much guide the work of the various organizations.This can be seen in the missions that guide the organizations and the services provided to fulfill the mission. Commercialization is however, far from a non-issue. If legislation regarding IPOs is changed, the level of commercialization and competitive scene for microfinance in India could change dramatically.",Economics and Finance
"This project aims to add empirical evidence to the corporate finance literature by looking at two main financing issues, namely firms’ payout policies and capital structure decisions, in the context of emerging markets.The project consists of seven chapters, including five main standalone research papers. After an introductory chapter, the first research paper reviews the existing literature on the dividend policy controversy with an emphasis on recent empirical work.The following two chapters consist of two research papers which look separately at the dividend and capital structure decisions of firms in India and in Mauritius.In the second research paper an agency model of dividend policy is estimated and tested on a sample of Indian firms using Weighted Least Squares methodology. The third research paper applies panel data procedures to estimate and test a model of the determinants of leverage, using the entire population of non-financial quoted firms in Mauritius.The last two empirical papers investigate how affiliation with an Indian Business House impacts on the dividend and capital structure decisions of firms. The impact of group-affiliation on the payout decision is tested by Maximum Likelihood qualitative and limited dependent variable techniques.The analysis of the impact of group-affiliation on the capital structure decision is conducted using Ordinary Least Squares methods and incorporates group-level characteristics as explanatory variables.While the main findings of these papers are on the whole consistent with the theory, there are new major insights that represent the special case of emerging markets. These main insights, as well as the main conclusions of the study, are summarised in Chapter 7, including some promising ideas for future research.",Economics and Finance
"Informing outsiders of the potential and quality of the organization in a way that will benefit the organization and avoid putting it at risk is a challenging task in competitive settings. Under conditions of uncertainty, in which external entities are imperfectly informed about the organization, outsiders will seek for alternative signals of quality.Current research of interfirm signaling has focused on the sender’s ability to generate signals. In this dissertation, I propose that receivers of signals are heterogeneous in their ability to interpret signals and that this heterogeneity significantly influences the outcome of the interaction between signaler and interpreter. I apply this insight in an entrepreneurial setting to explain differences in signaling to venture capitalist and informal private equity investors (business angels) over the early stages of a firm’s lifecycle.The findings have strong implications for entrepreneurial firms’ strategy and, generally, to signaling theory. I argue that signals are multifaceted. Outsiders may base their decisions on two aspects of signal: the informative aspect, which relays direct information on the capabilities of the organization; and, the legitimizing aspect, which conveys legitimacy through actions of third-party entities. The use of each aspect is determined by the abilities of the sender to generate the signal and the receiver to interpret it. I posit that the informative aspect of the signal will be prominent when both the sender’s and the receiver’s abilities are high. When either the sender’s ability to generate a signal, or the receiver’s ability to interpret it, is limited, the legitimizing aspect of the signal will be prominent. When both the sender and the receiver possess low signaling abilities, the interpretation will be based on idiosyncratic data.This study explores the differences between these two facets of signals, the relationships between the signal aspects at different stages of the organizational life cycle, and the usefulness of each signal aspect when considering the organization’s target audience. The first essay explains the purpose of the two signal aspects for stakeholders and the interactive nature of the signals’ facets. The two following essays test the theory by utilizing two large datasets of private equity investment solicitations. The second essay evaluates the effectiveness of the legitimizing aspect of the signal as a mechanism for screening startups’ funding solicitations. The third essay compares the informative and legitimizing aspects of signals as decision making mechanisms for both angel and venture capital investors.",Economics and Finance
"PURPOSE:The main purpose of this research is to determine the consumer level approach of brand equity in Citibank N.A using empirical information based on its brand awareness. The awareness of a brand would show the level of the brand recognition. A telephone interview was conducted to explain the different aspects that constitute the recognition of brand equity and brand awareness of Citibank N.A-Cameroon in addition to its ads.RESEARCH QUESTION:How can Citibank N.A, Cameroon subsidiary, measure the level of its brand equity from its brand awareness?RESEARCH APPROACH/METHODOLOGY:In order to answer the research question and achieve the research objective established for this research, a structured research method was required. In this research a qualitative research approach was applied to suit the content of the research. A telephone interview was conducted to give a qualitative view of this research.FINDINGS AND CONCLUSIONS:Awareness (aided, unaided), contributes to the recognition of brand equity. In the empirical part of the thesis brand recognition and awareness can be facilitated by Citibank-Cameroon subsidiary being participative in its social corporate responsibility plan to develop the community by planting trees and organizing football competition every summer holidays. This brand strategy has been used for several years to keep a positive brand image of the bank.",Economics and Finance
"Essay 1, Constrained Capacity and Equilibrium Forward Premia in Electricity Markets, develops a refinement of the equilibrium electricity pricing model in Bessembinder and Lemmon. The refined model explicitly accounts for constrained capacity, an important feature in electricity markets.Explicitly including a role for capacity allows the model to reproduce the price spikes observed in wholesale electricity markets. The refined model implies that the equilibrium forward premium, defined to be the forward price minus the expected spot price, is decreasing in spot price variance when the expected spot electricity price is low, but is increasing in the spot price variance when the expected spot electricity price is high. Further, the refined model implies that, ceteris paribus, the equilibrium forward premium is increasing in the ratio of the expected spot electricity price to the fixed retail price. The implications of this model are closer to reality.How does currency return volatility evolve over time and what are the properties of volatility dynamics? Is the drift of currency return volatility non-linear? What forms of non-linearities are admitted in the drift and diffusion functions? The purpose of essay 2, Estimation of Continuous-Time Models for Foreign Exchange Volatility, is to estimate a large class of volatility processes and explore these issues using weekly data on two currency pairs: U.S. dollar-British pound and Japanese Yen-U.S. dollar.The estimation approach is based on maximum-likelihood estimation that relies on closed-form density approximations. Based on volatility implied by currency options, the constant elasticity of variance specification provides a reasonable characterization of the variance of variance function. Extending the diffusion function beyond the CEV specification does not improve the fit of the model, regardless of the assumed form of the drift function. Further, I find that certain types of non-linearities in the drift function improve the goodness of fit statistics, though no generalizations can be made.",Economics and Finance
"Prior research has identified the manner in which human capital, social capital, and other intangible resources create value for organizations. Among such resources, those contributed by a firm’s top managers have been singled out as particularly important for the generation and preservation of competitive advantage. However, the costs incurred to gain access to these resources, which reside at the individual and relational levels rather than at the firm level, are rarely considered.In this study, I focus on individual executives as the level of analysis instead of the traditional view of firms as unitary actors in order to study intra-organizational value appropriation. I focus on the most direct and economically significant form of value appropriation by top managers: executive compensation.I introduce a theoretical framework linking executive compensation to executive-level intangible resources including human capital and social capital. I distinguish between generic and firm-specific forms of capital due to differences in the causal mechanisms linking each type of resource to compensation.Generic resources convey market power and are directly appropriable by executives. Firm-specific resources have no value outside the firm and therefore do not convey market power, yet they will convey a different sort of power derived from familiarity, visibility, and legitimacy. Drawing on a sample of 71 executives from 36 publicly-traded US firms in high-technology industries, I provide empirical results that are broadly supportive of three of four hypotheses.Executive compensation is found to be positively related to generic human capital (measured by the breadth of executives’ experience across multiple industries), generic social capital (external network size, external network range) and firm-specific social capital (the strength of intra-TMT ties, internal network size, criticality of internal ties, criticality of external ties).I find no evidence linking executive compensation to firm-specific human capital. These results demonstrate the hazard of focusing on the value created by human capital and social capital without also considering the costs firms incur to access those resources.",Economics and Finance
"Financial securities market regulation is subject to increasingly rapid reforms. Despite the political interest in different forms of reforms, economic analyses of the rationales for specific securities market regulation are primarily focused on specific issues such as insider trading. An overall analysis of securities markets regulation is rare.The purpose of this paper is to fill this gap. I identify three reasons – based on market failures – for specific securities market regulations, systemic risk, investor protection and efficiency problems. The systemic risks first emanate from the clearing and settlement systems and second stem from the financial intermediaries’ substantial dependence on securities markets for funding and risk management. Regulation may also be warranted, for efficiency reasons, due to externalities in the markets.The investor protection arguments are more problematic. The most persuading argument is based on a combination of a) the principal agent problem, b) the free riding problems resulting in monitoring difficulties, c) the long-term aspect of many investment services, and d) an assumption that the public sector has a responsibility for some minimum living standards. I also analyze why securities markets should not be regulated based on a) an analysis of the motives of the regulator, b) the potential of creating negative side effects, c) moral hazard, d) enforceability, and e) the risk of consumer over-protection.The paper further discusses the pros and cons of self-regulation, as well as some trends affecting the regulatory process presently. Finally, the paper concludes with some policy recommendations. First, there is a risk that the new EU-wide securities regulation in practice will lead to a government re-regulation, at the expense of well-functioning self-regulations.Second, even though the EU regulatory harmonization has the objective of increasing competition by creating a single market for investment services, there is a clear risk that it will hamper a necessary regulatory competition. Third, there is a clear trend of motivating new regulations using consumer protection arguments, without a serious discussion of the market failures involved. A larger focus on such an analysis is necessary.",Economics and Finance
"The first essay provides theory concerning the risk-taking incentives of microfinance borrowers in varying cases: individual liability, group liability without social sanctions, and group liability with social sanctions.The results provide insight into how a community’s social capital and a country’s credit rights interact to induce recipients of microfinance programs to take risk. Consistent with recent anecdotal evidence that suggests a “dark side” to microfinance, the results show that communal ties among joint liability borrowing groups may not lead to higher repayment rates and may have worse welfare effects on the recipients by making the poorest group members unwilling to take the risks necessary to grow a business.The second essay considers floating rate convertibles (FRCs). FRCs are a category of PIPE securities that receive negative associations in both the academic and professional literature. This study sheds light on the managerial relationship to the decision to issue FRCs and to the variation in market response to these issues. One main result of the study identifies influence of the CFO relative to the CEO as significant in the decision to issue FRCs and in the market’s immediate reaction to the issuance. Another main result is that FRC issuing firms with CFOs without prior public equity issuance experience have significantly negative long run abnormal returns, whereas FRC issuing firms with experienced CFOs do not.",Economics and Finance
"This project studies two related issues that have gained relevance as a consequence of several of the major currency crises of the 1990s. The first is the impact that devaluations have on investment when domestic firms have currency mismatches, i.e., debt denominated in foreign currency and assets and revenues in domestic currency. The second has to do with the causes behind the widespread presence of currency mismatches in many economies of the world.Chapter 2 analyzes the first issue using firm level data for Thailand to test for the impact of currency mismatches on firms’ investment during the Asian crisis. A key feature of the analysis is that it exploits the heterogeneity that exists in the degree of currency mismatch across firms in order to identify the mentioned impact.The results of this chapter suggest that currency mismatches played a statistically significant role in explaining the investment decline observed in Thailand during and after the Asian crisis, and, as a result, that a balance sheet channel may have operated during the crisis.The results also suggest that omitting complementary explanations of the Asian crisis, in particular the presence of over-investment prior to the crisis, produces an artificially high impact of currency mismatches on investment. This result occurs due to the co-movement that investment and currency mismatches have in the period preceding the crisis. Chapter 3 assesses the generality of the results of the previous chapter by analyzing other three countries that were involved in the Asian crisis: Indonesia, Malaysia, and South Korea. Although less robust due to data limitations, the analysis is still very insightful.Chapter 4 deals with the second issue mentioned in the first paragraph. The chapter proposes a model that emphasizes the incentives of domestic governments to generate opportunistic devaluations in order to transfer resources from foreign lenders to domestic borrowers in case debt contracts were denominated in domestic currency. The model is not only able to explain why firms end up having currency mismatches, but it is also consistent with several of the stylized facts associated with international capital movements.",Economics and Finance
"It is fact that one of the main reasons why a country is considered developed or developing lies on its industry development level. A nation without a well-developed industry does not create jobs enough, thus wealth to keep its population on high standards. It is critical to a nation have its national enterprises boosting employment and developing internal technologies, which is the driving force behind innovation.Thus, small companies pose a tremendous opportunity to allow expansion and development; however one of the main constraints avoiding it is due to the difficulty in providing financial funds to entrepreneurial ventures, which is the main track of this study.This study was based in two “newly industrialized countries” (Bozyk) (Brazil and Thailand) by analysing entrepreneurs in terms of how they have got seed funds to start their business, what they think about other options of start-up financing and if they would open a new company, would they choose a different source of funding? Moreover, a comparison between the two countries is assessed showing commonalities and differences between them, demonstrating the most viable seed funding options in the entrepreneur’s perspectiveas the completion of this study.",Economics and Finance
"Real estate industry is a new economic growth point and main industry in Chinese gross domestic product nowadays. This paper analyzes the trend of Chinese real estate market development to help investors to understand the current situation of Chinese real estate markets and policies better, so as to make better real estate investment decisions in China in the future.Because of oversaturated with investment and higher cost of investment there are more and more limitations in investing in big cities in China. With the rapid development of the economy, the huge inner demand of real estate is increasing in medium and small sized cities.Some investigations show that there are huge spaces of the appreciation in Chinese real estate market in medium and small sized cities. The author will describe and analyze the investment strategy and development of Fuxing Huiyu Real Estate Corporation as a case study.The demonstrated company is a public company with rapid growth in a medium sized city named Wuhan in the central part of China. Other investment companies or real estate companies could get some ideas by analyzing the development and decision making process of this company.",Economics and Finance
"Today, neither employees nor employers seem to take for granted that a person will stay with the same firm until retirement. Yet, keeping employees for longer periods is an important challenge for firms. One industry where retention is interesting is the auditing industry in Sweden, this because certain requirements are needed to become an auditor.Firstly, the employee needs to have a Swedish university degree, including specific courses within auditing/accounting. Furthermore, the person needs practical experience for a specific period of time. Due to these statements the challenge of retaining and motivating valuable employees is crucial for the auditing firms, which is why we have chosen to do a case study at Auditing Company X to see how they work with employee retention.We have compared the findings to our chosen theory, which consist of four categories: the hiring process, internal labor market and career, motivation and performance, and finally culture and leadership. These four categories are initially based on Leigh Branham‟s book: Keeping the people who keep you in business: 24 ways to hang on to your most valuable talent.In our conducted case study, at Auditing Company X, we have been able to conclude that the firms retention practices are to a great extend in line with the theoretical framework. There are some areas that need further attention from the company, such as an individualized reward system and communication between managers and employees. Even though there are some parts to work on the most important aspects of retention, such as having a holistic and long-term orientation, Auditing Company X seems to have incorporated this into their practices successfully.",Economics and Finance
"The subject of corporate governance and its role to define and guard the rights and duties of all the participants of corporate culture is so important in the financial and economic system of the business world that all the financial growth models prepared in the history of the economics are based on the assumption of efficient, just and effective corporate governance structures of the business units and the society, it has been and will be a subject under scrutiny for further discussion because of its importance in various dimensions of human economic actions.This paper tends to explore the impact of board composition and ownership concentration on the financial performance of the company particularly in Pakistani capital market, this impact has been analysed by various researchers in different parts of the world for the research purposes.They found positive, negative and mixed results. Very limited research work has been done for Pakistani capital market so it is the need of time to do more in-depth study for this capital, particularly after the world-wide financial crises of 2008.For our research study, we reviewed not only the previous researches and literatures from world-wide capital markets but also examined the local researches on the impact of the ownership and board composition on the firm performance in the listed companies of Pakistani stock market. The sample for this research paper is consisting of two hundred (200) listed companies in Pakistan.A positivist, deductive and quantitative approach has been adopted to analyse the impact  of ownership and board composition on the financial performance of the companies. We have used Tobin’s Q and ROA as measures of financial performance of the sample companies, and analysed the variation of these variables with respect to the ownership and board composition variables of the sample companies.On the basis of our correlation results; it is reported that for the board composition factors, we find significant correlation between board size and the firm’s financial performance, where as we could not find any significant correlation of the female percentage in the board and independent directors percentage in audit committee with the financial performance of the company.For ownership composition we found the significant relation between the associated  companies’ ownership percent age and the financial performance of the company. Where as we could not find any significant relation of ownership held by financial institutions, and ownership concentration on the financial performance of the company in Pakistan.Finally after considering all the results driven from the sample under analysis, this paper concludes with the understanding  that there is significant relation between the board size and associated companies ownership on the financial performance of the company. However this topic requires further exploration because there is so much diversity of perspectives in this circumstance.",Economics and Finance
"Background: Growth oriented entrepreneurial businesses need funding for the development of their idea, technology, product etc. However, for the businesses in the very earliest stages of development, access to funding is very limited. Growing young ventures are important job creators and positively affect growth in an economy. Bridging the gap of funding to these companies is therefore on the agenda of governments around the world.Purpose: To describe the situation facing seed stage investing venture capitalists. I will emphasize difficulties and evaluate venture capitalists ability in addressing them. Effects of the difficulties in form of access to financing for entrepreneurs and a possible need for government intervention will be examined.Method: Empirical information from seed stage investing venture capital organizations have been collected in the form of face-to-face interviews, email- questionnaires and a telephone interview. Organizations from Sweden, Denmark and Germany are included in the study.Result: Several factors make seed stage investing unattractive compared to later stages. Important difficulties are higher risks, high costs for fund management, goal in congruence in the investor – venture capitalist relation and lack of bargaining power for seed venture capitalists. Environmental factors that have an impact on seed investing are the deal flow, the investment climate and access to soft funding. Seed stage investing is a very challenging business and the difficulties are to a large extent hard to overcome. The investors more likely have to accept them and I conclude that long term profitability of seed funds is unlikely, at least in absence of government support in form of soft funding towards the entrepreneurial businesses.",Economics and Finance
"Globalization and deregulations have increased competition in the marketplace, as nowadays it has become much easier for companies to cross borders and compete internationally. The increased competition, on its behalf, has made organizations to constantly try increase their productivity and decrease their costs. One way for them to achieve that is by investing in information technology.Using an already developed model for measuring the quality of online services, the thesis authors have developed and later on modified a theoretical model (instrument) for measuring the quality of online banking services in particular. Using quantitative research method including the design and distribution of a questionnaire, empirical data was collected on which statistical analysis has been performed.As a result of the conducted analysis, the initial theoretical model has been modified, so as the final version of the model (instrument) for measuring quality of online banking services includes four quality dimensions (Service Performance, Website Characteristics, Communication and Efficiency) with total of 17 items (questions).Furthermore, based on the modified theoretical model, customer satisfaction with different aspects of the online banking services has been evaluated. Based on the results of the Analysis of Empirical Data, managerial recommendations are given. Suggestions for further research on quality of online banking services are also offered.Contents1 Introduction1.1 Background1.2 Problem Discussion1.3 Purpose1.4 Research Questions1.5 Delimitations1.6 Definitions1.7 Disposition of the Thesis2 Theoretical Framework2.1 Traditional Services2.1.1 Definition and Characteristics of Services2.1.2 Traditional Services Quality2.1.3 SERVQUAL2.1.4 Studies on Traditional Banking Services Quality2.2 E-Services2.2.1 Definition and Characteristics of E-services2.2.2 E-services Quality2.3 Online Systems Quality2.3.1 Definition and Importance in Relation to the Study of E-service Quality2.3.2 Studies on Online Systems Quality2.4 E-Banking Services2.4.1 Definition and Types of E-Banking Services2.4.2 Studies on E-banking Service Quality2.5 E-SQ (E-S-QUAL and E-RecS-QUAL) Instrument for Measuring Online Services Quality2.6 Summary of the Theoretical Framework3 Methodology3.1 Research Approach3.1.1 Quantitative and Qualitative Research Methods3.2 Sample Selection3.3 Data Collection3.4 Data Analysis3.4.1 Cronbach’s Alpha Test of Reliability3.4.2 Principal Component Analysis3.5 Reliability and Validity3.5.1 Reliability3.5.2 Validity4 Empirical Data and Analysis4.1 Missing Data4.2 Descriptive Statistics4.3 Cronbach’s Alpha Test of Reliability4.4 Principal Component Analysis4.5 Cronbach’s Alpha Test of Reliability on the Modified Theoretical Model4.6 Modified Theoretical Model4.7 Descriptive Statistics Analysis (based on the modified theoretical model)4.7.1 Analysis by Quality Dimension4.7.2 Ranking Satisfaction & Dissatisfaction Levels of Customers on Different Quality Dimensions4.7.3 The Special Case of Föreningssparbanken (FSB)5 Conclusion and Discussions5.1 Conclusions5.2 Discussions5.3 Managerial Recommendations5.4 Further ResearchReferencesAuthor: Kenova, Vasya & Jonasson, Patrik",Economics and Finance
"Working capital management refers to the administration of all aspects of current assets, namely cash, marketable securities, debtors and stock (inventories) and current liabilities. The financial manager must determine levels and composition of current assets. He must see that right sources are tapped to finance current assets, and that current liabilities are paid in time. He must see that right sources are tapped to finance current assets, and that current liabilities are paid in time.There are many aspects of working capital management, which make it an important function of the financial manager:• Time: working capital management requires much of the financial manager’s time.• Investment: working capital represents a large portion of the total investments in assets.• Significance: working capital management has great significance for all firms but it is very critical for small firms.• Growth: the need for working capital is directly related to the firm’s growth.Investment in current assets represents a very significant portion of the total investment in assets. Working capital management is critical for all firms. A small firm may not have much investment in fixed assets, but it has to invest to in current assets. Small firms in India face a severe problem of collecting their debtors.Banks have their own policies to assess the working capital of the firm to finance them with the shortage. Bank of Maharashtra adopts certain method for financing their customer’s working capital requirements. There are certain recommendations from the committees for the banks to finance the working capital needs of their clients.It may, thus, be concluded that all precautions should be taken for the effective and efficient management of working capital. The finance manager should pay regular attention to the levels of current assets and the financing of current assets.Download Project",Economics and Finance
"This paper examines the value-relevance of Scandinavian earnings information and book values over the past decade in order to shed some light on whether the extensive global adoption of IFRS/IAS has contributed to an increased accounting quality in terms of economic decision-usefulness to equity investors.We address this research question using a sample of 4.310 firm-year observations for 431 exchange-listed companies at NASDAQ OMX Nordic and Oslo Stock Exchange between 2001 and 2010. The degree of value-relevance in our firm-sample is operationalized through two price regressions and one return regression and empirically tested via the statistical association between capitalized values of equity or annual changes in capitalized values of equity and the study’s three explanatory accounting variables: (i) book values, (ii) accrual-based earnings and (iii) cash-flow-based earnings.Taken as a whole, our results show significant empirical signs of an increased value-relevance in both Scandinavian earnings information and book values, allowing us to draw significant as well as contributing conclusions on the information content of financial statement information disclosed in the Scandinavian region. We believe our study adds empirical substance to practical debates over the function of financial reporting as well as resourceful material to both Scandinavian investors and to the ongoing international discussion on the harmonization of financial reporting standards.",Economics and Finance
"The study investigates the role of networks and connectedness on CEO and director labor market outcomes. I develop new measures of degree, closeness, betweenness, and eigenvector centrality using a new database of executive connections based on executive and director biographical information supplied by BoardEx.I then study the influence of networks and connectedness on CEO labor market outcomes, including new CEO appointments, CEO termination, and CEO compensation. I distinguish between the pairwise specific CEO-board connectedness and the strength and structure of the CEO’s overall connectedness.I find that both types of connectedness add to traditional turnover and compensation variables in distinct and economically significant ways. Specific connectedness increases CEO entrenchment. Greater overall CEO connectedness on the employment network results in greater likelihood of CEO departure, greater turnover-performance sensitivity, and more rapid re-employment of a departed CEO.The existence of specific links between the CEO candidate and the board of directors enhances the chances of appointment in the event a company chooses to appoint an outsider as the CEO. Finally, CEOs with better overall connectedness enjoy higher total compensation.The evidence suggests that the general connectedness of a CEO in the employment network has significant and distinct economic effects beyond those of the connections between the CEO and the board in the current firm. In the paper “On the Independence of Independent Directors”, I examine director appointment and replacement decisions after a new CEO assumes office. A new incoming CEO can make many changes in the size and structure of the board and influence on the types of individuals that populate it.I assess the role played by prior connections between the CEO and outside directors, including the overlaps established through common employment history, educational background, and other activities. I also test the nature of these changes in specifications that model CEO and director changes jointly.I find that with a higher proportion of professionally connected outside directors on the board, the CEO is more likely to stay. New CEOs reshape the board in the early years of their tenure rather than later years when they may have more power and influence. Conditional on CEO continuation, outside directors that are of similar age to the CEO and share common employment antecedents with the CEO are less likely to be replaced. Replacements of unconnected directors are accompanied by appointments of connected directors. I discuss the implications of the findings for research and practice.",Economics and Finance
"This project examines the impact of foreign portfolio investment on the financial constraints of small firms. Utilizing a dataset of over 195,000 firm-year observations across 53 countries, I examine the impact of foreign portfolio investment on capital issuance and firm growth across countries and firm characteristics, in particular size.After controlling for firm, industry and country-level characteristics such as change in foreign exchange rate, share of market capitalization, relative interest rates and investment climate, I find that foreign portfolio investment helps to bridge the gap between the amounts of financing small firms require and that which they can access through the capital markets. Specifically, I find that foreign portfolio investment is associated with an increased ability to issue publicly traded securities for small firms in all nations, regardless of property rights development.For those small firms that do issue, the form of capital appears to be debt. Since small firms often rely heavily on bank lending, I also test for potential increases in credit for small firms utilizing the bank lending theory of monetary transmission. Results show significantly decreased short-term debt and increased long-term debt, supporting the contention that bank debt maturity to these firms has increased. This transition to longer-term debt could also be as a result of the increased public debt securities these firms are more able to access.The overall increased access to capital only leads to value-enhancing growth at the firm level in nations with more developed property rights. I find that the volatility of foreign portfolio investment is significantly negatively associated with the probability of small firms issuing publicly-traded securities as well as their firm growth, in periods when their domicile nations are deemed less ‘creditworthy.’ Results underscore the significance of a good financial system that minimizes information asymmetry and enhances liquidity, as well as property rights and country creditworthiness, to instill confidence in foreign investors.",Economics and Finance
"Nowadays, the skyrocket price of residential house due to lack of houses in cities becomes a crucial problem in China.The development of commercial real estate industry is not only an emerging real estate industry, but also plays a mediating role in solving the problem of lack of houses and high-price to some extent, as a mature commercial real estate market in the city gives birth to a core business centre in the downtown and many sub-business areas in different districts in the city.It is able to create jobs in different areas and to spread the population more averagely. Instead of gathering everybody in the centre, it is going to solve the problem of imbalance of supply and demand for houses and the high price in some areas, which is especially important for the big cities in China like Beijing, Shanghai and Guangzhou.This study is going to explore some new financing options for the small and medium-sized commercial real estate developers and provide some suggestions accordingly. Financing options like REITs, real estate fund, CBMS and mezzanine financing are discussed.In addition, taking Guangzhou, one of the first-tier cities in China, as a case study we have gained a further understanding of the real financing problems in commercial real estate. Some suggestions on the financing options of small and medium commercial real estate developers are proposed according to the academic and practical experiences.",Economics and Finance
"Over the past twenty years, write-offs have grown in popularity. With the increased usage of write-offs, it is becoming more important to understand the mechanisms behind why companies take write-offs and how write-offs affect company performance.In this paper, I examine the cross-sectional determinants of the decision to take write-offs. I use a hand-collected dataset on write-offs that is much more comprehensive than existing write-off datasets. Contrary to much hype and scandals surrounding a few write-offs, I find that quality of governance is positively related to write-off decisions in the cross-section. My results also suggest that poor governance companies wait to take write-offs until it becomes inevitable, while well-monitored companies take write-offs sooner. As a result, the charge is substantially larger than the average write-off charge.When these poor governance companies announce write-offs, the announcement generates negative abnormal returns. However, when good corporate governance companies announce write-offs, the charge is substantially smaller than the average charge. These well-monitored companies take write-offs immediately following a problem. Following the write-off announcements of these types of companies, average announcement day effects exceed a positive six percent. These results suggest that companies with quality monitoring mechanisms use write-offs in a manner that is consistent with enhancing shareholder value.In my second essay I examine the effect of write-off announcements on the stock market liquidity of firms taking write-offs from 1980 to 2000. I find that there are substantial improvements in stock market liquidity following corporate write-offs. Spreads decrease and turnover volume increases after write-off announcements, which indicates an improvement in liquidity. The liquidity improvement is greater for better governed companies. I decompose bid-ask spreads and show that adverse selection costs decrease substantially as market participants respond to the write-off announcement. The evidence suggests a liquidity benefit of write-offs that must be weighed against any other perceived cost of write-offs. Such a liquidity benefit may validate that write-offs convey favorable information about the firm.",Economics and Finance
"Today problems exist with how the leases are recognized in public companies that uses the IFRS. The liability to make lease payments is not recognized as a liability in the balance sheet even though it should according to the current lease accounting standard.There are two different classifications of leases, financial and operational, where the latter means that the liability to make lease payment does not end up in the balance sheet. Today many lease contracts are tailored to be classified as operational to avoid the liability on the balance sheet.The problem described above has for long been known and the international accounting organisations, IASB and FASB, have been working on a solution to the problem for many years. The project’s completion in form of a new standard has been postponed several times and it is currently scheduled for the earliest to entry into service during 2013.This study aims at investigating the IASB’s and FASB’s joint project to solve the lease accounting problem and its effects on the Swedish commercial real estate market.The approach adopted in this thesis is to examine the available literature about the problem and the project and to conduct interviews with expert in the field and possible future stakeholder that will be affected.The conclusions of the study are that the effects due to the project will mainly be for the lessee and then indirectly for the lessor. The lessees will try to find solutions like shorter leases to avoid the biggest effects of the new standard but to what extent they will avoid these remains uncertain. The lessor will most likely see a higher demand for shorter leases that will increase the risk in the lessors business. This will probably cause higher rental prices for listed companies.",Economics and Finance
"Credit rating systems are complex processes and involve mainly two parties; a company and a bank. The complexity of a relationship between a company and a bank lies in the fact that a company usually has access to more information about the company than the bank. Hence, an auditor acts as a third party who validates the information involved in credit rating processes.The purpose of this dissertation is to explore how auditing is being used in credit rating processes and to identify the role auditing has. In addition, this study recognizes the use of auditing in both Denmark and Sweden, with a goal to compare and explore the differences between the countries.In order to collect secondary data, Danish and Swedish banks were interviewed. To be able to explore the rather newly discovered relationship between auditing and credit rating processes, this study was carried out with an exploratory research design. In addition, this study is based on assumptions stated in the Agency Theory, the Positive Accounting Theory and the Stakeholder Model. Because the intention was to use existing theories, a deductive research approach was suitable.The empirical findings imply that auditing is being used in banks’ credit rating processes to validate the information and to reduce the risk. The trustworthiness of auditors and the relationship between a company and a bank influence banks’ perceptions regarding the creditworthiness of companies. The role of auditing is rather common in Denmark and Sweden, whereas the amount of accessible information is higher in Sweden than in Denmark. The pattern is that more information diminishes the risk and implies that the role of auditing is less important.This study is limited to only taking the bank’s perceptions of auditing into consideration, leaving out other stakeholders. Moreover, the examination is restricted to Danish and Swedish banks. The findings are interesting for banks and small companies to consider, because they explain the importance of auditing other components such as customer relationship. As a conclusion, the findings would be appropriate for Swedish banks to review in order to evaluate possible consequences of the statutory audit.",Economics and Finance
"Stock splits are supposed to be financial cosmetics. However, this study shows that such corporate events have impact on ownership structure. This study exploits unique data from Swedish Central Security Registration regarding ownership and analyzes the ownership structures in stock splitting firms.Our data consists of exclusive semi-annually reported ownership structures of companies listed on Stockholm Stock Exchange. We categorize stock owners as domestic institutional investors, foreign investors and domestic individual investors. The information on ultimate ownership composition in listed companies is rare and more or less exquisite for Sweden.Our results confirm positive abnormal returns surrounding the announcement of stock splits and stock dividends. Moreover, we find evidence on changes in ownership structure as well as number of shareholders. The results show evidence on decreasing ownership concentration due to the stock split, which implies a more dispersed ownership structure.",Economics and Finance
"PURPOSE: The two approaches to audit sampling; statistical and nonstatistical have been examined in this study. The overall purpose of the study is to explore the current extent at which statistical and nonstatistical sampling approaches are utilized by independent auditors during auditing practices.Moreover, the study also seeks to achieve two additional purposes; the first is to find out whether auditors utilize different sampling techniques when auditing SME´s (Small and Medium-Sized Enterprise) and big companies and the second is to find out some common selection methods that are used by auditors for selecting statistical or nonstatistical audit samples during audit sampling practices.METHOD: The population that has been investigated consists of professional auditors residing in Umeå-Sweden.Data for the study was collected by conducting semi-structured interviews and convenient sampling; a non-probability sampling technique was used for respondent’s selection. An interviewed guide was sent to respondents in advance with the objective of giving them the opportunity to have both mental and psychological preparations prior to each interview scheduled date.The semi-structured interview technique was adopted because it was a suitable approach to extract valuable information and in-depth explanations from auditors about the current extent of the use of statistical audit sampling and nonstatistical audit sampling during auditing practices. Ultimately, the selected respondents actively participated in which they thoroughly expressed their views and experiences about audit sampling, statistical audit sampling, and nonstatistical audit sampling.RESULTS: Statistical audit sampling and nonstatistical audit sampling were found to be used most often by auditors when auditing the financial statements of big companies compare to SME´s where nonstatistical audit sampling is most often used.Therefore, both statistical and nonstatistical samplings are in dominant utilization by auditors in Sweden. Audit samples are selected through random selection method and systematic selection methods when using statistical audit sampling and for nonstatistical audit sampling; items are selected by the use of professional judgment.However, auditors in Sweden are more inclined with the use of random selection method for statistical audit sampling and their professional judgment for nonstatistical audit sampling. The main reasons for the auditors using both statistical audit sampling and nonstatistical audit sampling are to minimize risks and to guarantee high quality audit.The conclusion of the study was that auditors in Sweden use both statistical and nonstatistical audit sampling techniques when auditing big companies, use nonstatistical audit sampling when auditing SME´s, select samples using random selection method and systematic selection method for statistical audit sampling and for nonstatistical audit sampling, items are selected within the parameters of their professional judgment.",Economics and Finance
"This thesis report presents the process which has been followed to develop a large real estate project in São Paulo, Brazil where the buildings remaining on the site are landmarks. The report includes an extensive case study the Matarazzo Project about which I performed the analysis of the procedure of development during my internship at SCPM – a French Project Management company.The ultimate goal of the thesis is to provide investors with brief recommendations to develop similar project in Brazil with respect of the cultural values. A French Investor intends to develop the Matarazzo Project – a large and complex real estate project in São Paulo, Brazil – on a site defined as a national and municipal landmark by public authorities, respectively CONDEPHAAT and CONPRESP, due to the remaining buildings erected from 1904 which are witnesses of the well-organized institutions of Italian immigrants.The protection of the existing buildings involved a particular procedure to apply for permits. Indeed, it implies the presentation of the project to several organs such as IPHAN, CONDEPHAAT , CONPRESP, SEHAB, SMT, DEPAVE, etc. with a list of required documents – TAC , Projeto de Restauro, Relatorió de Impacto de Vicinhenza, plans, layout, renderings, etc.Thus, to apply for building permits such a situation implies a selected numbers of particular consultants as a Legal Authorization Specialist, Retrofit Specialist, DEPAVE Specialist, Cultural Centre Specialist , lawyers, added to the stakeholders normally present during the development of a real estate project – architects, engineers, land surveyor, quantity surveyor , insurance companies, etc.The case study involved, at this stage, more than 23 entities (2 from the Direction, 3 from the Supervision, and 18 from the Executive Stakeholders) The combination of actors was such because I realized my internship at an early stage of the project – maybe the earliest. Indeed, when I started, the Master Plan had not been defined yet and the Work Cost Estimate had not been performed, even though the Project Manager already had an idea about the overall schedule and was hiring the appropriate stakeholders.By now, the Master Plan has been fixed and shares both green and brown field areas. The existing buildings will host a Retail Centre (18.000m²) surrounded by glazed roof, a Palace Hotel (10.000m²), the Chapel remains a religious place, the Paediatric will be replaced by a Village Hall (500m²). Underground constructions will be located all above the site with a Cultural Centre (18.500m²) and a Parking Lot (55.000m²). Plus, depending on the Right-to- Built, a Tower (21.000m²) will be erected near the Ponta.Consequently, in terms of time, the Project Manager forecasts the whole project to last no less than five years – including legal documents approvals and works execution. In terms of budget, a Work Cost Estimate – more or less accurate depending on the level of completion of the plans of each specific area – has been done so that the Client can start to set up the Business Plan and develop the strategy to finance the project – finding financers, operators, tenants, etc. Having work more than five months on the Matarazzo Project enables to make an analysis of what the situation had been and what it should be.It is crystal clear that mentalities and ways of proceeding between France and Brazil are different. Nothing is said but that is the role of the consultants to establish what strategy to choose, or to state things such as what is allowed to build, how to build, etc. Nothing is written either, indeed there is no code of construction, barely a Código de Obras e Edificações which define for which permit to apply depending on the work to perform.So, the spirit is ‘ do as best as you can and let’s see if will be accepted by legal authorities’. And conflict is avoided – problems are not pointed directly, they last and they became bigger putting the whole project on hold. The solution to all this has been to hire a Project Manager Assistant to work directly from there, increasing communication between France and Brazil, making researches about similar projects, and trying to keep everyone on the right track cause – due to the size of the project – minor points are often forgotten and became major points.For the future, the Project Manager starts to forecast the whole organization of the project, in particular for the detailed conception and execution phases. Regarding the work breakdown structure, to simplify communication proceeding having one representative for the architectural team and one general contractor is the favourite option despite the disadvantages it implies (information retention, increased fees for management of sub-contractor, etc.).The analysis of the procedure of development of a large real estate project in São Paulo, Brazil has resulted in future recommendations on what attention should be focused on. In short, the recommendations include the following: Being aware of local culture and local way of proceeding (steps of development, local institutions, subsequent required documents); Having a good intern organization (being aware of what is due and by who); For more details on the future recommendations, cf. chapter 6.",Economics and Finance
"This study examines the impact of working capital management on cash holdings of small and medium-sized manufacturing enterprises in Sweden.The aim of this work is to theoretically derive significant factors related to working capital management which have an influence on the cash level of SMEs and test these in a large sample of Swedish manufacturing SMEs.The theoretical framework for this study consists of a treatise of motives for holding cash, working capital management and cash level. From these theoretical findings, two hypotheses are deduced:• H1: Cash holdings are negatively related to the presence of cash substitutes• H2: Cash holdings are positively related to working capital management efficiencyThe quantitative investigation consists of the statistical analysis – namely comparison of means and correlation analysis – of key figures which are calculated from the financial statements of a large sample of firms. The dataset contains 13,287 Swedish manufacturing SMEs of the legal form ‘Aktiebolag’. Both hypotheses are confirmed by the results. Empirical evidence is presented which substantiates the supposition that the presence of cash substitutes – namely inventory and accounts receivable – entails lower cash holdings.Furthermore, it is confirmed that working capital management efficiency – measured by the cash conversion cycle – is positively related to cash level. The discussion of the empirical findings pays regard to the different subordinate components of both cash substitutes and working capital management efficiency. Implications of the detected findings are highlighted with respect to their potential utility for the achievement and maintenance of a firm’s target cash level.",Economics and Finance
"The purpose of this research is to generalise the results of the 2000-2010 period development of the Swedish real estate market for FDI and provide a better understanding of it from the point of view of foreign investors.The approach used in the thesis was based on deductive method assuming previous theory and research. Quantitative data relies on both scientific and media sources, qualitative empirical data – on questionnaires filled in by companies involved in real estate FDI process.The study addresses the changes of macro and micro economical issues, cultural, political, geographical patterns, changes of market characteristics, investor preferences and provides an overview of both classical investment theories and FDI theories.The results of current research show that within the indicated 10-year period the major changes in the Swedish property market where: increased difficulties with obtaining finance, higher selectiveness when choosing investment objects, increased use of structured deals, greater importance of diversification, decreased risk and yield levels.The thesis originates from the prior research in the field by KTH scholars – Axelsson, Victrorin (1999), O’Connor (2003) and Falk, Olsén (2009). The main contribution of the current research is adding to the knowledge about real estate FDI and quantifying the changes during the long time-horizon – 2000-2010 period considering both “economical rationale” and “behaviour rationale”.Present research may be useful for further investigations in the property FDI area, can provide information for foreign investors about the historical development of the Swedish market and be helpful for analyzing or choosing FDI market strategy.",Economics and Finance
"Credit derivative has become an important financial instrument in global financial market, it plays significant role in transferring credit risk. During the latest financial crisis, collapse of credit derivative market was a main reason led to this worldwide turmoil.In this thesis, I try to investigate this adverse performance through a case study of Goldman Sach’s ABACUS 2007-AC1. I conclude three major findings. First, severe interest conflicts and asymmetric information existed between counterparties in credit derivative market in U.S..Second, the securities‘ credit ratings provided a downward-biased view of their actual default risks, the yields failed to account for the extreme exposure of structured products to declines in aggregate economic conditions.Third, credit derivatives do not eliminate systematic risk, they just shift the risk, CDOs exchanged diversifiable risk for systematic risk during the structuring process, which was difficult to understand for most of investors, we see risk accumulation rather than spreading risk.",Economics and Finance
"There is growing concern about current web security development. This project looks at common web system designs, the security threats to such designs and the security requirements for a networked system, thus understanding the problems of web system security.The project then analyzes how available security technologies answer the web security problems. The current security technologies can be classified as core security technologies, which provide required security service, and web system specific security technologies, which are the technologies that fit directly into web system security scenario.The analysis shows that current protocol design of the web – HTTP protocol and underlying infrastructure provide almost no security services. Fortunately, add-in security technologies are available with their advantages and disadvantages. The framework is then presented trying to make the most secure web system out of available technologies. Further researches show unsolved security problems and possible direction.",Software Design
"The main goal of the project called Socratenon was to build a new Web-based training environment that would go beyond traditional ones. In the open literature, there are several solutions trying to accomplish the same to a certain degree. Some of them are nothing more but plain virtual textbooks that only flip pages on mouse-clicks.More sophisticated techniques include user modeling in order to personalize the content for the user, adaptive interfaces, intelligent agents for improved assistance and search, neural networks and case-based reasoning for building intelligent back-ends, etc. In general, many existing learning environments lack interaction, full utilization of Web resources is scarce, while solutions utilizing a combination of all above are practically non-existent or in works.This project tried to merge potentials of the new Internet technologies and the latest developments in cognitive sciences, on one hand, with the comfort of learning at the most suitable time and in the most suitable place, on the other hand.The project has been finalized, the package works, and its performance had been tested both objectively and subjectively; it demonstrates superiority over similar solutions from the open literature. Its complexity is such that it can fit even the widespread PC platforms, although it demonstrates the best performance on state-of-the-art corporate platforms.",Software Design
"By exploiting context awareness, traditional applications can be extended to offer better quality or new functions. Utilizing a context-aware infrastructure, a variety of context information is merged and processed to produce information that is useful to applications. Applications exploiting such context can provide more intelligent and creative services to end users.This study examines two ways to make use of a user’s location along with room occupancy information in context aware applications: a Context Agent and a Call Secretary. In the former case, the application subscribes to room occupancy information via a context server, and provides a Meeting Room Booking System with “real-time” information about the utilization of the rooms which the room booking system is to manage.The Call Secretary acquires both location and room occupancy information from a server. When the user is in one of the meeting rooms and multiple people are present, then this is interpreted as the user being in a meeting — therefore it triggers a CPL module in a SIP proxy to redirect the user’s incoming call to their voice mail box. A description of the implementation of these two applications will be presented along with an evaluation of these applications’ performance.The evaluation of the Context Agent showed that it was straightforward to integrate information from a presence source and to extend the meeting room booking system to use this information. The Call Secretary needs a more reliable source for the user’s location. However, given this location the Call Secretary provides the service which the user expects.",Software Design
"In the current arena, rapid changes are required to address dynamic patient’s treatment process needs according to the patient’s demand in the healthcare sector. This research work addresses existing problems about information flow in ward-round, what is the optimal information need for an individual with his/her competences according to their role during ward-round in healthcare area. This work also mentions what are the certain activities which are required during the patient treatment.This research work contributes in the field of Information logistics and ontology development in healthcare. So the main purpose of this thesis is to design an ontology based model that can fix information flow problems in the ward-round process of hospital unit. The ontology based model can be used to provide relevant information to the domain users according to their needs and demands. The ontology based model projects domain users profiling and describes their roles, information demands with competencies: skills, qualifications and experiences. The ontology based model will be implemented in OWL language that can be used in an application to support ward-round activities for achieving effective patient’s treatment process.For ontology development is concerned, different ontology development methodologies have been reviewed from literature review by the author to analyze the existing problems in the ward-round. This thesis incorporates Hybrid Methodology (HM) that helps to develop ontology based model that addresses information flow problems in ward-round. The proposed ontology based model is developed in web Ontology Language (OWL) supported tool protégé 4.0.2 that can be considered as foundation to develop a software product with the help of IT practitioners and developers to fulfill medical practitioner’s demands in ward-round’s context.",Software Design
"Web programming is getting more and more important every day and as a consequence, many new tools are created in order to help developers design and construct applications quicker, easier and better structured.Apart from different IDEs and Technologies, nowadays Web Frameworks are gaining popularity amongst users since they offer a large range of methods, classes, etc. that allow programmers to create and maintain solid Web systems.This research focuses on two different Web Frameworks: Ruby on Rails and Google Web Toolkit and within this document we will examine some of the most important differences between them during a Web development.",Software Design
"Since the beginning of the 21st century mobile phone usage has had a big growth. Together with developed techniques from the Internet conditions for a new market emerged – mobile Internet. Europe, North America and Japan took the lead in this development.Europe and North America developed Wireless Application Protocol (WAP) whilst a Japanese company, NTT DoCoMo, developed their own standard – i-mode – which is dominating the Japanese market today. WAP on the other hand was not a success at all and the usage is still low today in Sweden, even though almost all mobile phones support WAP.The purpose of this study is to, from a user perspective, explain why the WAP usage is so low in Sweden and also explain how i-mode became such a success on the Japanese market. In the thesis we will research mobile phone users needs regarding mobile Internet, and if those needs can be applied to i-mode functionality.We will also compare WAP and i-mode marketing. The result will then explain why the majority of Swedish mobile phone owners do not use WAP. We started out with a literature study, which became the base of our chosen method; a survey. Thus to discover the chosen populations’ needs, demands and degree of usage of mobile Internet. A result was created from the survey data and theories.• People in Sweden tend to use Internet at home instead.• WAP usage today is expensive and has slow bandwidth.• The knowledge about WAP is poor among the Swedish population.• There is no need for mobile Internet in Sweden according to our research.The low mobile Internet usage can mainly be explained with that people in Sweden rather use Internet at home. We are convinced that this is not the main reason though, since this result emerged because of WAPs faults and weaknesses.The majority of these demands can not be satisfied by an i-mode implementation. That is why we do not see i-mode as an alternative to WAP in Sweden. Although if i-mode could use another approach in their marketing they may succeed – like a stand-alone system with unique functions. Using this approach instead of marketing the service as a light version of the Internet, as we see today in WAP.",Software Design
"The existing advanced web browsers in today’s mobile phones open up the door for mobile web applications. By using standard web technologies, a web page can be crafted to mimic the behavior of a normal application.The purpose of this study has been to look at web application development for mobile phones in general and to implement a web-based Mobile TV client to determine whether it would be a viable alternative to existing clients based on other technologies.The advantages are the same as for any other web application: 1) the user avoids the hassle of installing an application and will always run the latest version, 2) developers benefit from the browser’s ability to render generic content, and 3) it is believed that the differences between browser implementations are less than in other environments in which an application would run, for example Java or operating system specific environments.",Software Design
"The aim of this project is to create a user interface for a web based film production project management portal. This implies creating a site map and a functionality specification based on the needs of the people working in the film production industry. The project was made on account of The Chimney Pot, a post production company in Stockholm.For the scope of this project, the research was concentrated on the part of film production that concerns The Chimney Pot, i.e. the procedures that take place after a film has been recorded. The research also focused on people working in the area of Stockholm, even if their clients and customers in other areas of Sweden and abroad were indirectly included in order for the project portal to be a usable tool in projects where these people are involved.Before any visible results can be seen in a web production project, a range of preparation steps needs to be taken. Planning is essential if the final product shall work properly. Extensive research has to be done into the industry. In order to make the product usable, the intended users, their requirements, work procedures and environment need to be examined. Only when there are substantial results and enough knowledge about the industry, the actual implementation can start.The first step is to make a functionality specification, next a site map should be produced and the technical architecture should be specified. These are the areas that are covered in this project, but there are also recommendations about how the further development should be made. Important aspects in the next phase are to create a budget, to put together a development team and to create a graphic user interface. In the whole process the issues of usability need to be considered, i.e. efficiency, flexibility, learnability and satisfaction.The key requirements for the project portal turned out to be speed and effectiveness. The user interface was designed to be intuitive and to be shallow, which means that the user should be able to perform any task with the least amount of mouse clicks possible. Another intention with the produced user interface is for it to be clearly divided into the four main areas that could be extracted from the user requirements. They are planning, project details, communication and file sharing. Directly after logging on to the project portal, the user should get an overview of all these areas. Other important considerations were security, version control and seamlessness. These issues demand a thorough planning of the technical architecture and this thesis provides some useful tips for the further development of the technical specification.",Software Design
"MMS-enabled terminals on the market today are very complicated to use. It takes several steps to create a multi-slide MMS-message with images and text. This discourages users from using it.To increase usage of MMS, several companies provide web-based or stand-alone programs that allow users to create and send MMS-messages from a regular computer. However these editors have many limitations and are not user-friendly.This project describes the design and implementation of a user-friendly web-based MMS-portal where users can create, edit and send MMS-messages. The portal is integrated into Densitet’s system for development of mobile services.Conclusions that can be draw from this work are that problems with MMS interoperability have mostly the poor standardization to blame. Different terminals support different types of images and sound formats, and to make the MMS-portal user-friendly, format conversions of uploaded content had to be implemented. Also the MMS-portal only supports basic MMS-functionality.If the MMS-specification includes more audio and image formats and if the MMS-terminals are upgraded to handle these formats, sending MMS-messages will be easier and mobile messaging will continue to grow.",Software Design
"The Internet has become a valuable channel for both business-to-consumer and business-to-business e-commerce. It has changed the way for many companies to manage the business. Every day, more and more companies are making their presence on Internet.Web sites are launched for online shopping as web shops or on-line stores are a popular means of goods distribution. The number of items sold through the internet has sprung up significantly in the past few years. Moreover, it has become a choice for customers to do shopping at their ease.Thus, the aim of this project is to design and implement a consumer to consumer application for Facebook, which is one of the largest social networking website. The application allows Facebook users to use their regular profile (on Facebook) to buy and sell goods or services through Facebook. As we already mentioned, there are many web shops such as eBay, Amazon, and applications like blocket on Facebook.However, none of them is directly interacting with the Facebook users, and all of them are using their own platform. Users may use the web shop link from their Facebook profile and will be redirected to web shop. On the other hand, most of the applications in Facebook use notification method to introduce themselves or they push their application on the Facebook pages.This application provides an opportunity to Facebook users to interact directly with other users and use the Facebook platform as a selling/buying point. The application is developed by using a modular approach. Initially a Python web framework, i.e., Django is used and association rule learning is applied for the classification of users’ advertisments. Apriori algorithm generates the rules, which are stored as separate text file. The rule file is further used to classify advertisements and is updated regularly.",Software Design
"Usability is an important aspect of product development that deals with the quality of interaction between the user and the product. Capturing requirements is aimed at understanding what the users expect the system to do.This report attempts to apply principles from both the Usability Engineering and the Requirements Engineering methodologies in the development of a subsystem for managing an e-commerce solution. The main focus is on the user interface design, which is developed by iterating the three phases of design, usability testing and evaluation, until the desired level of usability is achieved.Prototyping was central to the rapid development, but the use of software prototyping tools instead of paper-mockups would reasonably have improved the usefulness of the evaluations. The desired usability level was set to reach a specified fix point, instead of attempting to achieve some absolute usability metrics as is typically practiced.The former approach was apparently simpler to use without the broader experience otherwise needed to write reasonable requirements. The transition from the throw-away prototype to the implemented evolutionary prototype in ASP.NET posed some interesting problems that are further discussed.",Software Design
"A carbon dioxide emission calculator for buildings created by the U.S.-based company CTG Energetics, Inc. and based on a Excel file has been converted to a ASP.NET / SQL Server web application. Carbon dioxide emissions are calculated using data given by the user (i.e. floor area, workdays per year) in combination with statistical data used in user-selectable presets (i.e. building type, climate zone, type of water-using fixtures).In most cases a custom value can be inserted instead of using a preset. Emissions attributable both directly and indirectly to the building such as building energy use, domestic water use, landscape/irrigation, transportation, materials used for the building/parking lot and the disposal of solid waste are calculated. The emissions can be compared with a national average and/or emissions from alternate scenarios created for the same building. The web application contains some upgrades and extra functionality that would not have been possible in Excel such as user handling.",Software Design
"Cascading Web Services represent a collection of services offered in a system consisting of multiple devices and multiple interacting platform independent networks. ‘Cascading’ enables Web Services to exploit access in diverse environments without manual intervention.The aim of this thesis is to investigate how Mobile Web Services interact with multiple other Web Services by allowing the generated content to cascade. These services are demonstrated as a technical design solution, in a number of cases within the field of Learning technologies.Communication among devices is preceded using request-response commands by cascading these commands between different Web Services that are self-contained and independent on their context or state.The system signifies a typical Service Oriented Architecture (SOA) based on a distributed system. Cascading Web Services involve multiple transport networks including Bluetooth Technology, GPRS, Wi-Fi, and Wired Networks.Whereas the protocol of this communication is to bridge Wired and Wireless networks for data transactions, specifically from a Bluetooth location-based network. A number of particular cases will be illustrated in the context of ‘educational outdoor activities’, to demonstrate how the system solution works involving users.",Software Design
"As of December 2007, the number of Internet users in China had increased to 210 million people. The annual growth rate reached 53.3 percent in 2008, with the average number of Internet users increasing every day by 200,000 people. Currently, China’s Internet population is slightly lower than the 215 million internet users in the United States.Despite the rapid growth of the Chinese economy in the global Internet market, China’s e-commerce is not following the traditional pattern of commerce, but instead has developed based on user demand. This growth has extended into every area of the Internet.In the west, expert product reviews have been shown to be an important element in a user’s purchase decision. The higher the quality of product reviews that customers received, the more products they buy from on-line shops. As the number of products and options increase, Chinese customers need impersonal, impartial, and detailed products reviews. This thesis focuses on on-line product reviews and how they affect Chinese customer’s purchase decisions.E-commerce is a complex system. As a typical model of e-commerce, we examine a Business to Consumer (B2C) on-line retail site and consider a number of factors; including some seemingly subtitle factors that may influence a customer’s eventually decision to shop on website. Specifically this thesis project will examine aggregated product reviews from different on-line sources by analyzing some existing western companies. Following this the thesis demonstrates how to aggregate product reviews for an e-business website.During this thesis project we found that existing data mining techniques made it straight forward to collect reviews. These reviews were stored in a database and web applications can query this database to provide a user with a set of relevant product reviews. One of the important issues, just as with search engines is providing the relevant product reviews and determining what order they should be presented in. In our work we selected the reviews based upon matching the product (although in some cases there are ambiguities concerning if two products are actually identical or not) and ordering the matching reviews by date – with the most recent reviews present first.Some of the open questions that remain for the future are: (1) improving the matching – to avoid the ambiguity concerning if the reviews are about the same product or not and (2) determining if the availability of product reviews actually affect a Chinese user’s decision to purchase a product.",Software Design
"During the practical use of Design Automation (DA) System in a company, the lack of assistance from either documentation work about the whole system or management of knowledge could bring out some obstacles when engineers reuse existing knowledge and information.The purpose of this project is to explore an approach of documentation and knowledge management in DA System. The study is mainly based on the actual case of seat heater DA system developed by JTH.Based on preset functional requirement for the potential solution, several principles and methods of documentation and knowledge management are introduced such as MOKA, CommonKADS, SysML and PVM. A number of useful applications such as DRed (Design Rationale Editor), PC PACK, Sementic MediaWiki and Product Model Manager became candidates solutions for this project.The selection of final approach was Sementic MediaWiki, and this is based on the comparison of the result from evaluation of functionality of each application.Due to specificity of documentation on the DA system, the “process based” approa­ch­ had been used for structuring system included knowledge instead of using a systematical method like either MOKA or CommonKADS completely. Setting up interconnection between different knowledge objects was one of the most important tasks in this project because it enables capturing and retrieving of knowledge.Sementic MediaWiki, a powerful text representative and web-based tool has been used as a platform of representing the whole knowledge and information. With its implementation, the performance of Sementic MediaWiki had been tested accor­ding to the preset functional requirement. After a slight refine process to the solution, the satisfactory result had been achieved, and also proved the applicability of Sementic Wiki in such kind of project.",Software Design
"The development of web mapping industry is so fast that hundreds of web mapping software products are being created each year. These products are usually parts of three solution categories: a) proprietary solutions, b) Open source solutions, or c) Web 2.0 mashup solutions.Due to the solutions’ maturity, rich functionalities and great external support, most enterprises use proprietary products to build their web mapping applications. Seldom are the latter two, named as non-proprietary solutions in this study, ever used in corporations. This study explores the suitability of non-proprietary web mapping solutions for WSP Sweden.Two prototype applications are developed using one Open source web mapping solution and one Web 2.0 mashup solution. Both applications attempt to accomplish similar tasks as an existing application, Stockholmshem tree inventory project, to demonstrate the functional potential of each solution.The implementation process will help to further access both prototype solutions on the basis of: a) how well they satisfy WSP’s list of demands; b) their implementation difficulty; and c) their response performances. The results indicate that both categories of non-proprietary solutions can satisfy the most important demands of WSP’s basic web mapping application.While Open source solutions are more suitable for meeting advanced demands, mashup solutions can help to quickly establish a simple application. The combinational use of both solutions is a promising alternative to the predominant ArcIMS-based proprietary solution used at WSP.",Software Design
"This study aims to focus on relational controversy about the causes behind the inconsistency in number of students who use a Web 2.0 application named “LibGuide” inside the Linnaeus University and the attempts of program coordinator to develop certain strategies to perform a better use of it in a particular department of Healthcare.The nature of the problem will be discussed, suggesting that how the these strategies maintained a high significant of use in that department. The research foregoes, as it uses a process of translation which are the moments of struggles by a program coordinator to impose itself by its role to the definition of the situation. The research suggests a network within which the series of processes and interrelation of the sociotechnical role of each member is drawn and allocated.",Software Design
"Search engines are the most popular tools for finding answers to questions, but unfortunately they do not always provide complete direct answers. Answers often need to be extracted by the user, from the web pages returned by the search engine.This research addresses this problem, and shows how an automated theorem prover, combined with existing ontologies and the web, is able to reason about world knowledge and return direct answers to users’ questions. The use of an automated theorem prover also allows more complex questions to be asked. Automated theorem provers that exhibit these capabilities are called World Knowledge Reasoning systems.This research discusses one such system, the CNL-WKR system. The CNL-WKR system uses the ACE controlled natural language as its user-input language. It then calls upon external sources on the web, as well as internal ontological sources, during the theorem proving process, in order to find answers. The system uses the automated theorem prover, SPASS-XDB. The result is a system that is capable of answering complex questions about the world.",Software Design
This Project is an ideal web-based recruitment tool for companies and co-op/internship programs.,Software Design
"This study analyzes the use of five types of advanced content in state e-government: audio and video content, RSS feeds, podcasts, blogs, and participative services. State government portals and governors’ websites were reviewed to determine if and how they implemented any of the five evaluation criteria.Points were assigned for the presence of these criteria, with additional points being granted for examples of advanced content that were deemed to be of quality based on defined measures. The study found many state e-government sites have implemented features that set standards for the use of advanced content in an e-government setting.",Software Design
"The proliferation of web-based social networks has lead to new innovations in social networking, particularly by allowing users to describe their relationships beyond a basic connection. In this project, I look specifically at trust in web-based social networks, how it can be computed, and how it can be used in applications.I begin with a definition of trust and a description of several properties that affect how it is used in algorithms. This is complemented by a survey of web-based social networks to gain an understanding of their scope, the types of relationship information available, and the current state of trust. The computational problem of trust is to determine how much one person in the network should trust another person to whom they are not connected.I present two sets of algorithms for calculating these trust inferences: one for networks with binary trust ratings, and one for continuous ratings. For each rating scheme, the algorithms are built upon the defined notions of trust. Each is then analyzed theoretically and with respect to simulated and actual trust networks to determine how accurately they calculate the opinions of people in the system. I show that in both rating schemes the algorithms presented can be expected to be quite accurate. These calculations are then put to use in two applications.FilmTrust is a website that combines trust, social networks, and movie ratings and reviews. Trust is used to personalize the website for each user, displaying recommended movie ratings, and ordering reviews by relevance. I show that, in the case where the user’s opinion is divergent from the average, the trust-based recommended ratings are more accurate than several other common collaborative filtering techniques. The second application is TrustMail, an email client that uses the trust rating of each sender as a score for the message. Users can then sort messages according to their trust value. I conclude with a description of other applications where trust inferences can be used, and how the lessons from this project can be applied to infer information about relationships in other complex systems.",Software Design
"The purpose with this report is to present the findings from the project work performed at Ipendo Systems. The goal was to develop a methodological support for the migration process and implement a web portal for migration of data.When a company acquires a new application to perhaps replace a legacy system, or to improve their efficiency and there by their competitiveness, the company’s data need to be transferred into the new application. The process of transfer the data from a source to a target is called data migration. Because the source and target systems probably have a somewhat different architecture some transformation to the data has to be made.The project is divided in two parts, a theoretical part where I learned about data migration and developed a methodological support for data migration projects. The second part of the thesis work was practical designed and I developed a data transformation portal.Data migrations are often a somewhat forgotten activity in a project. It is sometimes carried out without a proper plan or structure. To bring some structure to this important process I developed a methodological support. The methodological support is made like a guide for how to conduct data migration projects. The purpose of the methodological support is to make data migrations more visible as an own project and add more structure to it. The methodological support is divided into five phases. The five phases are planning, analysis, design, implementation and validation. Every step has its own milestones and deliverables so the support could be used as a sort of checklist during the project.The purpose with a data transformation portal is to gather all data migration to one common area without a third-party migration tool and minimize the technical complexity associated with data migration projects. I have developed two modules for the portal. The first module concerns migration from an Excel document to a SharePoint list.The second module handles upload of documents to a SharePoint document library. The portal has functionality like data mapping, validation and setting of metadata. Migration of data is a specific process, depending of the type of data that should be migrated it requires a somewhat different approach. A data transformation portal which can visually monitor, filter, transform and import various types of data to and from various data sources would facilitate the migration process.",Software Design
"The modern IT society is based on Internet access, and many corporations, organizations and persons take advantage of the increased accessibility and flexibility that the Internet provides for products, services and information. This can also cause problems for the visually impaired since they cannot always access and use all websites, because of that their aiding devices cannot always interpret all the contents of the website, or that they freeze or sometimes even crash.The purpose of this thesis is therefore to find out how websites should be designed so that they function as well as possible with the aiding devices of the visually impaired, as well as how to make websites as accessible as possible for the visually impaired.By comparing the result of a case study with existing theory, it was concluded that the existing standards and guidelines should be followed to make websites as accessible and user friendly as possible for the visually impaired. One of the many important things regarding accessibility for the visually impaired is the importance of providing ALT texts to images and links, to allow the aiding devices to interpret these. Because it is very common to forget to provide ALT texts on websites today.It is also important to follow the accessibility standards and guidelines that are available for both Flash animations and PDF documents. Modern aiding devices can interpret Flash animations if they follow these standards and guidelines, but most of the aiding devices can still not interpret Flash at all. The aiding devices can also interpret PDF documents if these are made correctly, which, sadly, the often are not.To find a solution for all these problems, and many more, the authors have concluded a number of good advice and requirements based on the experience of visually impaired persons, as well as giving some advice on how to increase accessibility in websites.",Software Design
"Nowadays, Intelligent Tutoring Systems (ITSs) are so regarded in order to improve education quality via new technologies in this area. One of the problems is that the language of ITSs is different from the learner’s. It forces the learners to learn the system language. This paper tries to remove this necessity by using an Automatic Translator Component in system structure like Google Translate API.This system carry out a pre-test and post-test by using Expert System and Jackson Model before and after of training a concept. It constantly updates learner model to save all changes in learning process. So this paper offers an E-Learning system which is web-based, intelligent, adaptive, multilingual and remotely accessible where tutors and learners can have non-identical language. It is also applicable Every Time and Every Where (ETEW). Furthermore, it trains the concepts in the best method with any language and low cost.",Software Design
"Online Course Registration System project is developed in .Net, providing easier registration to courses online saving time. It is developed with ASP.Net. MySQL is used as database.Some of the source code files are:categorysearch.aspx",Software Design
"In Web Based Claims Processing System (WCPS), the employee can fill the claim form online and submit it so that the form is sent to CPD through Internet. At CPD, the form needs to be checked automatically by a program which will compute the amount that needs to be reimbursed to the employee for the treatment undertaken.Technology: ASP.Net 2.0, C#, Java Script, SQL ServerDownload Project Source CodeDownload Installation Guide",Software Design
"Web applications initially became popular much thanks to low deployment costs and programming simplicity. However, as business requirements grow more complex, limitations in the web programming model might become evident.With the advent of techniques such as AJAX, the bar has been raised for what users have come to expect from web applications.However, although web application development often starts off simple, limitations in the web programming model might start to show when the business requirements become more complex. To successfully implement large-scale web application, software developers need to have knowledge of a big set of complementary technologies.This study describes the implementation of a prototype of a central hotel property management system using web technologies. These technologies are then compared to an alternative set of technologies, which are used for implementing a second prototype; a stand-alone desktop client distributed using Java Web Start.The study highlights some of the current problems with the web programming model and shows how the user experience can be improved by instead using desktop technologies.",Software Design
"The main objective of Matrimonial Web Application is to provide Grooms and Brides with excellent matchmaking experience by exploring the opportunities and resources to meet true potential partner. Keeping our objective in mind, we have created a world renowned online matchmaking services that will touch the souls of millions of people all over the globe.The purposes of the Matrimonial Web Application are:Matrimonial Web Application will allow a new user to register and after successfully registration user can get email confirmation, after completing registration users profile will be visible to other users.Download Matrimonial Web Application Project>> List of Projects in other languages like JAVA, ASP.Net, C#.Net, VB.Net, J2EE, J2ME, PHP, SQL etc.",Software Design
"Our web-based interactive game-playing-oriented college selection system acts as an smart advisor/mentor and helps students, parents, and teachers use an effective graphical user interface to efficiently search college information and to make good decisions at each stage of students’ academic development. It is an expert agent with hierarchical fuzzy knowledge base using fuzzy logic.Users are expected to be able to use this agent as a trusted, involved and smart counselor, who remembers their profile and their past history and advises them through their high school years. It gives them increasingly better and specific nuggets of advice as they make progress through their schools, and guides them toward a selected set of colleges to apply that optimizes their potential.At the heart of this system is an assessment tree, which uses bottom-up fuzzy calculations to generate possibility of admission in various sets of colleges. The primary output is a short list of colleges to apply containing five kinds of colleges (highly-selective down to non-selective) with possibilities of acceptance in each college according to fuzzy rules provided.It is also a smart tool to play self-guided  “what if” games to explore what specific action one should be taking to have maximum impact on the selection of colleges one can get in and on his/her chances of admission. It employs a natural interactive interview process for a user (i.e., a user can play a game with the agent to gradually find out rational solutions), and produces advisories at different stages.",Software Design
"A management platform is an integral part of any modern computer network. Its role in any kind of network (research or commercial) is undeniable. By using the management solution, the operators of the network monitor, troubleshoot and manage the network from a centralized location.In a research network such as the Mid Sweden University (MIUN) IPTV test bed, it also plays a very important role. Researchers can setup different configurations for the underlying network according to their research goals.MIUN IPTV test bed is expanding in the sense that it is covering a greater geographical area and more researchers are using the network in order to carry out their experiments. In this project, an attempt will be made to develop a management platform for the IPTV network.This platform will manage the whole network and will give the researchers opportunity to setup trail field by configuring the network devices according to their experiments.",Software Design
"Testing is one of the critical processes in software development life cycle. It plays key role in the success of software product by improving its quality. Web-based applications are emerging and evolving rapidly; their importance and complexity is also increasing.Heterogeneous and diverse nature of distributed components, applications; along with their multi-platform support and cooperativeness make these applications more complex and swiftly increasing in their size. Quality assurance of these applications is becoming more crucial and important; testing is one of the key processes to achieve and ensure the quality of these software or Web-based products.There are many testing challenges involved in Web-based applications. But most importantly interoperability and integration are the most critical testing challenges associated with Web-based applications. There are number of challenging factors involved in both integration and interoperability testing efforts. These integration and interoperability factors have almost 70 percent to 80 percent impact on overall quality of Web-based applications.In software industry different kind of testing approaches are used by practitioners to solve the issues associated with integration and interoperability, which are due to ever increasing complexities of Web-based applications.It is fact that both integration and interoperability are inter-related and it is very helpful to cover all the possible issues of interoperability testing that will reduce the integration testing effort. It will be more beneficial if a dedicated testing team is placed to perform the both integration and interoperability testing.",Software Design
"The research field Knowledge Management (KM) is about improving methods to structure and filter information. A concept browser makes it possible to navigate through complex information structures. Conzilla is such a concept browser. It is designed to present knowledge, to set concepts into relations to each other, and to make browsing through the resulting context-maps possible. Conzilla allows information and content being tied to concepts and concept-relations.The collaboration facilities in Conzilla are limited. Basic elements such as a lookup mechanism and lifecycle information for information structures are missing. Before knowledge can be contributed, it is necessary to make sure that dependencies are fulfilled and the history of an edited object is obtained. This thesis is about providing these missing parts.To be able to load a container, the information about the location of a component has to be held by a central registry. To resolve eventually existing dependencies, it is also necessary to register the components and its references. This project provides a design which eliminates the existing restrictions. The aim is to allow real collaboration through a remote services infrastructure, realized with Collaborilla. The theoretical background is discussed as well as a practical solution, including a prototype of a remote collaboration service.",Software Design
"Medical Diagnostic system for heart diseases is an expert system built using java and Knowledgewright by Amzi Inc. It helps to detect whether a person is suffering from a heart disease. The conclusion is calculated after the user answers to some questions.The program then searches through the knowledge base and as per the rules and facts, it comes up with a conclusion. It all contains some relevant information on the three heart disease that it focuses on. It uses a Heuristic search and follows the forward chaining principle. Please read the “read me” file in the archive before running the application.Download Online Medical Diagnostic System in JAVA>> List of Pharmacy Management System Projects in C#.Net, PHP, VB.Net, JAVA, VB>> List of Hospital Management System Projects in JAVA, ASP.Net, PHP, VB, C, C++, VB.NetMedical Related Projects >>Hospital Related Projects >>",Software Design
"Today, testing applications for Internet (web sites and other applications) is being verified using proprietary test solutions. An application is developed and another application is developed to test the first one. Test Competence Centre at Ericsson AB has expertise on testing telecom applications using TTCN-2 and TTCN-3 notations. These notations have lot of potential and are being used for testing in various areas.So far, not much work has been done on using TTCN notations for testing Internet application. This project was a step through which the capabilities/possibilities of the TTCN notation (in Web testing) could be determined.This project presents investigation results of the 3 different test technologies/tools (TTCN-2, TTCN-3 and a proprietary free software, PureTest) to see which one is the best for testing Internet Applications and what are the drawbacks/benefits each technology has. The background topics included are brief introduction of software testing and web testing, short introduction of TTCN language and its version 2 and 3, description of the tool set representing the chosen technologies, conceptual view of how the tools work, a short description of HTTP protocol and description of HTTP adapter (Test Port).Several benefits and drawbacks were found from all the three technologies but it can be said that at the moment proprietary test solutions (PureTest in this case) is still the best tool to test Internet Application. It scores over other the two technologies (TTCN-2 and TTCN-3) due to reason like flexibility, cost effectiveness, user friendliness, small lead times for competence development etc.TTCN-3 is more of a programming language and is certainly more flexible when compared to TTCN-2. TTCN-3 is still evolving and it can be said that it holds promise. Some of the features are missing which are vital for testing Internet Applications but are better than TTCN-2.",Software Design
"This paper has been made with the health care center Aroma in Vetlanda. The work was to deliver a complete web portal with an integrated booking system.The objectives were to provide a complete informative website for Aromas users with the option to make an appointment for a vaccination or health certificate, order prescriptions and get update information directly published by Aromas staff. And to give the staff of Aroma a graphical Web interface to manage the content and the booking system.The report goes through the basic language used and why. Further it takes up it how works and how the final product looks and behaves.",Software Design
"This feature is made available to public for interaction with police indirectly. This system registers the complaints from people through online and is helpful to the police department in identifying criminals. In this system any person can register their complaint online. The aim of this project is to develop an E-cops reporting and management system which is easily accessible to the public, police department and the administrative department.Generally many crimes seen by the public will not reach to the police due to many reasons like fear, lack of time, ignorance. Due to this reason many cases are not even reported to the police station. Though some cases are registered they are not investigated properly due to lack of evidences and cooperation of the public. This project helps the public to report about the crimes to the police without any fear in correct time.This is also helpful for higher authorities of police to have an overview about the progress of the investigation.This feature is made available to public for interaction with police indirectly. This system registers the complaints from people through online and is helpful to the police department in identifying criminals.In this system any person can register their complaint online.The aim of this project is to develop an E-cops reporting and management system which is easily accessible to the public, police department and the administrative department.",Software Design
"As the core of a previous project, a Web-based tool, called LDBN(Learn DataBase Normalization), was developed. The purpose of this tool is to provide an interactive learning environment for the normalization of relational database schemata whose constraints are defined by functional dependencies (FDs).As a part of this project, some crucial extensions to LDBN, based upon these observations, are developed. The most significant extension is a tool for the visualization of FDs, based upon templates found in popular textbooks. Often, such visual representations are much easier for humans to grasp than purely text-based representations. However, this extension does not compromise the existing capabilities of LDBN. In addition, we present some other shortcomings of the previous version of LDBN and our approach to deal with those, in particular issues surrounding user privileges.",Software Design
"A coherent software environment simplifies maintenance – and using the same terminology facilitates communication and learning within the IT department.Having a mixed and complex software environment could put strain on the IT department. Applications and databases needs to be somehow cataloged in case of system failure.While mapping applications to databases using a unified terminology might seem to be a good idea from the start, but when it comes to generating a data model of interconnections based on terminology – confusion will arise. This confusion could lead to misinterpretations, which in turn could lead to incidents.Introduction:",Software Design
"This study was written on behalf of ESAB Research and Development department, in Laxå Sweden. One of ESAB’s product areas is developing various welding systems.Today if ESAB’s customers experience a problem with one of their welding systems they call ESAB’s service center. If the problem seems to have been caused by software, or if it requires log files to be analyzed, ESAB needs a way to get this system information from the customer’s welding system to ESAB’s employees.One of the goals with this project study was to perform an analysis answering how the system information should be sent, stored and what unit in the customer’s welding system that should send it. Another goal was to implement the solution that the analysis presented.The analysis shows that WeldPoint in combination with a web service is the best way to send the system information from the customer’s welding system. WeldPoint is a PC control and log software connected to the customer’s welding system.A web service provides a service interface enabling clients to interact with a web server. Clients communicate with the webservice using HTTP, this means that clients can easily communicate across firewalls and other network obstacles.The thesis work resulted in three different applications written in C#.NET. The first application is a simple form called WeldPoint Remote Support (WRS). This form extracts customer information, welding system information and log files from the customer and the customer’s welding system. All this information is called a case. The case is received by ESAB using the second application, WeldPoint Web service (WWS). WWS stores the received case in a database.The third application is called WeldPoint Remote Support Center (WRSC). This application is used by the ESAB employee’s to view the case sent from the customer’s welding system.The above implementation has been tested and supports a robust and secure way to send andview the system information from the customer’s welding system. The conclusions showed that all goals and requirements set by ESAB were met.",Software Design
"The main aim of the project is to provide a complete, ready to run, fully customizable website for listing and managing Classified Advertisements.The features of this project are:Easily create ad listingsBuilt-in search and categories simplifies finding adsBuilt-In Site AdministrationTechnologies and Design Approaches Demonstrated:Download Source Code – Sulekha Classifieds Website using ASP.net and C#.net>> List of Projects in JAVA, ASP.Net, C#.Net, VB.Net, J2EE, J2ME, PHP, SQL etc.",Software Design
"Consistent monitoring of vital health parameters is an important issue in the medical industry. With recent technologies we are able to carry out remote monitoring of physiological parameters in patients. This allows communication between a patient and medical personnel using a smart-phone, which will collect, analyze and transfer heart rate and oxygen saturation data for subsequent review by a medical professional.Before any on-line analysis is performed on the phone it is necessary to clarify the nature of the correlation between these medical parameters. In the current thesis we establish connection between a patient wearing a pulse-oxymeter and a smart-phone running Android and perform continuous data collection. All measurements were done in consultation with medical facility and involved real patients.This data is subsequently analyzed using change point detection and anomaly detection algorithms in off-line mode. Both techniques are complementary to each other and showed reliable results which could be useful for a medical review.",Software Design
"This study was made for Cybercom in Ostersund. They wanted an evaluation of HTML5 cross platform applications which studied HTML5 features as well as JavaScript libraries and frameworks. The resources put into mobile application development can be reduced by making applications that can work on all platforms instead of only natively.These types of applications are called cross platform applications and can be developed with specific tools.One way to develop cross platform applications is by using HTML5, which can either be used as a web application or packed into native applications using plug-ins. The purpose of this study was to create a mobile web app that can save maps to be used online. The work was done by evaluating frameworks for web applications.Frameworks that provide user interface elements and features similar to those in native applications, and libraries that render maps served by map servers. Development environments for web development were also tested and evaluated. The results of the research and development were documented experience, and a HTML5 application that shows a map, has GPS functionality and can be used online.",Software Design
"Nowadays people use maps everyday in many situations. Maps are available and free. What was expensive and required the user to get a paper copy in a shop is now available on any Smartphone. Not only maps but location-related information visible on the maps is an obvious feature.This work is an application of opportunistic networking for the spreading of maps and location-related data in an ad-hoc, distributed fashion. The system can also add user-created information to the map in form of points of interest. The result is a best effort service for spreading of maps and points of interest. The exchange of local maps and location-related user data is done on the basis of the user position. In particular, each user receives the portion of the map containing his/her surroundings along with other information in form of points of interest.",Software Design
"Mobile devices are becoming more common in health care and studies show that they can contribute with a lot of benefits. The purpose of this thesis is to investigate what important factors should be considered when designing an application for a tablet computer to be used at an emergency department.The project involved creating a prototype for an application that would be used as a decision support system for doctors when a stroke patient arrives to the emergency department – a case where time and accuracy are both equally important. Research was conducted by doing field studies and interviews, and the results from these helped to develop a prototype.Usability tests were conducted on the prototype and changes were made accordingly. The study showed that there are many important factors to consider; e.g. identifying the workflows, creating a non-linear system and overview support.",Software Design
"This is a small project for an advertising agency in ASP.Net and C#.The main features of this system are: Ad Details, Ad Request, Ad Creation, Ad Rejection, Staff Functionality, Staff View, etc.Main files of the system include:AdvList.aspxBudget.aspxBudgetList.aspxBudgetList.aspx.resxCreateList.aspxLogin.aspxNewUser.aspxDownload Ad Agency System Source Code in ASP.Net and C#",Software Design
"The Classifieds Site Starter Kit provides a complete, ready to run, fully customizable, Web site for listing and managing classified advertisements.Easily create ad listings",Software Design
"The objective of this project is to build an e-commerce website using ASP.NET as well as J2EE technologies. Visual Studio 2005 provides a great IDE to build seamless front end layer for the websites with minimum effort.Hence, it is used to build the presentation layer. The business logic layer is developed in ASP.NET 2.0 and J2EE, exposing the functions as web services. Two similar clients have been developed in ASP.NET. These two clients invoke the .NET and J2EE web services.The two similar websites are subjected to testing for correctness and performance. Stress and load testing is performed thoroughly on the website. A detailed analysis of the results is done using the response times and throughputs from various tests.This report proves that we can build a website using a presentation tier developed in ASP.NET consuming any of the two technologies’ (ASP.NET & J2EE) web services. This proves to be very useful in scenarios where we need the best overall user experience regardless of the technology, to replace or extend an existing business tier by using a different technology.",Software Design
"The aim of this .NET Application is to develop an ASP.NET 3.5 Web Application using Microsoft Visual Studio 2008, SQL Server 2008 and Crystal Report.Problem Description:Aim of this assignment is to develop a web application that can be used to keep track of the patients registering in a hospital.Also, this system should support features such as- accessing the previous visit histories of any patient, search for patients by name and other attributes, etc.Some of the most general requirements of the system are:• Registration of patients",Software Design
"This cinema ticket booking is a faster, cleaner and a tad more personal website, specially designed to make your booking experience better.Customers may view the contents of any movie show at any time and may book any movie ticket as needed. The program automatically calculates the subtotal and grand total. When a visitor decides to finally book the ticket, the order information including the buyer’s name, address and billing instruction is stored in the database securely and payment has been made.The combo booking is also provided at the time of booking the ticket and there’s a wonderful facility of delivering the combos at your seat when you are watching the movie.You need to register a new user whenever you have first visited or site then for future it will be stored in our database permanently and you can book you movie ticket at any time you want with this username and password.Download Online Cinema Ticket Booking System in ASP.Net>> List of Projects in JAVA, ASP.Net, C#.Net, VB.Net, J2EE, J2ME, PHP, SQL etc.",Software Design
"Problem StatementFor Organizations with huge data centers having a lot of servers hosting numerous applications, it is always a major problem to monitor if each of the servers is up and functional all the time. The problem is more acute during late night shifts when the usual number of network/systems engineers working is less.Usually, when organizations host the applications on their servers on behalf of their clients, they sign-up a service level agreement (SLA), specifying the allowed down time for each of the applications. Any lack of commitment on the part of the organizations in meeting the SLA could result in loss of business or legal action or both.So, it becomes very important for the organizations to know if a server is down or non-functional and take corrective action immediately. Unfortunately, for some less time critical applications, it is usually the client who informs that there is a problem with the server when he/she tries to logon to the application Organizations would be very interested in knowing about these server failures immediately and take corrective action before the client starts complaining.Proposed SolutionThere is a need for a web based application which can capture all the organization and data center details and remotely check if each of servers is up and running all the time. This monitoring piece of the application keeps pinging each of the servers at the specific intervals and based on the rules setup and response received it sends out an SMS to a predefined list of specialists whenever there is a failure. This SMS will also contain the information related to the server that has failed and also the time at which it had failed.Download Project SMS based Remote Server Monitoring System",Software Design
"A carbon dioxide emission calculator for buildings created by the U.S.-based company CTG Energetics, Inc. and based on a Excel file has been converted to a ASP.NET / SQL Server web application. Carbon dioxide emissions are calculated using data given by the user (i.e. floor area, workdays per year) in combination with statistical data used in user-selectable presets (i.e. building type, climate zone, type of water-using fixtures).In most cases a custom value can be inserted instead of using a preset. Emissions attributable both directly and indirectly to the building such as building energy use, domestic water use, landscape/irrigation, transportation, materials used for the building/parking lot and the disposal of solid waste are calculated. The emissions can be compared with a national average and/or emissions from alternate scenarios created for the same building. The web application contains some upgrades and extra functionality that would not have been possible in Excel such as user handling.",Software Design
"“U Auction” is an online auction web site aimed at taking the auction to the finger tips of aspiring bidders there by opening up the doors of the “OPEN Auction House’ to a wider cross section of Art Lovers and Antique Collectors. This site also acts as an open forum where buyers and sellers can come together and exchange their products. The site makes sure that the sellers get a fair deal and buyers get a genuine product.Home Page – The site opens up door to aspiring web users through the Home page. The Home page is designed in such way that the layout is as user friendly as possible. There is a navigational menu at the top of the page which links to various inner pages. There is a category drop down on the left side for easy manipulation. The center area is for displaying latest products in the chorological order.Login/User Registration – Those who wish to take part in bidding or sell products at the site have to register at the site as seller or buyer. Only authenticated users can take part in selling or in bidding. The system automatically rejects un-authenticated users who try to bid or sell at the site.Register Products – This module is for presenting items for bidding. Only those who have registered and authenticated as sellers can place their articles for bidding. The Module collects information like Product Name, Product Details, Starting Bid amount, Incremental value etc. The system automatically inputs the closing date.Bidding Module – The module is for bidding on any selected item. The bidder has to authenticate before participating in bidding. The system checks whether the incremental amount entered by the bidder is equal or more than the incremental minimum set during the product registration time. The system places the record in the bid history against the bidder account.My Auction – This page is an interface for both buyer and seller. Buyer can see the profile of the bidding history of items which are still open on which he/she has already bided. Similarly the seller can see the progress of bidding on articles he/she has placed for bidding.Feedback – The purpose of the page is to send messages/comments to the web administrator.FAQ – This page is meant for first time users of the site. The page provided answers to questions which are common and frequently asked.WebAdmin – This link opens to the administration module which is open to web administrator only. Here site administrator can add product categories and can edit product information like closing date. Also there is an option for administering the closed bids. This module is for contacting the bidder and seller by email instructing them to settle the transaction within a time frame.Download Online Auction in ASP.Net and VB.NetMore Downloads on Online Auction>> List of Projects in other languages like JAVA, ASP.Net, C#.Net, VB.Net, J2EE, J2ME, PHP, SQL etc.",Software Design
"This project develops a software for “Merit Scholar” which conducts Certification exam for application developers. The Exams are conducted at various cities at different centers on different dates at particular time. Only few members are allowed to write the exam at particular time on a date at any center in a city.The project is built using ASP.NET and C#. The zip file contains all the necessary .aspx, and images files. Functions: Entering User id, Password in the login screen for the administrator and application developer, Registration process for the examinee, Fixing venue and date by the examinee for a Certification Exam, Entering Exam centers, dates by the administrator for different certification exams, Displaying the Examinee ID, Examinee password and selected details for the examinee.Following are some main files in this project:-addcenter.aspx-addcity.aspx-admin_datafix.aspx-admin_login.aspx-datefixlogin.aspx-examlogin.aspx-fixingdate.aspx-registration.aspxDownload Exam Scheduler .Net Source Code>> List of Projects in other languages like JAVA, ASP.Net, C#.Net, VB.Net, J2EE, J2ME, PHP, SQL etc.",Software Design
"Online Course Registration System project is developed in .Net, providing easier registration to courses online saving time. It is developed with ASP.Net. MySQL is used as database.Some of the source code files are:categorysearch.aspx",Software Design
"The main objective of Matrimonial Web Application is to provide Grooms and Brides with excellent matchmaking experience by exploring the opportunities and resources to meet true potential partner. Keeping our objective in mind, we have created a world renowned online matchmaking services that will touch the souls of millions of people all over the globe.The purposes of the Matrimonial Web Application are:Matrimonial Web Application will allow a new user to register and after successfully registration user can get email confirmation, after completing registration users profile will be visible to other users.Download Matrimonial Web Application Project>> List of Projects in other languages like JAVA, ASP.Net, C#.Net, VB.Net, J2EE, J2ME, PHP, SQL etc.",Software Design
"Cooking Recipe Portal is developed on ASP.NET 2.0 C# N-Tier application and SQL 2005 Database with stored procedure to contain and display recipes in a wide variety of categories, also allow your visitors to post their favorite recipes, rate recipe and add comment.You can edit/delete recipes or comments in a password protected admin recipe manager area.Features:Download Cooking Recipe Portal Project in ASP.NET 2.0 C# ",Software Design
"Find variety of of Management System Projects in many technologies such as ASP.Net, C#.Net, JAVA, VB.Net, VB, C, C#, JSP, PHP etc. List of Projects on Hospital, Library, School, Salary, Hotel, Pharmacy, Student, Payroll, Employee Management System in ASP.Net, C#.Net, JAVA, VB.Net, VB, C, C#, JSP, PHP etc.Some of the Projects included are: ",Software Design
"Civil Registry is the online system or agency to help the Indian citizens to apply for their government records like passport, driving license, voter’s ID card, PAN card etc… and register certificates for birth, death, marriage etc.The primary objective of this web site is to give awareness about the government or legal documents and its registration details as well as to help to register or apply for those documents. This also acts as a consultancy agency to assist the public. The main purpose of the web site is to reduce the effort by the candidate and save his time and avoid unwanted rushes at the government offices and assure a smooth working schedule at government offices.The project Civil Registry still requires more development of IT solutions and its applications to improve the issuance of copies of government certificates and legal documents. Civil registry team trying to get more affiliation to government offices and departments. Now civil registry team acting as a agency to help the public.Download Civil Registry in C#.Net with ASP.Net>> List of Projects in JAVA, ASP.Net, C#.Net, VB.Net, J2EE, J2ME, PHP, SQL etc.",Software Design
"TRIMMA Affärsutveckling AB is developing and marketing a business intelligence solution called INSIGHT. INSIGHT presents tables showing possibly very large data sets and the performance and user experience is sometimes suffering.The main objective of this thesis is an evaluation of the pros and cons of replacing the existing ASP.NET/HTML table component in INSIGHT with a component developed in Silverlight.This thesis examines two techniques to speed up a Silverlight application showing a lot of data: UI- and data virtualization.UI virtualization intends to render only the user interface elements that appear on the screen and are visible to the user, while data virtualization intends to fetch (from the data source) only the section of the data that is visible to the user.The result of the project is a fully working prototype integrated into a test version of INSIGHT. Performance testing results indicate that the prototype performs approximately the same as the ASP.NET/HTML version of INSIGHT for small tables but significantly better for large data sets.The prototype also contains a few extra features, not available in INSIGHT, exemplifying the possibilities to create highly responsive user interfaces in Silverlight.",Software Design
"The main aim of the project is to provide a complete, ready to run, fully customizable website for listing and managing Classified Advertisements.The features of this project are:Easily create ad listingsBuilt-in search and categories simplifies finding adsBuilt-In Site AdministrationTechnologies and Design Approaches Demonstrated:Download Source Code – Sulekha Classifieds Website using ASP.net and C#.net>> List of Projects in JAVA, ASP.Net, C#.Net, VB.Net, J2EE, J2ME, PHP, SQL etc.",Software Design
Array microphones are frequently used in the field of speech signal applications. In this paper a use case for array microphones combined with signal processing and IEEE 802.1 AVB Ethernet-based audio signal transmission is presented. The proposed application is intended for conferencing systems. The array microphones with beam steering and sound source localization algorithm are used to span multiple speakers' recording areas. The benefit is the elimination of separate table microphones for the speakers.,Signal Processing
"We studied novel nonlinear equalization scheme using digital signal processing based on a neural network (NN). The performance of a three-layer NN was investigated using 16QAM signals distorted by SPM, achieving BER less than 10?5.",Signal Processing
Recent developments in programmable optical signal processing and monitoring are reviewed with emphasis on non-telecom applications including laser pulse shaping and intra-data-center switching.,Signal Processing
We review the recent progress of long-haul SDM transmission experiments and the issues to be addressed. Also described are advanced MIMO processing techniques we have developed to achieve low-complexity DMD compensation and MDL-tolerant transmission.,Signal Processing
"We demonstrate an ultimate flexible approach for simultaneous OFDM and N-OTDM transmission, using intermediate grids between time and frequency axes. We achieve open eye diagrams, and performance below the FEC limit in 89.2-km field-trial.",Signal Processing
"Analysis of electromyogram (EMG) signalprocessing and its application to identify human musclestrength of rehabilitation purpose has been successfully carriedout in this paper. Single channel EMG signal was obtainedfrom human muscle using non-invasive electrodes and furtherprocess by signal acquisition circuit to get a suitable signal tobe process. In the first part of signal acquisition, theamplification circuit for the small EMG signal has been designsuccessfully. After amplification stage EMG signal wasdigitized through analogue and digital converter (ADC) thenfurther process in microcontroller (ATmega328) for gettingaccurate EMG signal. Finally, the processed EMG signal wasclassified into 6 different levels in order to display the musclestrength level of the user. This EMG device can be used to helpthe weak person or an elderly to identity their strength level ofmuscle for clinical rehabilitation purpose.",Signal Processing
"Enabling ultra fast systems has been widely investigated during recent decades. Although polarization has been deployed from the beginning in satellite communications, nowadays it is being exploited to increase the throughput of satellite links. More precisely, the application of diversity techniques to the polarization domain may provide reliable, robust, and fast satellite communications. Better and more flexible spectrum use is also possible if transmission and reception can take place simultaneously in close or even overlapping frequency bands. In this paper we investigate novel signal processing techniques to increase the throughput of satellite communications in fixed and mobile scenarios. First, we investigate four-dimensional (4D) constellations for the forward link. Second, we focus on the mobile scenario and introduce an adaptive algorithm which selects the optimal tuple of modulation order, coding rate, and MIMO scheme that maximizes the throughput constraint to a maximum packet error rate. Finally, we describe the operation of radio transceivers which cancel actively the self-interference posed by the transmit signal when operating in full-duplex mode.",Signal Processing
"Multimodal source imaging is an emerging field in biomedical engineering. Its central goal is to combine different imaging modalities in a single model or data representation, such that the combination provides an enhanced insight into the underlying physiological organ, compared to each modality separately. It requires advanced signal acquisition and processing techniques and has applications in cognitive neuroscience, clinical neuroscience and electrocardiology. Therefore, it belongs to the heart of biomedical engineering.",Signal Processing
"The humble boxcar (or moving average) filter has many uses, perhaps the most well-known being the Dirichlet kernel inside a short-time discrete Fourier transform. A particularly useful feature of the boxcar filter is the ease of placement of (and tuning of) regular filter zeros, simply by defining (and varying) the time length of the boxcar window. This is of particular use within power system measurements to eliminate harmonics, inter-harmonics and image components from Fourier, Park and Clarke transforms, and other measurements related to power flow, power quality, protection, and converter control. However, implementation of the filter in real-time requires care, to minimise the execution time, provide the best frequency-domain response, know (exactly) the group delay, and avoid cumulative numerical precision errors over long periods. This paper reviews the basic properties of the boxcar filter, and explores different digital implementations, which have subtle differences in performance and computational intensity. It is shown that generally, an algorithm using trapezoidal integration and interpolation has the most desirable characteristics.",Signal Processing
"This paper builds upon the basic theory of multirate systems for graph signals developed in the companion paper (Part I) and studiesM-channel polynomial filter banks on graphs. The behavior of such graph filter banks differs from that of classical filter banks in many ways, the precise details depending on the eigenstructure of the adjacency matrix A. It is shown that graph filter banks represent (linear and) periodically shift-variant systems only when A satisfies the noble identity conditions developed in Part I. It is then shown that perfect reconstruction graph filter banks can always be developed when A satisfies the eigenvector structure satisfied by M-block cyclic graphs and has distinct eigenvalues (further restrictions on eigenvalues being unnecessary for this). If A is actually M-block cyclic then these PR filter banks indeed become practical, i.e., arbitrary filter polynomial orders are possible, and there are robustness advantages. In this case the PR condition is identical to PR in classical filter banks ? any classical PR example can be converted to a graph PR filter bank on an M-block cyclic graph. It is shown that for M-block cyclic graphs with all eigenvalues on the unit circle, the frequency responses of filters have meaningful correspondence with classical filter banks. Polyphase representations are then developed for graph filter banks and utilized to develop alternate conditions for alias cancellation and perfect reconstruction, again for graphs with specific eigenstructures. It is then shown that the eigenvector condition on the graph can be relaxed by using similarity transforms.",Signal Processing
"We numerically investigate direct detection of 28- Gbps-class PAM4 signals with receiver-side digital signal processing for bandwidth-efficient short reach optical transmissions, mainly including DD-LMS based linear equalization, 3-tap noise-whitening post filter and BCJR algorithm based MAP detector.",Signal Processing
The paper describes some new research results from designing a high precision audio measurement system using MLS (Maximum Length Sequence) algorithm. Evaluation version of USB audio measurement interface optimized for MLS signal processing has been presented in the paper. Comparison was subjected to commercial professional audio measurement system. Superior performance of the optimized measurement system has been shown.,Signal Processing
"Using arrays of bistable magnetic nanowires, we show that their microwave absorption properties can be reversibly configured using low magnetic field cycling by virtue of the double ferromagnetic resonance absorption spectra. These characteristics lead to a single bifunction microwave filter that can be configured to work as a bandstop or a bandpass filter, making these materials very attractive for compact multifunction planar microwave devices. The bifunction microwave properties of these systems are successfully predicted using a mean field model for their magnetic configuration-dependent effective permeability.",Signal Processing
"In this work we will work on analogue signal processing in the neural circuit of C. elegans which is able to detect the analogue signals from the environment and produce locomotive behaviours which are in accordance with experiments. The signals in C. elegans are processed in a purely analogue procedure, since no action potential has been recorded in its neural activity. We aim to show how signal processing can be executed in analogue domain in a living creature. In order to do that we will model two different behaviours of C. elegans which are generated in the same network of neurons, klinotaxis behaviour and isothermal tracking. We will implement a Genetic Algorithm to find appropriate sets of parameters of the model. Our contribution is to show how relatively straight forward differential equations can lead to relatively complex and different behaviours.",Signal Processing
"The function of any protein depends directly on its secondary and tertiary structure. Proteins can fold into a three-dimensional shape, which is primarily depended on the arrangement of amino acids in the primary structure. In recent years, with the explosive sequencing of proteins, it is unfeasible to perform detailed experimental studies, as these methodologies are very expensive and time consuming. This leaves the structure of the majority of currently available protein sequences unknown. In this paper, a predictive model is therefore presented for the classification of protein sequence's secondary structures, namely alpha helix and beta sheet. The proteins used throughout this study were collected from the Structural Classification of Proteinsextended (SCOPe) database, which contains manually curated information from proteins with known structure. Two sets of proteins are used for all alpha and all beta protein sequences. The first set comprise of sequences with less than 40% identity, and the second set comprise of proteins with less than 95% identity. The analysis shows a strong connection between the amino acid indices used to convert protein sequences to numerical sequences and proteins' secondary structures. The total classification accuracy for the proposed classifier for the protein sequences with less than 40% identity for amino acid index BIOV880101 and BIOV880102 are 78.49% and 76.40%, respectively. The classification accuracy for sets of protein sequences with less than 95% identity for amino acid index BIOV880101 and BIOV880102 are 88.01% and 85.17%, respectively.",Signal Processing
This paper covers the design aspects of a new multi-channel electrode for the acquisition of surface electromyography signals from a selected muscle. The new multi-channel electrode has 11 pins where the monopolar signals produced will be configured in a software either as Linear array or Laplacian configuration. The design specification of the pre-amplifier ideally was to have a voltage gain of 500 with bandpass filtering of 5 Hz?1 kHz. The final design of the pre-amplifier circuit using an INA 118 instrumentation amplifier was built and tested to give values for voltage gain of 484 with bandpass filtering of 6.8 Hz?1.02 kHz. The software configuration that gives clearer and more defined signals in terms of motor unit action potentials for future signal processing is the Laplacian rather than Linear array.,Signal Processing
"Signal processing on graphs finds applications in many areas. In recent years renewed interest on this topic was kindled by two groups of researchers. Narang and Ortega constructed two-channel filter banks on bipartitie graphs described by Laplacians. Sandryhaila and Moura developed the theory of linear systems, filtering, and frequency responses for the case of graphs with arbitrary adjacency matrices, and showed applications in signal compression, prediction, etc. Inspired by these contributions, this paper extends classical multirate signal processing ideas to graphs. The graphs are assumed to be general with a possibly non-symmetric and complex adjacency matrix. The paper revisits ideas such as noble identities, aliasing, and polyphase decompositions in graph multirate systems. Drawing such a parallel to classical systems allows one to design filter banks with polynomial filters, with lower complexity than arbitrary graph filters. It is shown that the extension of classical multirate theory to graphs is nontrivial, and requires certain mathematical restrictions on the graph. Thus, classical noble identities cannot be taken for granted. Similarly, one cannot claim that the so-called delay chain system is a perfect reconstruction system (as in classical filter banks). It will also be shown that M-partite extensions of the bipartite filter bank results will not work for M-channel filter banks, but a more restrictive condition called M-block cyclic property should be imposed. Such graphs are studied in detail. A detailed theory for M-channel filter banks is developed in a companion paper.",Signal Processing
"Indoor positioning technology based on WLAN signal strength is one of the most practical technical solutions. Considering the factors of environmental adaptability, laying cost and system complexity, the signal fingerprint positioning has become the first choice of the real time positioning technology. Because of the requirement of real-time positioning, the number of samples collected in the online phase should be as small as possible. Generally, the more sample points of the received signal, description of the RSSI information is more accurate. However, it will spend longer time to complete the information collection. Therefore, in order to reduce the amount of signal data acquisition and improve the real-time performance, this paper firstly introduce designs the experimental program to collect the fingerprint signals. Then proposed a processing method to the online acquisition signal based on the Bootstrap estimation. The simulation proves that this proposed method can effectively improve the real-time performance.",Signal Processing
"Processing of microwave signals using photonics has several key advantages for applications in wireless communications. However, to bring photonic-based microwave signal processing to the mainstream requires a reduction of the form factor. Integration is a route for achieving high-performance, low-cost and small-footprint microwave photonic devices. A high on-chip stimulated Brillouin scattering (SBS) gain is essential for synthesizing several key functionalities for advanced integrated microwave signal processing. We have optimized our on-chip SBS platform to achieve a record on-chip gain of 52 dB. In this paper, we discuss the implications of this giant gain from the viewpoint of new enabled technologies. The giant gain can be distributed over wide frequencies, which can be exploited for the realization of reconfigurable microwave bandpass, bandstop and multi-band filters. High gain also enables the demonstration of low-threshold on-chip lasers, which can be of relevance for low-noise RF signal generation. These wide range of functionalities made possible by the breakthrough on-chip gain makes Brillouin-based microwave photonic signal processing a promising approach for real-world implementation in the near future.",Signal Processing
"Implementation of ECG signal processing algorithms for removing baseline wander and electromyography (EMG) interference is proposed in this paper. First, Moving Average Filter (MAF) is used to remove the baseline wanders in ECG signal. Then the EMG components are detected and canceled by the Empirical Mode Decomposition (EMD). The Texas Instruments (TI) produced ADS1298 is chose to be the Analog Front-End (AFE) ECG capture chip which provides 8 measurement channels. The ARM series chips of STMicroelectronics produced STM32F429ZI is used as the computing core of signal processing which has operation frequency of up to 180MHz and is suitable for a large amount of data calculation as well as peripheral interface control.",Signal Processing
"Neural networks are a soft computing technique with wide application in signal processing as well as system and process modeling. In the present study, multilayer perceptron (MLP) neural networks were employed to process multidimensional signals generated in metal machining operations (including three-dimensional cutting force signals and three-dimensional cutting vibration signals) and to establish a model for predicting the machined surface roughness. This paper describes in detail our methods of multidimensional signal processing and modeling with MLP neural networks. The MLP neural network model developed in the present study fills an important research gap by taking into account the critical effect of tool-edge radius in machining. As compared to regression models, the MLP neural network model developed in the present study has significantly higher accuracy in predicting the machined surface roughness.",Signal Processing
"Signal processing of brain activity is becoming challenging to various researchers from different areas, including medical, biomedical, and engineering researchers. In this paper, investigations of brain activity are made from experimental works, with optical flow based on spatiotemporal analysis and wavelet over the equipment of Near Infrared Spectroscopy (NIRS). Ant Colony Optimization (ACO) algorithm is employed for obtaining the distributions of the intensity of the targeted image. The major outcomes of this paper from our research are the following items: (a) optical flow can be a proper technology for the investigation of brain activity based on NIRS; (b) the analyses of the temporal domain, the spatial domain, and the wavelet domain underpinned coherently to our experimental results; (c) our wavelet analysis can define the most brain activity image, denoted as targeted image; (d) the details of the intensity distributions on the targeted image show the most significant brain activity via ACO algorithm; (e) we can clearly observe, via our algorithm technology, the existence of the so-called Dominant Channel (DC) based on spatiotemporal analysis and it plays a critical role in brain activity. The spatial distribution of the origin of cortical activity can be described by hemodynamic response in the cerebral cortex after evoked stimulation using near infrared spectroscopy. Further application of this research is expected in the next step research outcomes.",Signal Processing
"This paper proposes a spiral-shaped dispersive delay structure (Spiral-DDS) composed of vertically stacked spiral coils and vertical vias. This all-pass network architecture can produce a large group delay peak at a certain frequency in a few GHz range. Basic performance of the Spiral-DDS are studied theoretically, and the group delay with more than 6 ns was successfully generated by a compact multilayered architecture with dimensions of 6.0 × 6.0 × 1.18 mm3. This paper also reports that the most of losses occurred in DDS comes from conductor loss, not from dielectric loss.",Signal Processing
"This paper presents a signal processing and coding system for processing realistic TDMR data generated by a grain flipping probability (GFP) model. The dataset was generated at the Data Storage Institute, Singapore, and will be referred to as the DSI data. Three types of two-dimensional intersymbol interference (2D-ISI) detectors with varying complexity are proposed. The first detector is a two-sided feedback (TSF) detector with known boundaries which simultaneously detects the three tracks of received data. This detector uses only one of the two samples provided by the reader for each bit. The second detector is a joint two-sided feedback (JTSF) detector which uses both samples provided by the reader for each bit. The third detector is a one-dimensional state-input decision-feedback (ODSIDF) detector which detects the data based on a 2D-ISI mask. Each of the 2D-ISI detectors is utilized in a turbo iterative approach with an IRA decoder in the proposed system. We use a coset coding approach in our IRA decoder for decoding the received data based on a known block of the data. A TDMR log-likelihood ratio (LLR) function is used to pass LLRs from the 2D-ISI detector to the IRA decoder. The read head sensitivity function (2D-ISI mask) is estimated based on the first sample alone (for TSF and ODSIDF detectors) and both samples (for JTSF detector) from the reader by using the least squares (LS) approach based on known data bits for a given set of reader outputs. The best simulation results show that the proposed signal processing and coding approach can achieve up to 1.7 Tb/in2 density at 18 nm track pitch (TP). Using a squeeze margin to account for the imperfect tracking of the track center by the read and write head in a practical system, the proposed system achieves a realistic areal density of 1.25 Tb/in2 at TP = 18 nm.",Signal Processing
"Fast scintillators such as LaBr3(Ce) and CeBr3 offer new opportunities in gamma-ray detection with good energy and time resolution. Recently, digital signal processing has become a standard in data acquisition for multi-parameter set-ups, since they have a very good performance in terms of energy resolution, dead time and flexibility. Nevertheless digital methods that are able to recover the excellent intrinsic time resolution of fast scintillates are still not widely available. In this paper we report on the results of digital acquisition and processing of signals of LaBr3(Ce), CeBr3 and BaF2 detectors aimed at obtaining the best time resolution. As a proof of principle we have used a 4-channel oscilloscope with 1 GHz bandwidth and 4 GSa/s sampling rate. Pulses were acquired, stored in memory and analyzed off-line. For each of the three scintillators coincidence measurements at 60Co and 22Na energies were performed against a fast reference BaF2 + XP2020 detector. Several digital signal-processing methods were used to measure the time resolution for the individual detectors. Constant fraction, threshold and comparator processing were used. The digital processing method that provides the best results is the digital CFD algorithm, yielding time resolution values comparable to those obtained by analog systems. Therefore digital processing is a competitive technique for fast timing with fast scintillators and it holds a strong potential for its implementation in standard set-ups.",Signal Processing
"This paper presents signal processing of position plan indicator (PPI) display for weather radar. The radar uses technique of frequency-modulated continuous-wave (FMC) to monitor the precipitation events in atmosphere and climate investigation. The use of FMCW technique is chosen in order to reduce the power at transmitter. For time efficiency, real-time domain processing conducted using Matlab® is implemented to process the received signal. Meanwhile, the PPI display is employed in the system due to its ability to map the area covered by the radar beam.",Signal Processing
The paper presents a new approach for processing of rhinomanometric signals based on F-transform approximation of phase diagrams. Methods of nonlinear dynamics for processing of time series allow us to obtain a significant features of rhinomanometric signals. Research indicated that the results of classification with F-transform approximation is more accurate than results of classification with FFT approximation.,Signal Processing
"Pattern-recognition algorithms from the domain of machine learning play a prominent role in embedded sensing systems, in order to derive inferences from sensor data. Very often, such systems face severe energy constraints. The focus of this work is to mitigate the computational energy by exploiting a form of compression which preserves a similarity metric widely used for pattern recognition. The form of compression is random projection, and the similarity metric is inner products between source vectors. Given the prominence of random projections within compressive sensing, previous research has explored this idea for application to compressively-sensed signals. In this work, we analyze the error sources faced by such approaches and show that the compressive-sensing setting itself introduces a significant source of feature-computation error ( \sim\sim 30 percent). We show that random projections can be exploited more generally without compressive sensing, enabling significant reduction in computational energy, and avoiding a significant source of error. The approach is referred to as compressed signal processing (CSP), and it applies to Nyquist-sampled signals. We validate the CSP approach through two case studies. The first focuses on seizure detection using spectral-energy features extracted from electroencephalograms. We show that at a 32 	imes	imes  compression ratio, the number of multiply-accumulate (MAC) and operand-access operations required is reduced by 21.2 	imes	imes , while achieving a sensitivity of 100 percent, latency of 4.33 sec, and false alarm rate of 0.22/hr; this compares to a baseline performance of 100 percent, 4.37 sec, and 0.12/hr, respectively. The second case study focuses on neural prosthesis based on extracting wavelet features from a set of detected spikes. We show that at a 32 	imes	imes  compression ratio, the number of MAC and operand access computations required is reduced by 3.3 	imes	imes , while spike sorting performance can be maintained within an average error of 4.89 percent for spike count, 3.42 percent for coefficient of variance, and 4.90 percent for firing rate; this compares with a baseline average error of 4.00, 2.75, and 4.00 percent for spike count, coefficient of variance, and firing rate, respectively.",Signal Processing
"Thallium-bromide (TlBr) is currently under investigation as an alternative room-temperature semiconductor gamma-ray spectrometer due to its favorable material properties. Previous work has shown that 5 mm thick pixelated TlBr detectors can achieve sub 1% FWHM energy resolution at 662 keV. However, these results are mostly limited to ?20 °C operation. In addition to good electron mobility, some TlBr detectors show hole mobility as high as 15?20% of the electron mobility. High hole mobility can affect depth reconstruction when single-polarity charge sensing is assumed. In this work, we use digital signal processing on the planar cathode waveforms to identify and account for the motion of holes and improve depth reconstruction at all depths for high hole mobility detectors. The hole drift only affects the cathode waveforms because the generated charge induces cathode signal at all depths. Due to the small pixel effect, the anode signal induction only occurs in a region right near the anode. As a result, the motion of holes does not significantly affect the anode signal.",Signal Processing
"Parkinson, is the second most common neurodegenerative disease after Alzheimer and no absolute cure has yet been found for it; however, the progression rate can be lowered with early diagnosis. Minor voice disorders are the first symptoms of this disease and they appear in almost 90% of the patients. The aim of this article to find the features that can create more meaningful difference between healthy and patient with Parkinson (PWP). For this purpose a Gaussian mixture model (GMM) is proposed to rank features based on its separability for each specific gender. We have used an existing database consisting of 195 samples computing 132 dysphonia measures and selection 22 features that have the most accurate classification. We also achieve correct disease classification performance of 88.89% and 86.05% for male and female respectively using a kernel support vector machine classifier and applying only 4 extracted features from any gender.",Signal Processing
"In order to optimize the baseband signal processing algorithm of BeiDou Navigation Satellite System (BDS) software receiver and improve the accuracy of pseudorange measurement and positioning, the baseband signal processing algorithm is analyzed. In this paper, the delay lock loop (DLL) is adapted for C/A code tracking, and the frequency locked loop (FLL) assisted Costas phase locking loop (PLL) is used for carrier tracking. Moreover, the different PLL discriminators are analyzed in detail. According to the simulation results of the discriminators, the two-quadrant arctangent discriminator is selected as the phase discriminator in the Costas PLL for BDS receiver. The simulation results showed that the improved baseband processing algorithm can perform reliable tracking for BDS receiver baseband signal. Our work will be helpful to better understand and design of BDS software receiver.",Signal Processing
"We review recent progress in the use of time lens based optical Fourier transformation for advanced all-optical signal processing. A novel time lens based complete optical Fourier transformation (OFT) technique is introduced. This complete OFT is based on two quadratic phase-modulation stages using four-wave mixing (FWM), separated by a dispersive medium, which enables time-to-frequency and frequency-to-time conversions simultaneously, thus performing an exchange between the temporal and spectral profiles of the input signal. Using the proposed complete OFT, several advanced all-optical signal processing schemes for spectrally-efficient systems and networks have been achieved, including all-optical generation, detection and format conversion of spectrally-efficient signals. The spectrally-efficient signals in this paper mainly refer to efficiently multiplexed signals with a high symbol rate per Hz, such as orthogonal frequency division multiplexing (OFDM), Nyquist wavelength-division multiplexing (Nyquist-WDM) and Nyquist optical time division multiplexing (Nyquist-OTDM) signals.",Signal Processing
"Machines without vibrations during operation are something non-existent which results in deterioration of machine tools. The condition based monitoring has become a crucial technique to ensure the machine availability by timely maintenance actions and reducing breakdown maintenance. Several condition monitoring techniques have been reported viz. vibration monitoring, acoustic emission monitoring, chemical monitoring, thermal monitoring and therefore new methods to improve the reliability, effectiveness, accuracy of the fault detection need to be evaluated. Vibration analysis is proven to be an important criterion for fault diagnosis in manufacturing processes and maintenance scheduling for various manufacturing equipment. This paper presents an overview of recent trends in condition monitoring and signal processing methods used for predictive maintenance of dynamic systems.",Signal Processing
"Extensive consumption of cereals as food in different domestic cousins places great demand the detection of cereal pest and struggle against them. Sunn pests such as Eurygaster integriceps, Eurygaster austriaca, Aelia rostrata and Aelia acuminata are insects with similar seasonal behaviors and dominant threat to the cereal plantations of Turkey. In this work, a microphone which works in acoustic and ultrasonic sound levels with the ability of making recordings with high frequency rate is used. Following the recording of sunn pest sounds with laboratory and outdoor conditions, the sound feature vectors are obtained with the application of different methods such as Linear Predictive Cepstral Coefficients (LPCC), Line Spectral Frequencies (LSF) and Mel Frequency Cepstral Coefficients (MFCC). By analyzing different kNN models it is shown that the automatic detection of sunn pests is possible with sound processing and machine learning methods. The best results is achieved with the overall accuracy of 93.6% using the combination of MFCC and LSF methods.",Signal Processing
"In hardware implementation of several widely used data and signal processing algorithms, data permutations need to be performed between the consecutive computation stages consisting of parallel computational units. Recently, some highly data parallel streaming architectures for data permutation have been proposed to achieve high throughput. However, the interconnection complexity of these designs increases dramatically with the problem size and data parallelism. In this paper, we develop a hardware structure to perform data permutation with optimized interconnection complexity, denned as the interconnection area per throughput. We propose a novel design technique such that the required interconnection logic is highly reduced for realizing a fixed permutation on streaming data. Our experimental results show that the proposed design technique reduces interconnection complexity by 27.3% to 75.8%, and improves the throughput by 5.3%~129% and the energy efficiency by 1.2×~3.5× compared with the state-of-the-art.",Signal Processing
"The rotary inductosyn is widely used as an angle measuring instrument in a control system. In order to obtain the absolute angle from the original output signals of the inductosyn, an ISA card for inductosyn signal processing based on the resolver-to-digital converter AD2S1210 and CPLD is designed and implemented in this paper. The sinusoidal oscillator and some other circuits, such as the one for adjusting the bandwidth, are integrated within AD2S1210. Therefore, the excitation generation circuit could be gotten rid of and few peripheral circuits would be adopted. This reduces the design complexity and improves the circuit integration. Meanwhile, a binary counter in the range of 360 degrees is implemented by CPLD to calculate the integer angle value, and a zero position sensor is set to obtain the absolute angle. Finally, the ISA card is tested with an industrial computer. The results indicate the real-time angle curve is smooth and the angle value is accurate. Consequently, the practicability and stability are verified. Compared with the traditional method of adding another one-pair pole resolver, the proposed approach simplifies the structure as well as reduces the costs of the system. The circuit is suitable for application requiring high resolution and fast conversion speed in industrial automation.",Signal Processing
"This paper proposes a massive Multiple-Input Multiple-Output (MIMO) with low-precision in-phase quadrature-phase (IQ) (de-)modulators and low-resolution analog-to-digital convertors (ADCs), and develops uplink baseband algorithms for the proposed MIMO system. The IQ imbalance parameters are recovered by a two-stage method. At the first stage, the base station (BS) antennas acquire phase-shifted versions of their imbalance parameters after receiving some predefined training sequence emitted by a specific transceiver that is near to the BS and shares flat-fading channels between itself and the BS. At the second stage, the phase-shifts from the first stage are estimated by the specific transceiver through receiving a common sequence transmitted by the BS antennas alternatively. In order to jointly handle the IQ imbalance and nonlinear quantization loss, the IQ-imbalanced multiuser (MU-) MIMO with single-antenna users is firstly converted to an IQ-balanced MU-MIMO with dual-antenna users. Then, two kinds of channel estimator and multiuser detectors are constructed for the equivalent IQ-balanced system based on the spectral projected gradient method and vectorized message passing de-quantization algorithm. Our numerical results validate the effectiveness of the above baseband algorithms, and show that the proposed massive MIMO is more energy-efficient than the conventional one when the channel coherence time is long enough.",Signal Processing
"In this paper, we compare a wide range of accelerator architectures (GPUs from AMD and NVIDIA, the Xeon Phi, and a DSP), by means of a signal-processing pipeline that processes radio-telescope data. We discuss the mapping of the algorithms from this pipeline to the accelerators, and analyze performance. We also analyze energy efficiency, using custom-built, microcontroller-based power sensors that measure the instantaneous power consumption of the accelerators, at millisecond time scale. We show that the GPUs are the fastest and most energy efficient accelerators, and that the differences in performance and energy efficiency are large.",Signal Processing
"The extraction of the Fetal Electrocardiogram (fECG) from the composite Electrocardiogram (ECG) signal obtained from the abdominal lead is discussed. The main point of this paper is to introduce some of the most used Least Mean Squares (LMS) based Finite Impulse Response (FIR) Adaptive Filters and to determine which of them are the most effective under varying circumstances. Experimental results suggest the ideal combination of the chosen settings for these functions. Results of fECG extraction are assessed by Percentage Root-Mean-Square Difference (PRD), input and output Signal to Noise Ratios (SNRs), and Root Mean Square Error (RMSE). Based on simulations conclusions, optimal convergence constant value and filter order were empirically determined. Setting the optimal value of the convergence constant and filter order of adaptive algorithm can be considered a contribution to original results. These results can be used on real records fECG, where it is difficult to determine because of the missing reference.",Signal Processing
"In this paper, 3D imaging of forward-looking Ground Penetrating Radar (GPR) data acquired by rotating antennas have been done. The data acquisition procedure mimics data collection of the Tunnel Boring Machine (TBM). Real GPR data for a Karst scenario were analyzed, preprocessed and finally imaged with back-projection method. Results show that objects buried in the subsurface of the ground can be successfully imaged using rotating antennas, which is a solid foundation for further development of the GPR system on TBM.",Signal Processing
"The present study focuses on the relationship between structure and mechanical properties in nanoporous (NP) metal foams. Experimental and numerical findings suggest for NP Au and single gyroid structures similar topological features. In particular, NP Au and single gyroids are shown to exhibit almost coincident form factors, defined as a function of specific surface area and ligament thickness. Furthermore, nanoindentation of NP Au and uniaxial compression of polymeric single gyroids with comparable relative density of about 0.3 result in almost overlapping relative Young?s moduli. Surface topology and elastic deformation behavior allow considering single gyroids as approximants of the NP Au structure. Consequently, it can be also expected that NP Au and single gyroids undergo similar local deformation mechanisms. These do not involve pure bending of ligaments, but rather a combination of shear and torsion components.",Material Science
"In this paper, YVO4:Bi3+, Eu3+ phosphors have been synthesized by high-temperature solid-state method. The samples were characterized by X-ray powder diffraction, photoluminescence spectra, luminescence lifetime, and GSAS structure refinement. The excitation spectrum of YVO4:Bi3+, Eu3+ monitoring at 622 nm was a broad band with major peak located at 280 nm. It contained the charge transfer from 2p orbit of O2? to 4f orbit of Eu3+ (257 nm) and the absorbing from energy level transition of Bi3+ (1S0?3P1, 346 nm) and VO43? (lA1?1T2, 286 nm and lA1?1T1, 320 nm) through gauss fitting. Upon excitation at a wavelength of 280 nm, the major emission peak of YVO4:Bi3+, Eu3+ located at 622 nm (red) was attributed to the electric dipole transition 5D0?7F2 of Eu3+. The energy transfer mechanism of Bi3+?Eu3+ was also studied to be dipole?quadrupole mechanism of electric multipole interaction, and the critical distance between Eu3+ and Bi3+ was calculated by concentration quenching method. The emission color of YVO4:Bi3+, Eu3+ can be tuned by the energy transfer of ions and the concentration of activator. In a word, the material has a good application prospects in the field of light-emitting diode under ultraviolet excitation.",Material Science
"Silicon nitride (Si3N4) has been introduced clinically as an orthopedic biomaterial for interbody fusion devices and in joint replacements. However, the production of complex shapes through conventional mechanical machining is difficult and expensive and limits interesting applications. Thus, several electrically conductive reinforcements to the Si3N4 matrix, like TiN, have been proposed, generating composites suitable to be wrought by electrical discharge machining (EDM). In this study, Si3N4?TiN with high strength, low density, and good electric conductivity wrought by EDM was studied. The role of surface finishing was investigated comparing the interface generated during the EDM process to that resulting from further polishing. The different topographical features were assessed by electron microscopy, energy dispersive X-ray spectrometry, and profilometry. Surface wettability was also determined based on the measurement of the OCA of water and diiodomethane. The biological responses induced in MC3T3 cells, a widely diffused osteoblast model, were correlated with the surface pattern. The unpolished samples could promote better cell viability, with a more relevant effect on the cytoskeleton arrangement as highlighted by numerous cytoplasmic extensions and filopodia-like structures and the high number of focal adhesions, while MC3T3 cells grown on polished Si3N4?TiN specimens displayed a flat morphology. In addition, the unpolished Si3N4?TiN increased osteocalcin production and calcium deposition. Taken together, these data support the biocompatibility and in vitro osteogenic properties of the electroconductive Si3N4?TiN investigated. Further in vivo studies are required to explore the possible use of bone implants directly obtained by EDM.",Material Science
"A series of silver nanoparticle-modified graphitic carbon nitride/N-doped TiO2 hybrids (Ag/g-C3N4/N-TiO2 or ACTs) were prepared by one-step in situ calcination process at 550 °C for 3 h in air atmosphere. The morphology, structure, and optical properties of ACTs with different Ag contents were characterized by X-ray diffraction, scanning electron microscopy, transmission electron microscopy, X-ray photoelectron spectroscopy, photoluminescence spectra, and UV?vis diffuse reflectance spectroscopy. Ag nanoparticles with grain size of about 5 nm are anchored on the surface of ACTs. In UV?vis absorption test, a red-shift of light absorption edge 
and more visible light absorption (compared to N-TiO2 and g-C3N4/N-TiO2) are observed for ACTs. Moreover, the dependence of photocatalytic activity on Ag contents was investigated, and ACTs-3 presents the highest photocatalytic activity as the optimal Ag content under visible light irradiation. Remarkably enhanced UV?visible light photoelectrochemical response was also confirmed for ACTs compared with TiO2, N-TiO2, and g-C3N4/N-TiO2. Ag-decorated g-C3N4/N-TiO2 composites result in enhanced light absorption capacity and improved transfer of charge carriers, which prominently contribute to the improvement of photoactivity. This work demonstrates that Ag/g-C3N4/N-TiO2 is a promising photocatalytic material for organic pollutant degradation under visible light irradiation.",Material Science
"Electrically conducting copolymers of 3-octylthiophene and biphenyl in equimolar ratio were synthesized and also homopolymers for comparison reasons by potentiostatic electropolymerization, and the polymers were deposited as coatings. Based on various criteria, a proper copolymer was selected and the homopolymer of poly(3-octylthiophene) (P3OT) for comparison reasons, in order to investigate their ability to prepare nanostructured thin films. The latter were synthesized by spin coating from solutions of the polymers in anisole. The polymers were characterized by proper methods such as size-exclusion chromatography (SEC), scanning electron microscopy/energy-dispersive spectroscopy (SEM/EDAX), X-ray diffraction (XRD), differential scanning calorimetry (DSC), ultraviolet?visible spectroscopy (UV?Vis), dynamic light scattering (DLS), atomic force microscopy (AFM), and cyclic voltammetry including also the determination of the limiting viscosity number [?] and their electrical conductivity (?). The selected copolymer and the (P3OT) are mainly amorphous having also regions with order, the copolymer is soluble in more solvents, (P3OT) has higher ?, and both polymers form nanostructured thin films containing nanoparticles with ellipsoid morphology. Generally, the copolymers exhibit comparable properties with those of (P3OT); however, they are far cheaper. Besides the novelty to extend electroactive polymers in new application directions such as nanostructured materials, a further novelty consists of a proposed methodology based on the experimental data, in order to estimate different parameters at molecular level, especially for the macromolecules in solution. The energy gap Eg (band gap) of the polymers as nanostructured thin films was determined by cyclic voltammetry indicating semiconductor behavior, which was also confirmed by their electrical conductivity.",Material Science
"Indium oxide (In2O3) thin films were prepared by spray pyrolysis technique on glass substrates. Prepared thin films were irradiated by gamma radiations with various doses 1, 5, 10, and 100 kGy using an industrial gamma 60Co source. Structural, optical photoluminescence, and electrical properties of irradiated thin layers were investigated, respectively, by X-Ray diffraction, Raman spectroscopy, spectrophotometer, fluorescence spectrometer, and Hall effect. Analysis of structural properties of irradiated thin layers has shown that In2O3 thin films exhibit the same cubic structure with the appearance of new plane orientations (400) and (622) besides the initial one (222) with a decrease in grain size. Transmission values of irradiated thin layers show an increase from 77 to 86 % with the presence of more interference fringes. It was found that band gap energy Eg decreases from 3.45 eV to a minimum value of 3.08 eV for a ?-dose of 10 kGy. Envelope method was used to determine the refractive index which decreases after exposing to ?-radiations from 3.38 to a minimum value of 1,98. Photoluminescence spectrum depicts a global diminution in intensity peak after irradiation. Besides, measured electrical resistivity shows a strong decrease from 65.02 × 10?2 ? cm to a minimum value of 1.02 × 10?2 ? cm for 5 kGy. These results suggest that gamma radiation can improve the physical properties of indium oxide thin films which can be used as transparent conductive electrode or optical window in photovoltaic devices.",Material Science
"Flexible porous materials have been widely used as precursors for preparing superhydrophobic oil absorbents due to their high capacity and extraordinary recyclability. A final product with multiple characteristics such as superhydrophobicity, fire retardancy, good elasticity, low cost, and environmental friendliness is highly needed for practical applications. In this study, superhydrophobic melamine sponges (SMSs) with the above characteristics were prepared by modifying melamine sponges with polymethylsilsesquioxane via an immersion method. A villiform layer of organosilane was coated on the surface of the melamine fibers and disclosed by scanning electron microscopy. The superhydrophobicity of the sponge with a water contact angle of 156° is due to the increased surface roughness and methyl terminal groups exposed at the interface. Polycondensation reaction between the secondary amine groups on the raw sponge surface and silanol is identified by ATR-FTIR and EDX spectra. The SMS effectively absorbs various organic solvents and oils from water with excellent absorption rate. In addition, it maintains stable superhydrophobicity in extreme environments, including strong acid/alkali conditions, high/low temperatures, and prolonged immersion in organic solvents. Importantly, the SMS retains the intrinsic fire retardancy of the raw melamine sponge. In simulating oil spill environments, the SMS shows good performance in blocking spread of crude oil spill and separating surfactant-free water-in-oil emulsions. These advantages make it a promising material for oily wastewater treatment and oil spill clean-ups.",Material Science
"In this study, a series of ?-Fe2O3?CeO2 nanocomposites containing 5, 15, 30, and 50 % Fe as well as the pure oxides, ?-Fe2O3 and CeO2, were synthesized by a novel route of auto-combustion method at temperatures lower than those reported previously. The as-synthesized catalysts were characterized by several techniques such as XRD, XRF, N2 physisorption, DSC/TGA, NH3-TPD, TEM, and EDX. The catalytic activity of the synthesized nanocomposites was examined under ethanol conversion. The results revealed that the solid-solution formation was established for all the Fe-substituted CeO2 samples while maintaining the fluorite structure of ceria. Only a hardly noticeable segregation of ?-Fe2O3 was appreciated for the catalyst samples with higher iron content (30 and 50 wt% Fe). The results confirmed that the adopted auto-combustion method allowed a good control of the chemical composition of the prepared composites with the proper structural and textural characteristics. The 30 % Fe?Ce sample was the most active and selective catalyst toward ethylene production compared with the other samples under study, owing to the pronounced Brönsted acid sites. The overall data collected through this work revealed that the synthesized nanocomposites are promising candidates for the production of ethylene from ethanol.",Material Science
"It was recently shown that silicon particles in heat-treated Al?Si casting alloys can contain flaws such as surface pinholes and grooves, which cause varying degrees of reduction in the in situ particle fracture strength and hence influence the mechanical properties of this class of alloys. In this work, we show that the formation of one class of such strength-limiting flaws in solidified and coarsened Si particles, namely surface pinholes, is caused by alloy impurities such as Fe and Ti in both binary eutectic Al?Si alloys and also in casting alloy A356. This is evidenced by using Focused Ion Beam serial sectioning tomography coupled with Energy-Dispersive X-Ray Spectroscopy, and confirmed by the observation that a high-purity Al?Si alloy presents a significantly lower proportion of pinholes along the surface of the silicon phase than does an alloy of commercial purity. A similar correlation between alloy purity and the formation of another, more severe strength-limiting particle defect, namely grooved interfaces, was on the other hand not found.",Material Science
"The interface between carbon fibers (CFs) and matrix resin makes a critical contribution to bulk performance of composites. In order to enhance interfacial properties and anti-hydrothermal aging behaviors of methyl phenyl silicone resin (MPSR) composites, octamaleamic acid-polyhedral oligomeric silsesquioxanes (POSS-acid) were directly grafted onto CFs surface by chemical bonding for the first time. Surface chemical groups and morphologies of CFs before and after POSS-acid grafting were systematically characterized. Scanning electron microscopy and atomic force microscopy images showed a uniform distribution of POSS-acid on the fiber surface and the improved surface roughness. POSS-acid cages grafting could improve obviously the fiber polarity, wettability, and free energy by dynamic contact angle analysis testing. The interlaminar shear strength (ILSS) of MPSR composites reinforced with the POSS-acid-modified CFs (CF-POSS) was 45.01 ± 1.69 MPa, which increased by 52.73 % compared to that of MPSR composites reinforced with untreated CFs (29.47 ± 0.94 MPa). And, impact strength of CF-POSS composites (77.69 ± 2.83 kJ m?2) was increased by 32.89 % compared to that of untreated CF composites (58.46 ± 1.91 kJ m?2). Moreover, ILSS of CF-POSS composites after hydrothermal aging treatment was 40.89 ± 1.51 MPa with a decrease of just 9.15 % compared to that of untreated CF composites (20.52 ± 0.65 MPa) with an obvious decrease of 30.37 %. Meanwhile, POSS-acid functionalization did not decrease fiber tensile strength. Based on our design starting from simple chemistry and inexpensive materials, such hierarchical reinforcements with improved interfacial strength and anti-hydrothermal aging behaviors have great potential in advance polymer matrix composites.",Material Science
"Metal additives usually have a catalytic effect on non-graphitic carbon materials. However, graphitic carbon materials are difficult to catalyze owing to carbon atoms whose neighbors are ordered regions and less cross-linked. Artificial graphite is generally prepared from coke and pitch, both of which are graphitic carbon. Therefore, efficient catalysts for graphitic carbon materials are important for industrial technology. The effect of light rare earth elements (La, Ce, and Pr) and other additives (Ti, Ni, and B) as co-catalysts in artificial graphite development was investigated. Compared with the single catalysts, the combinatorial catalysts more significantly improved the degree of graphitization in the carbon materials, indicating synergistic catalytic effects. Both dissolution?precipitation and formation?decomposition of carbide were involved in the synergistic catalytic mechanisms. In the combinatorial catalysts systems, the light rare earth element would accelerate the graphitization process of carbon materials by widening the range of the catalytic temperature, accelerating the speed of oversaturation of dissolution, or generating a new carbide phase with the other catalyst. This would promote formation of the more-ordered graphitic structure at relatively low temperature. For instance, to attain the same degree of graphitization and better crystalline sizes at the same residence time, the carbon materials with combinatorial catalysts can be heat treated at temperatures 400 °C lower than without catalysts, and the electrical and mechanical properties are enhanced.",Material Science
"Materials with intrinsic self-healing ability have attracted tremendous interest in literature, especially coatings in anti-corrosion applications. In this work, environmentally friendly waterborne polyurethanes containing disulfide bonds in the main chain were synthesized. Poly (?-caprolactone) glycol with a molecular weight of 1000 was used as soft segment, and isophorone diisocyanate, 2-bis(hydroxymethyl) propionic acid, and 2-hydroxyethyl disulfide were used as hard segment. The influence of 2-hydroxyethyl disulfide/2-bis(hydroxymethyl) propionic acid molar ratios on stability of dispersions and the self-healing property of the waterborne polyurethane films was investigated. The self-healing system was triggered by the chain exchange reaction of disulfide bonds and assisted by the shape memory effect to bring the crack on the waterborne polyurethane surfaces in spatial proximity. The tensile strength of the scratched waterborne polyurethane film was recovered to 90.5 % in 10 min at a modest healing temperature of 65 °C. Meanwhile, the prepared waterborne polyurethanes exhibited excellent dispersion stability and improved thermal stability.",Material Science
"Spark plasma sintering (SPS) is a fairly novel powder metallurgy (PM)-based process. Compared with more traditional PM processes, SPS technology provides greater sintering efficiency for the Ti-48Al alloy, due to its fast heating and cooling rates, combined with an applied pressure and electric field during the process. In this study, three fundamental processing parameters (i.e. sintering temperature, time and particle size) are investigated, and their effects on densification, hardness and phase transformations are studied. Three grain morphologies were found in the microstructures, present in different ratios in the samples, depending on the sintering parameters. A model is proposed to explain the (?2) grain-phase growth and the transformation of two types (fine and coarse) of lamellar structural development. The pore configurations (i.e. size and quantity) are examined, and their interactions with the phases, which suggest the phase-formation sequence and sintering state, are also discussed.",Material Science
"The awned seeds of the family Geraniaceae are special seed-dispersal units. The awns can generate periodic coiling and uncoiling movement through interaction with the diurnal humidity cycle. To investigate how this natural actuator acquires the remarkable property, we determined the three-dimensional morphological features of the coiling awns of Pelargonium peltatum through X-ray microtomography (micro-CT). Many streaks with sharp corners were found distributed in the surface of the inner layer cells, indicating there are two different microfibril angles (MFAs) in the special tilted helix structure of each one cellulose fiber within the cell wall. A simplified mechanical model of the cell wall was developed. Moreover, finite element method was conducted based on the proposed model to analyze the basic mechanism of the coiling deformation. The results showed that stiff cellulose fibers with special tilted helix structures could direct the shrinkage forces resulted from the matrix, so as to generate torsional and bending movement simultaneously. Therefore, the inner layer cell could generate an anti-clockwise coiling deformation macroscopically. In addition, effects of other structural factors including fiber frequency of the cellulose fiber skeletons, modulus ratios between the fibers and matrix, and macroscopical combination among the cells on the degree of the coiling deformation were also studied. The results determined in this work may benefit the development of new kind of intelligent composites.",Material Science
"We present the results from density functional theory calculations of the lithium adsorption on various forms of boron- and nitrogen-doped graphene derivatives. Encouraging results are noticed for the lithium adsorption on the boron-doped graphyne model. The acetylenic linkage increases the lithium adsorption affinity but decreases the gravimetric densities marginally in bare, boron/nitrogen-doped graphene derivatives. From lithiation potential, gravimetric density, and specific capacity values, we notice boronated graphyne as a highly suitable anode material for Li-ion batteries.",Material Science
"Mg?Zn?Al hydrotalcites and derived mixed oxides with different Mg2+-to-Zn2+ ratios were prepared by co-precipitation in super-saturated conditions, followed by thermal decomposition at 500 °C. The synthesized materials were evaluated as catalysts for the self-condensation of octanal in order to establish structure-to-functionality properties of the prepared materials. The presence of zinc affects the structural and textural properties of the as-synthesized hydrotalcites and derived mixed oxides, and provokes a remarkable modification on the acidic?basic properties of the materials as studied by CO2 and NH3-TPD. The presence of Zn2+ caused an increment in the concentration of surface acidic sites compared to the binary Mg?Al system. The samples characterized by a Zn/Mg ratio ?1 showed the optimal ratio of acidic and basic sites and the best catalytic performance for the production of the ?,?-unsaturated aldehyde. The reconstruction of the layered materials (starting from the mixed oxides) caused an increment in the concentration of surface OH? groups, further modifying the selectivity of the reaction.",Material Science
"A series of thermosensitive films for firefighting applications were synthesized by two-step polymerization from two types of polyol and isophorone diisocyanate  and by the formation of aqueous polyurethane dispersions. This study was conducted to clarify the influence of different parameters such as the type of polyol, the chain length of polyol, and the hard segment content on the chemical, thermal, mechanical and diffusion properties of the final films using ATR infrared spectroscopy, differential scanning calorimetry, thermogravimetric analyses, water vapor permeability, swelling behavior, contact angle measurement, and dynamic mechanical analyses. It was noticed that the humidity transfer was influenced by the soft segment crystallization. Indeed, it enhanced the chain mobility in bulk materials leading to an increase in water vapor permeability rather than in swelling. In contrast, low crystallization induced surface state modification resulting in higher swelling capacity.",Material Science
"Nitrogen-doped reduced graphene oxide-supported Mn3O4 nanoparticles (N-RGO/Mn3O4) were prepared by solvothermal method and characterized by several physical techniques such as TEM images, XRD, XPS, and N2 adsorption?desorption techniques. The as-made N-RGO/Mn3O4 catalyst was used for the oxidation of vanillyl alcohol to vanillin. Several important reaction parameters were investigated such as reaction solvent, oxygen concentration, reaction temperature, and catalyst loading. N,N-Dimethylformamide was found to be the best solvent, affording both high conversion and vanillin selectivity. 92.5 % conversion of vanillyl alcohol and 91.4 % selectivity of vanillin were achieved after 12 h at 120 °C under oxygen balloon by the use of 40 mg of the N-GO/Mn3O4 catalyst. Kinetic studies revealed that the active energy for the oxidation of vanillyl alcohol to vanillin over N-GO/Mn3O4 catalyst was 39.67 kJ.mol?1. More importantly, the catalyst was stable and could be reused for 6 times without the significant loss of its catalytic activity.",Material Science
"Indium aluminum tin oxide (IATO) films with high Hall mobility have been deposited on the SiO2 (0001) substrates by metal organic chemical vapor deposition. The structural, morphological, and optoelectronic properties of the IATO films with Sn contents varied from 0 to 18 % [Sn/(In+Al+Sn) atomic ratio] were studied in detail. Well-crystallized IATO film with the highest Hall mobility of 15.59 cm2 V?1 s?1 was obtained at 15 % of Sn content, and the corresponding carrier concentration and resistivity were about 2.38 × 1020 and 1.51 × 10?3 ? cm, respectively. The average transmittance for all the obtained films in the visible range was over 81 %, and the optical band gap of the films changed in the range of 4.05?5.03 eV.",Material Science
"In this paper, we report a thermochemical etching method to fabricate well-distributed micropatterns with large pattern ratios on diamond crystallites using cobalt (Co) powder. The effect of temperature on the depth and area of the micropatterns on different crystal planes is quantified. Results show that the depth and area of the patterns on the same plane increase with the temperature and that, at the same processing temperature, the pattern depth and area on {100} planes are larger than those on {111} planes. After heat treatment at 850 °C, the pattern depths on {100} and {111} planes reach 4.0 and 3.5 µm, and the corresponding average ratios of the pattern area are 54 and 46 %, respectively. The morphologies of the micropatterns on (001), (113), (101), and (111) planes are dependent on the relative orientations between the etched crystal plane and its adjacent planes, and diamond nanoparticles with specific orientations are observed on etched {100} planes. Furthermore, graphite is detected in the etch patterns, suggesting that thermochemical etching process involves the phase transformation from diamond to graphite.",Material Science
"Negative thermal expansion (NTE) and negative Poisson?s ratio (NPR) are counterintuitive material properties that have gained popularity as the focus of many recent works. However, most of the structures previously studied only exhibit NTE or NPR exclusively. One important structure that has already been shown to exhibit NPR is the re-entrant triangle. In this work, the property of NTE in re-entrant triangular cellular structure composed of welded/bonded/brazed ribs of two different materials is investigated via analytical and finite element (FE) modelling. Based on analytical and FE analysis, the geometrical and material parameters for attaining NTE in the re-entrant metamaterial are established. The analysis and simulations reveal the dependence of NTE on the inclination of the longer chevron strut, the dimensionless rod coefficient of thermal expansion (CTE), the ratio of thermal expansion coefficients of constituent struts but independent of scale and temperature. The extent of this property becomes more negative for higher values of the angle of the longer chevron strut with the vertical, higher ratios of CTE of the base to chevron strut material and for lower values of the non-dimensional re-entrant base material thermal expansion coefficient. The anisotropic and NTE behaviour is stretch-dominated. Effectively, combined with previous knowledge of NPR in the re-entrant triangle, NTE leads to further significance of such structures for many thermal and mechanical applications, such as composite materials, sensors and electronic components industries in both thermal and mechanical applications.",Material Science
"The current communication deals with elaboration of electrodeposited graphene oxide (GO)-reinforced copper composite coating with tribomechanical and electrical properties. Graphene oxide, chemically reduced graphene oxide (RGO) and thermally reduced graphene oxide (TRGO) with different concentrations (0.1, 0.5 and 1 g/L) were incorporated in the copper matrix. The surface-mechanical and electrical properties of the developed coatings were investigated for possible electrical contacts applications. The deposition process was carried out at a pH value of 1 ± 0.02, which was sufficiently below the isoelectric point of RGO and TRGO to avoid possible agglomeration during deposition. A structural change of the synthesized specimens and the presence of GO in the composite coating were demonstrated from Raman spectra characterization. X-ray photo electron spectroscopy of some specific specimens (RGO, TRGO and Cu-0.5 g/L TRGO) was carried out to study the elemental composition, chemical state and electronic state of the elements present. Improvement of mechanical and electrical properties was clearly evident due to dispersion hardening caused by uniform dispersion of second-phase GOs. Cu?TRGO composite coating shows excellent electrical conductivity as compared to GO- and RGO-reinforced composite coatings due to removal of oxygen-containing groups after thermal reduction process.",Material Science
"Lead-free and high-temperature 0.71BiFeO3-0.29BaTiO3 ceramics with Mn modification (BF-BT-x %Mn) were fabricated by conventional solid-state reaction method, and the high temperature dielectric, ferroelectric and piezoelectric properties were investigated. All compositions exhibited pseudo-cubic phases. Mn modification improved the electrical properties of BF-BT solid solutions at both room and high temperature. The Curie temperature TC, depolarization temperature Td, dielectric constant ?r, dielectric loss tan?, piezoelectric constant d33, electromechanical coupling factor kp, remnant polarization Pr of BF-BT-1.2 %Mn ceramics were 506, 500 °C, 556, 0.04, 169 pC N?1, 0.373, 31.4 ?C cm?2, respectively. The ?r, tan?, and kp of BF-BT-1.2 %Mn ceramics were stable with the increase of temperature until 500 °C. The coercive field Ec of BF-BT-1.2 %Mn ceramics was nearly 30 kV cm?1 at 200 °C, which was much larger than those of PZT, BS-PT,BNT and KNN ceramics. The high field strain coefficient d*33 reached as large as 525 pm V?1 at 200 °C. These results showed that the BF-BT-x %Mn ceramics were promising candidate for high temperature piezoelectric applications.",Material Science
"An ordered porous Mn3O4@N-doped carbon/graphene (MCG) composite has been synthesized through a facile carbonization of Mn-based metal?organic frameworks (Mn-MOFs) using the poly(styrene-co-AA) spheres as the template. Because of the periodic arrangement of metal nodes and organic ligands in the Mn-MOFs, the Mn3O4 nanoparticles with an average diameter of 7 nm are uniformly distributed and the carbon is formed in situ in the MCG composite. The MCG exhibits a specific surface area of 326 m2 g?1 with a total pore volume of 1.02 cm3 g?1, which is much higher than that of the Mn3O4-based composites reported to date. In addition, the MCG displays excellent electrochemical performances in an aqueous 1 M Na2SO4 electrolyte with a maximum specific capacitance of 456 F g?1 at 1 A g?1 and 246 F g?1 at 20 A g?1. The MCG also owns a good cycling stability with 98.1 % of the initial capacitance remaining after 2000 cycles at 5 A g?1.",Material Science
"Polymer-stabilized gold nanoparticles have been reported using an in situ chemical synthesis route where the gold nanoparticles were uniformly dispersed throughout the macromolecular chain and formed a uniform metal?polymer composite material. The surface properties of the composite material were characterized using X-ray diffraction and X-ray photoelectron spectroscopy techniques. The electron transfer resistance (ETR) value of the resultant material was measured using electrochemical impedance spectroscopy technique. By incorporating the gold nanoparticles in the polymer matrix, the ETR value of the composite material was decreased as compared with the pure polymer and showed the efficient catalytic performance for the electrochemical recognition of dopamine. The gold?polymer composite performed as a highly efficient material for the reduction of Rhodamine-B, which suggests that the reduction process was driven by the hydrogen atom transfer mechanism and catalyzed by the gold nanoparticles.",Material Science
"The worldwide production of glycerin exceeds the demand from the chemical industry and new applications have been investigated these last years mainly in the area of additives. Here, water?soluble glycerin-based polyacrylates and polymethacrylates have been prepared by free-radical polymerization of solketal (meth)acrylate using various transfer agents derived from fatty chains. According to specific experimental conditions, linear functional oligomers were obtained. This versatile process allowed designing amphiphilic copolymers after the hydrolysis of acetal groups. These oligomers exhibit critical aggregation concentration values ranging from 5 to 15 × 10?6 mol.L?1 without any strong differences between polyacrylate and polymethacrylate series. In the case of glycerol-based polyacrylate derivatives, the observed monomodal populations can be ascribed to the low polydispersity indexes.",Material Science
Atmospheric plasma-sprayed thermal barrier coating made up of YSZ and LaMgAl11O19/YSZ was plasma-sprayed over nickel-based superalloy. The coated surfaces are textured using a picosecond pulsed laser for different groove geometries. The scanning parameters were optimised to minimise the occurrences of re-cast layer and horizontal cracks. The textured samples were subjected to thermal shock cycles to study their thermal stability. The width-to-depth ratio (Wd) and the groove spacing between the adjacent texture were varied to analyse and correlate their geometrical influence in providing thermal stress?strain tolerance. The textured samples exhibit higher lifetime compared to the YSZ and LaMgAl11O19/YSZ as-sprayed surface. The induced thermal stress and minimal strain tolerance in the as-sprayed surfaces result in the traditional interface delamination failure where the failure occurs at the bond coat?ceramic layer interface. The textured grooves having higher Wd restrain the propagation of crack across the coating thickness and provide improved strain tolerance. The horizontal cracks initiated at the edge propagates across the textured layer chipped the groove segments within the ceramic bulk layer. The LaMgAl11O19/YSZ-based textured sample having Wd of 0.8 and 300 µm groove spacing exhibits higher lifetime of 219 thermal cycles. This implies the significance of groove density in improving the thermal shock resistance of TBCs.,Material Science
"An isotropic pitch which has a relatively high softening point and an excellent spinnability for general performance carbon fiber was successfully prepared through the low-temperature co-carbonization with ethylene bottom oil (EO). The special bromination and dehydrobromination reaction of the mixed biotar and EO was adapted at a relatively low temperature for minimizing the phase separation of the two raw materials. The optimized reaction conditions for bromination and dehydrobromination were the heat treatments at 110 °C for 1 h with 20 wt% of Br2 addition and at 320 °C for 3 h under N2 atmosphere, respectively. After removal of volatile matters by thin layer evaporation at 350 °C, the target spinnable isotropic pitch, which has a relatively softening point of 205 °C and excellent spinnability, was successfully obtained with high synthetic yield of 45 wt%. The carbon fiber fabricated using the obtained isotropic pitch precursor showed an enormous tensile strength of 1200 MPa by heat treatment alone at 800 °C for 5 min.",Material Science
"Graphene oxide (GO)-based polymer nanocomposites were fabricated in aqueous solution via a novel strategy combination of mussel-inspired chemistry and Michael addition reaction. These GO-based polymer nanocomposites were used as efficient absorbents for the removal of organic dyes methylene blue (MB) from the aqueous solution. The successful preparation of GO-based polymer nanocomposites (GO-PDA-PSPSH) was confirmed by a number of characterization techniques in detail. Furthermore, a series of influential factors such as contact time, initial solution pH, and temperature were investigated and optimized. The optimal adsorption time of GO-PDA-PSPSH nanocomposites toward MB was 58 min. The maximum adsorption efficiency was occurred at pH 7. On the other hand, accompanying with the elevation of temperature, removal efficiency of GO-PDA-PSPSH nanocomposites was significantly increased, indicating that the adsorption process of MB by GO-PDA-PSPSH nanocomposites was endothermic. More importantly, the adsorption capability of GO-PDA-PSPSH nanocomposites was obviously greater than many other GO-based nanocomposites. Taken together, we have developed a facile biomimetic strategy for the preparation of GO-based polymer nanocomposites, which showed excellent adsorption capability toward MB and are promising for environmental adsorption applications.",Material Science
"Biogas-powered fuel cells that use low-quality biogas produced from organic waste hold a great promise for providing ultra-clean electric energy with on-site power generators. However, natural biogas contains a small amount of H2S, which causes a rapid deactivation of steam-reforming metal catalysts, such as Ni. In this work, we successfully prepared two types of paper-structured catalyst, separately containing manganese oxides (MnOx) and nickel/magnesium oxides (Ni/MgO), for desulfurization and methane-steam reforming, respectively. In the sequential desulfurization and methane-steam reforming, paper catalyst assembly, designed by stacking MnOx papers upstream and Ni/MgO papers downstream in a dual-layered form, enabled continuous hydrogen production from simulated biogas containing ca. 2000 ppm H2S impurities, whereas single-layered Ni/MgO papers immediately lost their catalytic activity due to the H2S poisoning. This combination of flexible, stackable, and easy-to-handle paper-structured catalysts has the potential to improve the energy efficiency and to process economics of providing hydrogen to biogas-powered fuel-cell systems.",Material Science
"A new nucleation mechanism is proposed for {101¯1}{101¯1} \{ 10ar{1}1\}  deformation twin in hcp materials. The mechanism is based on the results of atomistic computer simulations. It was found that under high shear stress applied on {101¯1}{101¯1} \{ 10ar{1}1\}  plane (the stress level is about 7 % of shear modulus), the core of a slip dislocation can transform to a twin embryo. The transformation and subsequent twin growth are accompanied by nucleation and migration of interfacial defects including disconnections and stacking faults. The paper provides the analysis of the nature of these defects and describes the reactions between them.",Material Science
"A series of NaLaTi2O6: Eu3+ red phosphors with different Eu3+ ion concentrations were prepared via a high-temperature solid-state reaction technique. The effects of Eu3+ ion concentration and temperature on the fluorescent properties of NaLaTi2O6: Eu3+ phosphors were investigated. The XRD patterns revealed that the as-synthesized samples were single-phase NaLaTi2O6. Eu3+ ion concentration-dependent excitation and emission spectra showed that there was an efficient energy transfer from NaLaTi2O6 host to Eu3+ ions. Concentration quenching was observed and can be ascribed to exchange interaction between Eu3+ ions based on Van Uitert?s model. According to the temperature-dependent emission spectra and the fluorescence decay curves, crossover process was confirmed to be the main mechanism for the temperature-dependent fluorescence quenching behavior of 5D0 level of Eu3+ ions in NaLaTi2O6 phosphors. The activation energy was obtained to be 0.30 eV by Arrhenius model. Based on the emission spectra and Judd?Ofelt theory, the optical transition properties of Eu3+ ions in NaLaTi2O6 phosphors were studied.",Material Science
"High-surface area-activated carbons (ACs) are successfully prepared by coal-tar pitch (CTP)/sawdust (SD) co-carbonization followed by simple KOH activation. The ACs inherit the tubular morphology of the biomass and possess a hierarchical porous structure, a high specific surface area of 2224 m2/g, and a considerable amount of oxygen-containing species on the surface. The AC obtained from the co-carbonization of 67 % CTP and 33 % SD has a 25 wt% higher oxygen content than the AC (0.17 wt%) from 100 % CTP, and has a 27.50 wt% higher carbon yield than the AC (14.42 wt%) from SD. As an electrode material for supercapacitors, the prepared electrode from 67 % CTP and 33 % SD exhibits a favorable specific capacitance of 251 F/g at a current density of 0.5 A/g in 6 mol/L KOH electrolyte. The electrode also demonstrates excellent cycling stability with a retention rate of 93 % over 7000 cycles at 2 A/g and a favorable rate capability with a retention rate of 74 % when the current density increases from 0.5 to 5 A/g. Therefore, the ACs obtained by co-carbonizing CTP and SD have high potential as electrode materials. This route not only enhances the benefit from agricultural wastes, but also reduces the cost of producing electrode materials for supercapacitors.",Material Science
"In this work, a method for the fabrication of two- and three-dimensional curved surfaces with robust underwater superoleophobicity is reported for the first time on light alloys (including 5083 Al and TC4 Ti alloys) through the high speed wire electrical discharge machining (HS-WEDM). The surface morphology and compositions were characterized by scanning electron microscope and energy-dispersive X-ray spectrometer. The results showed that rough structures and a layer of oxidization were created on the light alloys by HS-WEDM cutting. The two- and three-dimensional structured curved surfaces after an ethanol immersion exhibited the extreme underwater superoleophobic property with the high oil contact angle and low oil sliding angle. More importantly, the underwater superoleophobic surfaces with the three-dimensional curved features could have many new applications. In order to use the potential functions, the durability of the fabricated samples was tested and the results showed that the samples still exhibited the underwater superoleophobic property after the underwater storage and physical mechanism tests. Additionally, this method is versatile, simple, environment-friendly, and cost-effective.",Material Science
